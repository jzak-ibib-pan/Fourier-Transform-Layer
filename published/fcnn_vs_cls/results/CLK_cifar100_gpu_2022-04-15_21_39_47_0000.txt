Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.712578 ||   0.0236 ||   0.0853 ||  0.531882 ||  0.547551 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607100 ||   0.0523 ||   0.1313 ||  0.559988 ||  0.561293 ||      4.605915 ||      0.0094 ||   0.0445 ||  0.501061 ||  0.487308 ||    17.714108 || 
    Epoch 01    --      4.605334 ||   0.0100 ||   0.0496 ||  0.496452 ||  0.498161 ||      4.603723 ||      0.0091 ||   0.0455 ||  0.502083 ||  0.492660 ||    16.245737 || 
    Epoch 02    --      4.601003 ||   0.0105 ||   0.0501 ||  0.494703 ||  0.496614 ||      4.601792 ||      0.0095 ||   0.0474 ||  0.502364 ||  0.488026 ||    16.284401 || 
    Epoch 03    --      4.599597 ||   0.0114 ||   0.0501 ||  0.497035 ||  0.499398 ||      4.599874 ||      0.0104 ||   0.0446 ||  0.503712 ||  0.490398 ||    16.457329 || 
    Epoch 04    --      4.597074 ||   0.0113 ||   0.0518 ||  0.496329 ||  0.498752 ||      4.597706 ||      0.0104 ||   0.0470 ||  0.504521 ||  0.495057 ||    16.283387 || 
    Epoch 05    --      4.592818 ||   0.0132 ||   0.0531 ||  0.499637 ||  0.501983 ||      4.592906 ||      0.0104 ||   0.0486 ||  0.506050 ||  0.496338 ||    16.399467 || 
    Epoch 06    --      4.589134 ||   0.0140 ||   0.0551 ||  0.501974 ||  0.504304 ||      4.593766 ||      0.0130 ||   0.0509 ||  0.511851 ||  0.500565 ||    16.248770 || 
    Epoch 07    --      4.580603 ||   0.0155 ||   0.0581 ||  0.505839 ||  0.508689 ||      4.581154 ||      0.0136 ||   0.0552 ||  0.515211 ||  0.502673 ||    16.788384 || 
    Epoch 08    --      4.569677 ||   0.0170 ||   0.0606 ||  0.510736 ||  0.514204 ||      4.569304 ||      0.0148 ||   0.0564 ||  0.518005 ||  0.507332 ||    16.118555 || 
    Epoch 09    --      4.557517 ||   0.0192 ||   0.0662 ||  0.518103 ||  0.521929 ||      4.559286 ||      0.0190 ||   0.0643 ||  0.524915 ||  0.519982 ||    16.382195 || 
    Epoch 10    --      4.546619 ||   0.0214 ||   0.0710 ||  0.523542 ||  0.528725 ||      4.552404 ||      0.0180 ||   0.0601 ||  0.524212 ||  0.516654 ||    16.646999 || 
    Epoch 11    --      4.532611 ||   0.0238 ||   0.0741 ||  0.526772 ||  0.533035 ||      4.526226 ||      0.0219 ||   0.0690 ||  0.536875 ||  0.531702 ||    16.066794 || 
    Epoch 12    --      4.517764 ||   0.0261 ||   0.0774 ||  0.533609 ||  0.540261 ||      4.507635 ||      0.0267 ||   0.0747 ||  0.541931 ||  0.540011 ||    16.169020 || 
    Epoch 13    --      4.506089 ||   0.0293 ||   0.0836 ||  0.537411 ||  0.545349 ||      4.512005 ||      0.0262 ||   0.0820 ||  0.542055 ||  0.538597 ||    16.269467 || 
    Epoch 14    --      4.490061 ||   0.0323 ||   0.0864 ||  0.543423 ||  0.551723 ||      4.490381 ||      0.0294 ||   0.0852 ||  0.550602 ||  0.550082 ||    16.191911 || 
    Epoch 15    --      4.475502 ||   0.0342 ||   0.0893 ||  0.547282 ||  0.555371 ||      4.480476 ||      0.0315 ||   0.0840 ||  0.548316 ||  0.548199 ||    16.051504 || 
    Epoch 16    --      4.460038 ||   0.0369 ||   0.0934 ||  0.552063 ||  0.561734 ||      4.452485 ||      0.0383 ||   0.0910 ||  0.557069 ||  0.558234 ||    16.077750 || 
    Epoch 17    --      4.440239 ||   0.0421 ||   0.1002 ||  0.557594 ||  0.567279 ||      4.458466 ||      0.0353 ||   0.0906 ||  0.553198 ||  0.554618 ||    16.399949 || 
    Epoch 18    --      4.428840 ||   0.0438 ||   0.1025 ||  0.560199 ||  0.569560 ||      4.444097 ||      0.0362 ||   0.0943 ||  0.565543 ||  0.571712 ||    16.075179 || 
    Epoch 19    --      4.414073 ||   0.0459 ||   0.1066 ||  0.565424 ||  0.576181 ||      4.407997 ||      0.0423 ||   0.1031 ||  0.570904 ||  0.575141 ||    16.267525 || 
    Epoch 20    --      4.400806 ||   0.0485 ||   0.1076 ||  0.568313 ||  0.579344 ||      4.386344 ||      0.0472 ||   0.1108 ||  0.574289 ||  0.580857 ||    16.453669 || 
    Epoch 21    --      4.382350 ||   0.0520 ||   0.1151 ||  0.574582 ||  0.586394 ||      4.396070 ||      0.0485 ||   0.1110 ||  0.571528 ||  0.574120 ||    16.402047 || 
    Epoch 22    --      4.367546 ||   0.0549 ||   0.1178 ||  0.576426 ||  0.588356 ||      4.368233 ||      0.0507 ||   0.1180 ||  0.580974 ||  0.587823 ||    16.491210 || 
    Epoch 23    --      4.348767 ||   0.0576 ||   0.1236 ||  0.579991 ||  0.593409 ||      4.344857 ||      0.0573 ||   0.1197 ||  0.587542 ||  0.592301 ||    16.298234 || 
    Epoch 24    --      4.343236 ||   0.0605 ||   0.1239 ||  0.583666 ||  0.595668 ||      4.326126 ||      0.0620 ||   0.1278 ||  0.595226 ||  0.603006 ||    16.482890 || 
    Epoch 25    --      4.316639 ||   0.0643 ||   0.1295 ||  0.588395 ||  0.601623 ||      4.329764 ||      0.0622 ||   0.1223 ||  0.587167 ||  0.591904 ||    16.465960 || 
    Epoch 26    --      4.307741 ||   0.0686 ||   0.1347 ||  0.591354 ||  0.605112 ||      4.287135 ||      0.0691 ||   0.1292 ||  0.598975 ||  0.603768 ||    16.461536 || 
    Epoch 27    --      4.286676 ||   0.0713 ||   0.1382 ||  0.595160 ||  0.609698 ||      4.269551 ||      0.0727 ||   0.1377 ||  0.603201 ||  0.613783 ||    16.360386 || 
    Epoch 28    --      4.277031 ||   0.0747 ||   0.1408 ||  0.598393 ||  0.612097 ||      4.329454 ||      0.0658 ||   0.1379 ||  0.602924 ||  0.612084 ||    16.577166 || 
    Epoch 29    --      4.256321 ||   0.0794 ||   0.1478 ||  0.602362 ||  0.617067 ||      4.271320 ||      0.0756 ||   0.1441 ||  0.605943 ||  0.616584 ||    16.150712 || 
    Epoch 30    --      4.243988 ||   0.0810 ||   0.1494 ||  0.602861 ||  0.618862 ||      4.232490 ||      0.0807 ||   0.1479 ||  0.605788 ||  0.614898 ||    16.288038 || 
    Epoch 31    --      4.230770 ||   0.0834 ||   0.1496 ||  0.605076 ||  0.621647 ||      4.208473 ||      0.0887 ||   0.1617 ||  0.615578 ||  0.626087 ||    16.227197 || 
    Epoch 32    --      4.211215 ||   0.0861 ||   0.1570 ||  0.611105 ||  0.626436 ||      4.258897 ||      0.0810 ||   0.1501 ||  0.606474 ||  0.619426 ||    16.288406 || 
    Epoch 33    --      4.204065 ||   0.0890 ||   0.1586 ||  0.612150 ||  0.628093 ||      4.176642 ||      0.0923 ||   0.1641 ||  0.622036 ||  0.632033 ||    16.225713 || 
    Epoch 34    --      4.182713 ||   0.0945 ||   0.1641 ||  0.616480 ||  0.633404 ||      4.192490 ||      0.0914 ||   0.1631 ||  0.621645 ||  0.633387 ||    16.389981 || 
    Epoch 35    --      4.167034 ||   0.0979 ||   0.1667 ||  0.619686 ||  0.636181 ||      4.165300 ||      0.0942 ||   0.1638 ||  0.623845 ||  0.635337 ||    16.236894 || 
    Epoch 36    --      4.167030 ||   0.0988 ||   0.1693 ||  0.620490 ||  0.638205 ||      4.242004 ||      0.0962 ||   0.1751 ||  0.633356 ||  0.643647 ||    16.190396 || 
    Epoch 37    --      4.138196 ||   0.1040 ||   0.1761 ||  0.625347 ||  0.642793 ||      4.154330 ||      0.0989 ||   0.1671 ||  0.625229 ||  0.638707 ||    16.144920 || 
    Epoch 38    --      4.130029 ||   0.1050 ||   0.1746 ||  0.626344 ||  0.643748 ||      4.150314 ||      0.1058 ||   0.1844 ||  0.638424 ||  0.652772 ||    16.410455 || 
    Epoch 39    --      4.119569 ||   0.1069 ||   0.1792 ||  0.628673 ||  0.647424 ||      4.079926 ||      0.1121 ||   0.1812 ||  0.639225 ||  0.649924 ||    16.608006 || 
    Epoch 40    --      4.102430 ||   0.1109 ||   0.1807 ||  0.632615 ||  0.650448 ||      4.097685 ||      0.1098 ||   0.1838 ||  0.637138 ||  0.650651 ||    16.109260 || 
    Epoch 41    --      4.097899 ||   0.1104 ||   0.1803 ||  0.632171 ||  0.650655 ||      4.079899 ||      0.1131 ||   0.1816 ||  0.636026 ||  0.645281 ||    15.964948 || 
    Epoch 42    --      4.094220 ||   0.1115 ||   0.1840 ||  0.634969 ||  0.654278 ||      4.098146 ||      0.1077 ||   0.1849 ||  0.640501 ||  0.651633 ||    16.394941 || 
    Epoch 43    --      4.075853 ||   0.1145 ||   0.1866 ||  0.637307 ||  0.656116 ||      4.113579 ||      0.1112 ||   0.1902 ||  0.644023 ||  0.657754 ||    16.510486 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
