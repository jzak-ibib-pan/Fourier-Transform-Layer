Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.831352 ||   0.0259 ||   0.0924 ||  0.537731 ||  0.555582 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607480 ||   0.0506 ||   0.1290 ||  0.563077 ||  0.564557 ||      4.607003 ||      0.0090 ||   0.0441 ||  0.500267 ||  0.486038 ||    92.452018 || 
    Epoch 01    --      4.606268 ||   0.0093 ||   0.0482 ||  0.493779 ||  0.495266 ||      4.605074 ||      0.0085 ||   0.0455 ||  0.501258 ||  0.492005 ||    90.030192 || 
    Epoch 02    --      4.602634 ||   0.0104 ||   0.0497 ||  0.494954 ||  0.496635 ||      4.602581 ||      0.0095 ||   0.0470 ||  0.501878 ||  0.487983 ||    91.655162 || 
    Epoch 03    --      4.600252 ||   0.0111 ||   0.0502 ||  0.496950 ||  0.499344 ||      4.601358 ||      0.0104 ||   0.0471 ||  0.504938 ||  0.491134 ||    92.106710 || 
    Epoch 04    --      4.597253 ||   0.0110 ||   0.0516 ||  0.496652 ||  0.499069 ||      4.593616 ||      0.0109 ||   0.0478 ||  0.505319 ||  0.495420 ||    90.373946 || 
    Epoch 05    --      4.593896 ||   0.0125 ||   0.0514 ||  0.498100 ||  0.500485 ||      4.590120 ||      0.0110 ||   0.0492 ||  0.506977 ||  0.497848 ||    90.371337 || 
    Epoch 06    --      4.589555 ||   0.0133 ||   0.0551 ||  0.500619 ||  0.502837 ||      4.589994 ||      0.0113 ||   0.0494 ||  0.507495 ||  0.495701 ||    90.623929 || 
    Epoch 07    --      4.584315 ||   0.0146 ||   0.0563 ||  0.504057 ||  0.506808 ||      4.581948 ||      0.0132 ||   0.0521 ||  0.510667 ||  0.496238 ||    90.905205 || 
    Epoch 08    --      4.577321 ||   0.0153 ||   0.0580 ||  0.506462 ||  0.509559 ||      4.583269 ||      0.0133 ||   0.0532 ||  0.513150 ||  0.502587 ||    91.358335 || 
    Epoch 09    --      4.570597 ||   0.0170 ||   0.0620 ||  0.510151 ||  0.513137 ||      4.566112 ||      0.0180 ||   0.0602 ||  0.517910 ||  0.511603 ||    90.420840 || 
    Epoch 10    --      4.562604 ||   0.0193 ||   0.0651 ||  0.513661 ||  0.517535 ||      4.559476 ||      0.0169 ||   0.0581 ||  0.518239 ||  0.510127 ||    91.077083 || 
    Epoch 11    --      4.551834 ||   0.0213 ||   0.0671 ||  0.516918 ||  0.521618 ||      4.555188 ||      0.0171 ||   0.0590 ||  0.520611 ||  0.513228 ||    90.886976 || 
    Epoch 12    --      4.543586 ||   0.0233 ||   0.0710 ||  0.520045 ||  0.524960 ||      4.543870 ||      0.0203 ||   0.0666 ||  0.528368 ||  0.521105 ||    90.920846 || 
    Epoch 13    --      4.532443 ||   0.0259 ||   0.0751 ||  0.524925 ||  0.530427 ||      4.535285 ||      0.0224 ||   0.0707 ||  0.530568 ||  0.526227 ||    91.894553 || 
    Epoch 14    --      4.521203 ||   0.0271 ||   0.0776 ||  0.528359 ||  0.534808 ||      4.522295 ||      0.0268 ||   0.0770 ||  0.539430 ||  0.537696 ||    92.630661 || 
    Epoch 15    --      4.511575 ||   0.0289 ||   0.0789 ||  0.531902 ||  0.538746 ||      4.512208 ||      0.0270 ||   0.0773 ||  0.537121 ||  0.534733 ||    94.702069 || 
    Epoch 16    --      4.496425 ||   0.0317 ||   0.0846 ||  0.539140 ||  0.547446 ||      4.495220 ||      0.0335 ||   0.0839 ||  0.546202 ||  0.545058 ||    91.355282 || 
    Epoch 17    --      4.477614 ||   0.0361 ||   0.0920 ||  0.545205 ||  0.553743 ||      4.488202 ||      0.0341 ||   0.0908 ||  0.556146 ||  0.561190 ||    90.889624 || 
    Epoch 18    --      4.457810 ||   0.0396 ||   0.0953 ||  0.551129 ||  0.560512 ||      4.465365 ||      0.0360 ||   0.0912 ||  0.554195 ||  0.560610 ||    91.708794 || 
    Epoch 19    --      4.448172 ||   0.0417 ||   0.1006 ||  0.555051 ||  0.565314 ||      4.433904 ||      0.0417 ||   0.1045 ||  0.568585 ||  0.574053 ||    91.639623 || 
    Epoch 20    --      4.425376 ||   0.0448 ||   0.1040 ||  0.562007 ||  0.573612 ||      4.434677 ||      0.0402 ||   0.1002 ||  0.566287 ||  0.572192 ||    91.565860 || 
    Epoch 21    --      4.417431 ||   0.0469 ||   0.1082 ||  0.565534 ||  0.577288 ||      4.406871 ||      0.0450 ||   0.1084 ||  0.569686 ||  0.573764 ||    91.874007 || 
    Epoch 22    --      4.396154 ||   0.0504 ||   0.1118 ||  0.570133 ||  0.582591 ||      4.451169 ||      0.0440 ||   0.1091 ||  0.570664 ||  0.577300 ||    92.202132 || 
    Epoch 23    --      4.384810 ||   0.0521 ||   0.1155 ||  0.571573 ||  0.585092 ||      4.374759 ||      0.0507 ||   0.1130 ||  0.579634 ||  0.586534 ||    92.842753 || 
    Epoch 24    --      4.365130 ||   0.0555 ||   0.1182 ||  0.577257 ||  0.590809 ||      4.352590 ||      0.0589 ||   0.1222 ||  0.592427 ||  0.602505 ||    94.373995 || 
    Epoch 25    --      4.349123 ||   0.0584 ||   0.1231 ||  0.582083 ||  0.595961 ||      4.347048 ||      0.0571 ||   0.1264 ||  0.588894 ||  0.597540 ||    93.842754 || 
    Epoch 26    --      4.342255 ||   0.0609 ||   0.1277 ||  0.584951 ||  0.600428 ||      4.359279 ||      0.0640 ||   0.1332 ||  0.599775 ||  0.607501 ||    91.905271 || 
    Epoch 27    --      4.327222 ||   0.0644 ||   0.1300 ||  0.587397 ||  0.601858 ||      4.308904 ||      0.0653 ||   0.1273 ||  0.591426 ||  0.600783 ||    93.185414 || 
    Epoch 28    --      4.301051 ||   0.0694 ||   0.1353 ||  0.592841 ||  0.607588 ||      4.283634 ||      0.0653 ||   0.1319 ||  0.601092 ||  0.611366 ||    91.186502 || 
    Epoch 29    --      4.286052 ||   0.0720 ||   0.1404 ||  0.597811 ||  0.613570 ||      4.286477 ||      0.0688 ||   0.1345 ||  0.601384 ||  0.612691 ||    90.830548 || 
    Epoch 30    --      4.282257 ||   0.0728 ||   0.1403 ||  0.595844 ||  0.613340 ||      4.254631 ||      0.0762 ||   0.1453 ||  0.604662 ||  0.616373 ||    90.950083 || 
    Epoch 31    --      4.261967 ||   0.0754 ||   0.1427 ||  0.599572 ||  0.617227 ||      4.232357 ||      0.0812 ||   0.1545 ||  0.610701 ||  0.624879 ||    90.436558 || 
    Epoch 32    --      4.249094 ||   0.0787 ||   0.1485 ||  0.604801 ||  0.622548 ||      4.253825 ||      0.0782 ||   0.1464 ||  0.611507 ||  0.626171 ||    91.164284 || 
    Epoch 33    --      4.230576 ||   0.0820 ||   0.1507 ||  0.608374 ||  0.626172 ||      4.215318 ||      0.0845 ||   0.1517 ||  0.615217 ||  0.625413 ||    90.858402 || 
    Epoch 34    --      4.222949 ||   0.0844 ||   0.1549 ||  0.611465 ||  0.630702 ||      4.232275 ||      0.0815 ||   0.1496 ||  0.611769 ||  0.621587 ||    91.045944 || 
    Epoch 35    --      4.200803 ||   0.0896 ||   0.1609 ||  0.614457 ||  0.634170 ||      4.199754 ||      0.0825 ||   0.1554 ||  0.618419 ||  0.631382 ||    91.467817 || 
    Epoch 36    --      4.190516 ||   0.0900 ||   0.1632 ||  0.618007 ||  0.637409 ||      4.218377 ||      0.0821 ||   0.1528 ||  0.613992 ||  0.624886 ||    91.561565 || 
    Epoch 37    --      4.171500 ||   0.0934 ||   0.1662 ||  0.620194 ||  0.639707 ||      4.169046 ||      0.0925 ||   0.1618 ||  0.623580 ||  0.638048 ||    90.859168 || 
    Epoch 38    --      4.161102 ||   0.0973 ||   0.1692 ||  0.622956 ||  0.642776 ||      4.144028 ||      0.0961 ||   0.1754 ||  0.637413 ||  0.653602 ||    91.014707 || 
    Epoch 39    --      4.148629 ||   0.0983 ||   0.1713 ||  0.625428 ||  0.645242 ||      4.116961 ||      0.1028 ||   0.1794 ||  0.637220 ||  0.652289 ||    90.382883 || 
    Epoch 40    --      4.143629 ||   0.1010 ||   0.1725 ||  0.627271 ||  0.646856 ||      4.149270 ||      0.1007 ||   0.1805 ||  0.633308 ||  0.650489 ||    91.452210 || 
    Epoch 41    --      4.140739 ||   0.1002 ||   0.1752 ||  0.626508 ||  0.647344 ||      4.178887 ||      0.0927 ||   0.1621 ||  0.621305 ||  0.630892 ||    91.499082 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
