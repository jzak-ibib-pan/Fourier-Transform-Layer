Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.385898 ||   0.0293 ||   0.0992 ||  0.543143 ||  0.560435 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607265 ||   0.0536 ||   0.1320 ||  0.561822 ||  0.563381 ||      4.607045 ||      0.0090 ||   0.0438 ||  0.499959 ||  0.486091 ||    92.202279 || 
    Epoch 01    --      4.607660 ||   0.0090 ||   0.0477 ||  0.493743 ||  0.495187 ||      4.606605 ||      0.0080 ||   0.0443 ||  0.500378 ||  0.490746 ||    91.327250 || 
    Epoch 02    --      4.605858 ||   0.0095 ||   0.0484 ||  0.493230 ||  0.494760 ||      4.606845 ||      0.0090 ||   0.0460 ||  0.500847 ||  0.486356 ||    91.421041 || 
    Epoch 03    --      4.602372 ||   0.0106 ||   0.0488 ||  0.495814 ||  0.497896 ||      4.603683 ||      0.0095 ||   0.0459 ||  0.503101 ||  0.488969 ||    90.811631 || 
    Epoch 04    --      4.600336 ||   0.0107 ||   0.0512 ||  0.496086 ||  0.498484 ||      4.597756 ||      0.0102 ||   0.0461 ||  0.504576 ||  0.493883 ||    91.155424 || 
    Epoch 05    --      4.597051 ||   0.0121 ||   0.0509 ||  0.498550 ||  0.500670 ||      4.594846 ||      0.0096 ||   0.0471 ||  0.504595 ||  0.494672 ||    91.327269 || 
    Epoch 06    --      4.592602 ||   0.0131 ||   0.0550 ||  0.500976 ||  0.503521 ||      4.588785 ||      0.0108 ||   0.0487 ||  0.508291 ||  0.496058 ||    91.124184 || 
    Epoch 07    --      4.585482 ||   0.0141 ||   0.0560 ||  0.504432 ||  0.507358 ||      4.585593 ||      0.0127 ||   0.0512 ||  0.508880 ||  0.494498 ||    90.811694 || 
    Epoch 08    --      4.577471 ||   0.0163 ||   0.0584 ||  0.506903 ||  0.510028 ||      4.594859 ||      0.0130 ||   0.0555 ||  0.517618 ||  0.507308 ||    91.752185 || 
    Epoch 09    --      4.570969 ||   0.0172 ||   0.0623 ||  0.511749 ||  0.514815 ||      4.572381 ||      0.0181 ||   0.0605 ||  0.516629 ||  0.511010 ||    90.967930 || 
    Epoch 10    --      4.560315 ||   0.0193 ||   0.0667 ||  0.515980 ||  0.520156 ||      4.561996 ||      0.0178 ||   0.0592 ||  0.524042 ||  0.516826 ||    91.563830 || 
    Epoch 11    --      4.546161 ||   0.0225 ||   0.0701 ||  0.521959 ||  0.527241 ||      4.544928 ||      0.0207 ||   0.0640 ||  0.523823 ||  0.517328 ||    90.982091 || 
    Epoch 12    --      4.532610 ||   0.0248 ||   0.0741 ||  0.525943 ||  0.531523 ||      4.525762 ||      0.0236 ||   0.0731 ||  0.538428 ||  0.533422 ||    91.249216 || 
    Epoch 13    --      4.518991 ||   0.0281 ||   0.0792 ||  0.531940 ||  0.538413 ||      4.516613 ||      0.0245 ||   0.0770 ||  0.535648 ||  0.529874 ||    91.186715 || 
    Epoch 14    --      4.507562 ||   0.0301 ||   0.0833 ||  0.536032 ||  0.543694 ||      4.502989 ||      0.0295 ||   0.0809 ||  0.543114 ||  0.541245 ||    92.039944 || 
    Epoch 15    --      4.484261 ||   0.0341 ||   0.0874 ||  0.543223 ||  0.551218 ||      4.485895 ||      0.0326 ||   0.0868 ||  0.546738 ||  0.546018 ||    91.311697 || 
    Epoch 16    --      4.475296 ||   0.0374 ||   0.0918 ||  0.547658 ||  0.556888 ||      4.471620 ||      0.0362 ||   0.0875 ||  0.549384 ||  0.549413 ||    90.858603 || 
    Epoch 17    --      4.452386 ||   0.0403 ||   0.0971 ||  0.554776 ||  0.563372 ||      4.467354 ||      0.0363 ||   0.0924 ||  0.555744 ||  0.559493 ||    91.033719 || 
    Epoch 18    --      4.438123 ||   0.0438 ||   0.1026 ||  0.557958 ||  0.567200 ||      4.468783 ||      0.0372 ||   0.0931 ||  0.554424 ||  0.556901 ||    91.233560 || 
    Epoch 19    --      4.421248 ||   0.0470 ||   0.1070 ||  0.563414 ||  0.574589 ||      4.413693 ||      0.0466 ||   0.1048 ||  0.566271 ||  0.570830 ||    91.030463 || 
    Epoch 20    --      4.406650 ||   0.0499 ||   0.1110 ||  0.567537 ||  0.578964 ||      4.414115 ||      0.0457 ||   0.1075 ||  0.573256 ||  0.577650 ||    90.733622 || 
    Epoch 21    --      4.383758 ||   0.0532 ||   0.1167 ||  0.573728 ||  0.585476 ||      4.397559 ||      0.0508 ||   0.1076 ||  0.571815 ||  0.576828 ||    91.624242 || 
    Epoch 22    --      4.364548 ||   0.0571 ||   0.1196 ||  0.577150 ||  0.589161 ||      4.351185 ||      0.0568 ||   0.1253 ||  0.587434 ||  0.595394 ||    90.905480 || 
    Epoch 23    --      4.353912 ||   0.0600 ||   0.1241 ||  0.578680 ||  0.592431 ||      4.337219 ||      0.0631 ||   0.1267 ||  0.590612 ||  0.597586 ||    91.061746 || 
    Epoch 24    --      4.335024 ||   0.0629 ||   0.1289 ||  0.586514 ||  0.599752 ||      4.341950 ||      0.0657 ||   0.1290 ||  0.592588 ||  0.601252 ||    90.803281 || 
    Epoch 25    --      4.314467 ||   0.0675 ||   0.1340 ||  0.591160 ||  0.605176 ||      4.361072 ||      0.0648 ||   0.1253 ||  0.585373 ||  0.591943 ||    91.280507 || 
    Epoch 26    --      4.307491 ||   0.0697 ||   0.1374 ||  0.590745 ||  0.605353 ||      4.276372 ||      0.0722 ||   0.1397 ||  0.603001 ||  0.609518 ||    91.358630 || 
    Epoch 27    --      4.283548 ||   0.0730 ||   0.1421 ||  0.596421 ||  0.610982 ||      4.280873 ||      0.0754 ||   0.1421 ||  0.605860 ||  0.616106 ||    91.061731 || 
    Epoch 28    --      4.259341 ||   0.0798 ||   0.1479 ||  0.604032 ||  0.619003 ||      4.321579 ||      0.0651 ||   0.1278 ||  0.587986 ||  0.595309 ||    91.296088 || 
    Epoch 29    --      4.243364 ||   0.0820 ||   0.1527 ||  0.606781 ||  0.622744 ||      4.249347 ||      0.0809 ||   0.1486 ||  0.612041 ||  0.622378 ||    90.702358 || 
    Epoch 30    --      4.234353 ||   0.0827 ||   0.1535 ||  0.607693 ||  0.624188 ||      4.226740 ||      0.0829 ||   0.1559 ||  0.616001 ||  0.624478 ||    91.264856 || 
    Epoch 31    --      4.211593 ||   0.0873 ||   0.1588 ||  0.613214 ||  0.630549 ||      4.202217 ||      0.0906 ||   0.1663 ||  0.624072 ||  0.634800 ||    91.046126 || 
    Epoch 32    --      4.197193 ||   0.0915 ||   0.1611 ||  0.615806 ||  0.632934 ||      4.200131 ||      0.0880 ||   0.1577 ||  0.616995 ||  0.628881 ||    91.327375 || 
    Epoch 33    --      4.186049 ||   0.0945 ||   0.1664 ||  0.619412 ||  0.636435 ||      4.169327 ||      0.0966 ||   0.1721 ||  0.628749 ||  0.639711 ||    91.108649 || 
    Epoch 34    --      4.162568 ||   0.0977 ||   0.1704 ||  0.623825 ||  0.641601 ||      4.174138 ||      0.0980 ||   0.1731 ||  0.630325 ||  0.642080 ||    90.777723 || 
    Epoch 35    --      4.139088 ||   0.1033 ||   0.1755 ||  0.626705 ||  0.644014 ||      4.149151 ||      0.0986 ||   0.1731 ||  0.632293 ||  0.644165 ||    91.956579 || 
    Epoch 36    --      4.129596 ||   0.1055 ||   0.1792 ||  0.629861 ||  0.648524 ||      4.128017 ||      0.1026 ||   0.1707 ||  0.631089 ||  0.641225 ||    90.837201 || 
    Epoch 37    --      4.104731 ||   0.1095 ||   0.1842 ||  0.635713 ||  0.653643 ||      4.154535 ||      0.1105 ||   0.1885 ||  0.647713 ||  0.662635 ||    91.436756 || 
    Epoch 38    --      4.092412 ||   0.1124 ||   0.1873 ||  0.638509 ||  0.657477 ||      4.074809 ||      0.1129 ||   0.1930 ||  0.645178 ||  0.657696 ||    91.233621 || 
    Epoch 39    --      4.087110 ||   0.1147 ||   0.1897 ||  0.638346 ||  0.657387 ||      4.087005 ||      0.1140 ||   0.1933 ||  0.648688 ||  0.661353 ||    91.468029 || 
    Epoch 40    --      4.061800 ||   0.1181 ||   0.1934 ||  0.644661 ||  0.663189 ||      4.045352 ||      0.1197 ||   0.1990 ||  0.651330 ||  0.664864 ||    90.831165 || 
    Epoch 41    --      4.053475 ||   0.1208 ||   0.1986 ||  0.645785 ||  0.665381 ||      4.027711 ||      0.1249 ||   0.1984 ||  0.657284 ||  0.667840 ||    91.905535 || 
    Epoch 42    --      4.034370 ||   0.1243 ||   0.2029 ||  0.651351 ||  0.670998 ||      4.064757 ||      0.1153 ||   0.1908 ||  0.648534 ||  0.660657 ||    91.202413 || 
    Epoch 43    --      4.032534 ||   0.1230 ||   0.2002 ||  0.649664 ||  0.669279 ||      4.009287 ||      0.1274 ||   0.2043 ||  0.654117 ||  0.666267 ||    91.311797 || 
    Epoch 44    --      4.011497 ||   0.1290 ||   0.2064 ||  0.653048 ||  0.672531 ||      4.008118 ||      0.1260 ||   0.2039 ||  0.657645 ||  0.673960 ||    91.139924 || 
    Epoch 45    --      4.014785 ||   0.1283 ||   0.2058 ||  0.653017 ||  0.673000 ||      4.013215 ||      0.1228 ||   0.2067 ||  0.657585 ||  0.671883 ||    91.046164 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
