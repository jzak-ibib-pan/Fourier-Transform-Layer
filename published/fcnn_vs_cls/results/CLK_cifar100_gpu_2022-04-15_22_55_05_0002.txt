Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.703609 ||   0.0260 ||   0.0910 ||  0.535468 ||  0.550409 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.605959 ||   0.0534 ||   0.1330 ||  0.560115 ||  0.561695 ||      4.605550 ||      0.0095 ||   0.0446 ||  0.501175 ||  0.487358 ||    17.345973 || 
    Epoch 01    --      4.603132 ||   0.0102 ||   0.0494 ||  0.496268 ||  0.497877 ||      4.603463 ||      0.0087 ||   0.0454 ||  0.501717 ||  0.492381 ||    16.442266 || 
    Epoch 02    --      4.601612 ||   0.0103 ||   0.0496 ||  0.494323 ||  0.496157 ||      4.602536 ||      0.0091 ||   0.0465 ||  0.502294 ||  0.488944 ||    16.203137 || 
    Epoch 03    --      4.597703 ||   0.0115 ||   0.0503 ||  0.496702 ||  0.499061 ||      4.598424 ||      0.0098 ||   0.0449 ||  0.504238 ||  0.491043 ||    16.098941 || 
    Epoch 04    --      4.597874 ||   0.0111 ||   0.0518 ||  0.496536 ||  0.499062 ||      4.600328 ||      0.0111 ||   0.0484 ||  0.506729 ||  0.496175 ||    16.257334 || 
    Epoch 05    --      4.592794 ||   0.0131 ||   0.0523 ||  0.499615 ||  0.501896 ||      4.589707 ||      0.0102 ||   0.0493 ||  0.507395 ||  0.497372 ||    16.372454 || 
    Epoch 06    --      4.587972 ||   0.0135 ||   0.0553 ||  0.502026 ||  0.504399 ||      4.603992 ||      0.0119 ||   0.0523 ||  0.512908 ||  0.501684 ||    16.072819 || 
    Epoch 07    --      4.583401 ||   0.0149 ||   0.0565 ||  0.504774 ||  0.507771 ||      4.577053 ||      0.0158 ||   0.0588 ||  0.517616 ||  0.505891 ||    16.067797 || 
    Epoch 08    --      4.574655 ||   0.0166 ||   0.0604 ||  0.507724 ||  0.511253 ||      4.590170 ||      0.0137 ||   0.0537 ||  0.513576 ||  0.502046 ||    16.029627 || 
    Epoch 09    --      4.569517 ||   0.0172 ||   0.0619 ||  0.511917 ||  0.515235 ||      4.584480 ||      0.0208 ||   0.0671 ||  0.526094 ||  0.522858 ||    16.669678 || 
    Epoch 10    --      4.561352 ||   0.0190 ||   0.0648 ||  0.513905 ||  0.517848 ||      4.561495 ||      0.0181 ||   0.0564 ||  0.518103 ||  0.509722 ||    15.932121 || 
    Epoch 11    --      4.552438 ||   0.0219 ||   0.0674 ||  0.517642 ||  0.522245 ||      4.549815 ||      0.0203 ||   0.0648 ||  0.526097 ||  0.518916 ||    16.309149 || 
    Epoch 12    --      4.543295 ||   0.0231 ||   0.0702 ||  0.520960 ||  0.526107 ||      4.538354 ||      0.0232 ||   0.0682 ||  0.531221 ||  0.523026 ||    16.557576 || 
    Epoch 13    --      4.532041 ||   0.0256 ||   0.0744 ||  0.525683 ||  0.531136 ||      4.524948 ||      0.0236 ||   0.0736 ||  0.532122 ||  0.524399 ||    16.219261 || 
    Epoch 14    --      4.523186 ||   0.0266 ||   0.0775 ||  0.529513 ||  0.535207 ||      4.513178 ||      0.0278 ||   0.0779 ||  0.539279 ||  0.535141 ||    16.125662 || 
    Epoch 15    --      4.500660 ||   0.0303 ||   0.0828 ||  0.536094 ||  0.542985 ||      4.521873 ||      0.0286 ||   0.0785 ||  0.536815 ||  0.534662 ||    16.343206 || 
    Epoch 16    --      4.497007 ||   0.0319 ||   0.0852 ||  0.538591 ||  0.546581 ||      4.490452 ||      0.0328 ||   0.0833 ||  0.545534 ||  0.545241 ||    16.270531 || 
    Epoch 17    --      4.475918 ||   0.0357 ||   0.0913 ||  0.547155 ||  0.555120 ||      4.483270 ||      0.0297 ||   0.0830 ||  0.547951 ||  0.550274 ||    16.019385 || 
    Epoch 18    --      4.456338 ||   0.0389 ||   0.0956 ||  0.550537 ||  0.559056 ||      4.496206 ||      0.0300 ||   0.0831 ||  0.548199 ||  0.551704 ||    16.139282 || 
    Epoch 19    --      4.449175 ||   0.0407 ||   0.0985 ||  0.555041 ||  0.564778 ||      4.446488 ||      0.0390 ||   0.0962 ||  0.558106 ||  0.562007 ||    16.194507 || 
    Epoch 20    --      4.430702 ||   0.0429 ||   0.1002 ||  0.558928 ||  0.570124 ||      4.430569 ||      0.0420 ||   0.1021 ||  0.566568 ||  0.569649 ||    16.390863 || 
    Epoch 21    --      4.417743 ||   0.0455 ||   0.1046 ||  0.561932 ||  0.572513 ||      4.439502 ||      0.0437 ||   0.0960 ||  0.552820 ||  0.555711 ||    16.331437 || 
    Epoch 22    --      4.402511 ||   0.0485 ||   0.1101 ||  0.566888 ||  0.578254 ||      4.418934 ||      0.0457 ||   0.1096 ||  0.571210 ||  0.578100 ||    16.181755 || 
    Epoch 23    --      4.387458 ||   0.0511 ||   0.1118 ||  0.569755 ||  0.581674 ||      4.370127 ||      0.0538 ||   0.1120 ||  0.579470 ||  0.584712 ||    16.410328 || 
    Epoch 24    --      4.375516 ||   0.0542 ||   0.1151 ||  0.575116 ||  0.587952 ||      4.362445 ||      0.0572 ||   0.1170 ||  0.580994 ||  0.587050 ||    15.932046 || 
    Epoch 25    --      4.360103 ||   0.0562 ||   0.1209 ||  0.578816 ||  0.591785 ||      4.385427 ||      0.0545 ||   0.1158 ||  0.576022 ||  0.579356 ||    16.195847 || 
    Epoch 26    --      4.351103 ||   0.0597 ||   0.1266 ||  0.580711 ||  0.594387 ||      4.367904 ||      0.0595 ||   0.1272 ||  0.588926 ||  0.594960 ||    16.210903 || 
    Epoch 27    --      4.333988 ||   0.0633 ||   0.1287 ||  0.586515 ||  0.600518 ||      4.305072 ||      0.0642 ||   0.1301 ||  0.593930 ||  0.604572 ||    16.567882 || 
    Epoch 28    --      4.310942 ||   0.0672 ||   0.1340 ||  0.590412 ||  0.604070 ||      4.312287 ||      0.0638 ||   0.1286 ||  0.594829 ||  0.603259 ||    16.188694 || 
    Epoch 29    --      4.299596 ||   0.0694 ||   0.1372 ||  0.593146 ||  0.606704 ||      4.282688 ||      0.0684 ||   0.1357 ||  0.600067 ||  0.609126 ||    16.089570 || 
    Epoch 30    --      4.280686 ||   0.0725 ||   0.1391 ||  0.595445 ||  0.611792 ||      4.263895 ||      0.0761 ||   0.1495 ||  0.608856 ||  0.619880 ||    16.392130 || 
    Epoch 31    --      4.265034 ||   0.0755 ||   0.1436 ||  0.599081 ||  0.615141 ||      4.279007 ||      0.0757 ||   0.1455 ||  0.602845 ||  0.613005 ||    16.392807 || 
    Epoch 32    --      4.253922 ||   0.0797 ||   0.1486 ||  0.602720 ||  0.618707 ||      4.274451 ||      0.0730 ||   0.1403 ||  0.603391 ||  0.614696 ||    16.039513 || 
    Epoch 33    --      4.241242 ||   0.0816 ||   0.1498 ||  0.605431 ||  0.621438 ||      4.233222 ||      0.0823 ||   0.1474 ||  0.610157 ||  0.618263 ||    16.085811 || 
    Epoch 34    --      4.228544 ||   0.0852 ||   0.1546 ||  0.609186 ||  0.625673 ||      4.262597 ||      0.0788 ||   0.1481 ||  0.609793 ||  0.620653 ||    16.555423 || 
    Epoch 35    --      4.204183 ||   0.0902 ||   0.1576 ||  0.613165 ||  0.629846 ||      4.302452 ||      0.0795 ||   0.1511 ||  0.608794 ||  0.620524 ||    15.975715 || 
    Epoch 36    --      4.186897 ||   0.0918 ||   0.1630 ||  0.616088 ||  0.634689 ||      4.208664 ||      0.0889 ||   0.1582 ||  0.616911 ||  0.627116 ||    16.361133 || 
    Epoch 37    --      4.179373 ||   0.0959 ||   0.1667 ||  0.619281 ||  0.636702 ||      4.179099 ||      0.0923 ||   0.1662 ||  0.622914 ||  0.637448 ||    16.018020 || 
    Epoch 38    --      4.164390 ||   0.0978 ||   0.1701 ||  0.621079 ||  0.639286 ||      4.178194 ||      0.0985 ||   0.1783 ||  0.629710 ||  0.643185 ||    16.504676 || 
    Epoch 39    --      4.153837 ||   0.1003 ||   0.1744 ||  0.625550 ||  0.643765 ||      4.278376 ||      0.0918 ||   0.1695 ||  0.620273 ||  0.634191 ||    15.993970 || 
    Epoch 40    --      4.127368 ||   0.1054 ||   0.1782 ||  0.629159 ||  0.647673 ||      4.109622 ||      0.1089 ||   0.1816 ||  0.636214 ||  0.652192 ||    16.404908 || 
    Epoch 41    --      4.128254 ||   0.1070 ||   0.1805 ||  0.630488 ||  0.649670 ||      4.120272 ||      0.1092 ||   0.1820 ||  0.639999 ||  0.651835 ||    16.071964 || 
    Epoch 42    --      4.112140 ||   0.1093 ||   0.1828 ||  0.632941 ||  0.653100 ||      4.118142 ||      0.1058 ||   0.1774 ||  0.633789 ||  0.643247 ||    16.183847 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
