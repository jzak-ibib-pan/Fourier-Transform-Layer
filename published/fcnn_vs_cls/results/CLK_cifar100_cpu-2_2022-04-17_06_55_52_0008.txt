Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.115006 ||   0.0278 ||   0.0952 ||  0.537303 ||  0.553745 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.606255 ||   0.0527 ||   0.1302 ||  0.558327 ||  0.560009 ||      4.605245 ||      0.0097 ||   0.0454 ||  0.502549 ||  0.489114 ||    90.764863 || 
    Epoch 01    --      4.602153 ||   0.0103 ||   0.0497 ||  0.496303 ||  0.498133 ||      4.602085 ||      0.0088 ||   0.0454 ||  0.502145 ||  0.493484 ||    89.936583 || 
    Epoch 02    --      4.600472 ||   0.0108 ||   0.0504 ||  0.494755 ||  0.496722 ||      4.601123 ||      0.0100 ||   0.0479 ||  0.504344 ||  0.491213 ||    89.983486 || 
    Epoch 03    --      4.596891 ||   0.0115 ||   0.0512 ||  0.497276 ||  0.499727 ||      4.594811 ||      0.0105 ||   0.0466 ||  0.506748 ||  0.493771 ||    90.780359 || 
    Epoch 04    --      4.594662 ||   0.0114 ||   0.0530 ||  0.498135 ||  0.500683 ||      4.594924 ||      0.0109 ||   0.0491 ||  0.506489 ||  0.496911 ||    93.514711 || 
    Epoch 05    --      4.589718 ||   0.0132 ||   0.0529 ||  0.500452 ||  0.502998 ||      4.581906 ||      0.0116 ||   0.0511 ||  0.510180 ||  0.501153 ||    91.358481 || 
    Epoch 06    --      4.584268 ||   0.0142 ||   0.0559 ||  0.502361 ||  0.504635 ||      4.585218 ||      0.0120 ||   0.0493 ||  0.509207 ||  0.496724 ||    90.811622 || 
    Epoch 07    --      4.578545 ||   0.0155 ||   0.0570 ||  0.504867 ||  0.507763 ||      4.574159 ||      0.0149 ||   0.0528 ||  0.512094 ||  0.499312 ||    91.561613 || 
    Epoch 08    --      4.573014 ||   0.0158 ||   0.0580 ||  0.505786 ||  0.509180 ||      4.574863 ||      0.0133 ||   0.0526 ||  0.512931 ||  0.501464 ||    91.378486 || 
    Epoch 09    --      4.570106 ||   0.0162 ||   0.0595 ||  0.508289 ||  0.511184 ||      4.559732 ||      0.0193 ||   0.0611 ||  0.517203 ||  0.512177 ||    91.389744 || 
    Epoch 10    --      4.561130 ||   0.0190 ||   0.0636 ||  0.511459 ||  0.515265 ||      4.555495 ||      0.0181 ||   0.0583 ||  0.518617 ||  0.509058 ||    91.389746 || 
    Epoch 11    --      4.555055 ||   0.0199 ||   0.0652 ||  0.515246 ||  0.519481 ||      4.563943 ||      0.0191 ||   0.0622 ||  0.522061 ||  0.512906 ||    91.655378 || 
    Epoch 12    --      4.545837 ||   0.0223 ||   0.0672 ||  0.517193 ||  0.521513 ||      4.541024 ||      0.0219 ||   0.0632 ||  0.522939 ||  0.514306 ||    91.310361 || 
    Epoch 13    --      4.535423 ||   0.0246 ||   0.0727 ||  0.520353 ||  0.525206 ||      4.534242 ||      0.0221 ||   0.0675 ||  0.524756 ||  0.517636 ||    91.231812 || 
    Epoch 14    --      4.523780 ||   0.0265 ||   0.0743 ||  0.524326 ||  0.529184 ||      4.565966 ||      0.0214 ||   0.0669 ||  0.522292 ||  0.517785 ||    91.022427 || 
    Epoch 15    --      4.510472 ||   0.0281 ||   0.0763 ||  0.528067 ||  0.533533 ||      4.534395 ||      0.0268 ||   0.0745 ||  0.536152 ||  0.532087 ||    90.794326 || 
    Epoch 16    --      4.501548 ||   0.0308 ||   0.0800 ||  0.531877 ||  0.538945 ||      4.514042 ||      0.0308 ||   0.0793 ||  0.537834 ||  0.532941 ||    91.435002 || 
    Epoch 17    --      4.489281 ||   0.0331 ||   0.0851 ||  0.537397 ||  0.543703 ||      4.505297 ||      0.0283 ||   0.0797 ||  0.538228 ||  0.537555 ||    91.466216 || 
    Epoch 18    --      4.477963 ||   0.0358 ||   0.0865 ||  0.539160 ||  0.545390 ||      4.487992 ||      0.0330 ||   0.0840 ||  0.542057 ||  0.541304 ||    91.060019 || 
    Epoch 19    --      4.469271 ||   0.0371 ||   0.0900 ||  0.542049 ||  0.549707 ||      4.471763 ||      0.0369 ||   0.0897 ||  0.549545 ||  0.549900 ||    91.229071 || 
    Epoch 20    --      4.454151 ||   0.0404 ||   0.0917 ||  0.547323 ||  0.555255 ||      4.444678 ||      0.0380 ||   0.0906 ||  0.555304 ||  0.556042 ||    91.417575 || 
    Epoch 21    --      4.442214 ||   0.0429 ||   0.0961 ||  0.550349 ||  0.558737 ||      4.436494 ||      0.0422 ||   0.0945 ||  0.555318 ||  0.555172 ||    91.330382 || 
    Epoch 22    --      4.427284 ||   0.0445 ||   0.0996 ||  0.555106 ||  0.563548 ||      4.420582 ||      0.0465 ||   0.1039 ||  0.561837 ||  0.564847 ||    90.919506 || 
    Epoch 23    --      4.416814 ||   0.0481 ||   0.1047 ||  0.556902 ||  0.566255 ||      4.410949 ||      0.0475 ||   0.1005 ||  0.564333 ||  0.566064 ||    92.731970 || 
    Epoch 24    --      4.410740 ||   0.0489 ||   0.1046 ||  0.558742 ||  0.568232 ||      4.393080 ||      0.0518 ||   0.1068 ||  0.567647 ||  0.569272 ||    93.389184 || 
    Epoch 25    --      4.386457 ||   0.0533 ||   0.1095 ||  0.566127 ||  0.575847 ||      4.403003 ||      0.0495 ||   0.1053 ||  0.566608 ||  0.567619 ||    92.466363 || 
    Epoch 26    --      4.379381 ||   0.0563 ||   0.1145 ||  0.568984 ||  0.578766 ||      4.358200 ||      0.0578 ||   0.1147 ||  0.577872 ||  0.579648 ||    91.364033 || 
    Epoch 27    --      4.368006 ||   0.0581 ||   0.1179 ||  0.571573 ||  0.581590 ||      4.331721 ||      0.0627 ||   0.1211 ||  0.581133 ||  0.586035 ||    90.997706 || 
    Epoch 28    --      4.340997 ||   0.0643 ||   0.1246 ||  0.579070 ||  0.589298 ||      4.340891 ||      0.0615 ||   0.1205 ||  0.581729 ||  0.586510 ||    91.747679 || 
    Epoch 29    --      4.319916 ||   0.0681 ||   0.1303 ||  0.584184 ||  0.596323 ||      4.327278 ||      0.0638 ||   0.1233 ||  0.587767 ||  0.593141 ||    91.263385 || 
    Epoch 30    --      4.310826 ||   0.0694 ||   0.1324 ||  0.586859 ||  0.599545 ||      4.295758 ||      0.0720 ||   0.1408 ||  0.596147 ||  0.602188 ||    91.341490 || 
    Epoch 31    --      4.286706 ||   0.0733 ||   0.1372 ||  0.591684 ||  0.605083 ||      4.352387 ||      0.0720 ||   0.1378 ||  0.592217 ||  0.599131 ||    91.029024 || 
    Epoch 32    --      4.270883 ||   0.0784 ||   0.1429 ||  0.597401 ||  0.610890 ||      4.295535 ||      0.0747 ||   0.1387 ||  0.596451 ||  0.605286 ||    91.279077 || 
    Epoch 33    --      4.247773 ||   0.0809 ||   0.1457 ||  0.602293 ||  0.616562 ||      4.246125 ||      0.0820 ||   0.1428 ||  0.603225 ||  0.608510 ||    91.279074 || 
    Epoch 34    --      4.237263 ||   0.0854 ||   0.1521 ||  0.604770 ||  0.619458 ||      4.234467 ||      0.0837 ||   0.1487 ||  0.610987 ||  0.619046 ||    91.206563 || 
    Epoch 35    --      4.214931 ||   0.0901 ||   0.1586 ||  0.610239 ||  0.625397 ||      4.277905 ||      0.0766 ||   0.1454 ||  0.599939 ||  0.608051 ||    90.950973 || 
    Epoch 36    --      4.198316 ||   0.0917 ||   0.1615 ||  0.613028 ||  0.629705 ||      4.177303 ||      0.0916 ||   0.1639 ||  0.627668 ||  0.636452 ||    91.888490 || 
    Epoch 37    --      4.167785 ||   0.0965 ||   0.1686 ||  0.620352 ||  0.636641 ||      4.254549 ||      0.0881 ||   0.1620 ||  0.621036 ||  0.632993 ||    91.013510 || 
    Epoch 38    --      4.159285 ||   0.0989 ||   0.1709 ||  0.624435 ||  0.640838 ||      4.203160 ||      0.0932 ||   0.1716 ||  0.623590 ||  0.635689 ||    91.370582 || 
    Epoch 39    --      4.143937 ||   0.1020 ||   0.1750 ||  0.628655 ||  0.645928 ||      4.148131 ||      0.1001 ||   0.1687 ||  0.627080 ||  0.635647 ||    90.977878 || 
    Epoch 40    --      4.127877 ||   0.1058 ||   0.1801 ||  0.631065 ||  0.647514 ||      4.128498 ||      0.1046 ||   0.1824 ||  0.638701 ||  0.652802 ||    91.154142 || 
    Epoch 41    --      4.109160 ||   0.1118 ||   0.1854 ||  0.634496 ||  0.653368 ||      4.147267 ||      0.1051 ||   0.1785 ||  0.636748 ||  0.647337 ||    91.263545 || 
    Epoch 42    --      4.101333 ||   0.1107 ||   0.1852 ||  0.637015 ||  0.655820 ||      4.079377 ||      0.1101 ||   0.1888 ||  0.647092 ||  0.658757 ||    91.156212 || 
    Epoch 43    --      4.092452 ||   0.1128 ||   0.1887 ||  0.638569 ||  0.657526 ||      4.068998 ||      0.1146 ||   0.1899 ||  0.645847 ||  0.658154 ||    91.826078 || 
    Epoch 44    --      4.066652 ||   0.1178 ||   0.1931 ||  0.642347 ||  0.661717 ||      4.077910 ||      0.1133 ||   0.1870 ||  0.642635 ||  0.657184 ||    90.935501 || 
    Epoch 45    --      4.065819 ||   0.1177 ||   0.1922 ||  0.644629 ||  0.663840 ||      4.080977 ||      0.1116 ||   0.1916 ||  0.646449 ||  0.657401 ||    91.169919 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
