Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.488245 ||   0.0263 ||   0.0926 ||  0.535052 ||  0.551067 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.608347 ||   0.0511 ||   0.1300 ||  0.559007 ||  0.560472 ||      4.606943 ||      0.0091 ||   0.0444 ||  0.500600 ||  0.486552 ||    18.051242 || 
    Epoch 01    --      4.606845 ||   0.0099 ||   0.0487 ||  0.495016 ||  0.496471 ||      4.605334 ||      0.0085 ||   0.0447 ||  0.501355 ||  0.492463 ||    16.351840 || 
    Epoch 02    --      4.601807 ||   0.0105 ||   0.0495 ||  0.494758 ||  0.496487 ||      4.605053 ||      0.0096 ||   0.0474 ||  0.502236 ||  0.488554 ||    16.390817 || 
    Epoch 03    --      4.598214 ||   0.0117 ||   0.0515 ||  0.498221 ||  0.500559 ||      4.596258 ||      0.0109 ||   0.0487 ||  0.506454 ||  0.492646 ||    16.268598 || 
    Epoch 04    --      4.593482 ||   0.0122 ||   0.0532 ||  0.499013 ||  0.501802 ||      4.589399 ||      0.0122 ||   0.0514 ||  0.509835 ||  0.501195 ||    16.416968 || 
    Epoch 05    --      4.589711 ||   0.0142 ||   0.0547 ||  0.502588 ||  0.505316 ||      4.585330 ||      0.0120 ||   0.0509 ||  0.509007 ||  0.500630 ||    16.006703 || 
    Epoch 06    --      4.583969 ||   0.0147 ||   0.0578 ||  0.504255 ||  0.506984 ||      4.585997 ||      0.0118 ||   0.0521 ||  0.513180 ||  0.500497 ||    16.464570 || 
    Epoch 07    --      4.579817 ||   0.0160 ||   0.0591 ||  0.507254 ||  0.510973 ||      4.574996 ||      0.0139 ||   0.0560 ||  0.516832 ||  0.504693 ||    16.458833 || 
    Epoch 08    --      4.569421 ||   0.0174 ||   0.0608 ||  0.510730 ||  0.514818 ||      4.576295 ||      0.0147 ||   0.0545 ||  0.513494 ||  0.503592 ||    16.456269 || 
    Epoch 09    --      4.563056 ||   0.0181 ||   0.0641 ||  0.514292 ||  0.518182 ||      4.565886 ||      0.0180 ||   0.0640 ||  0.524958 ||  0.520579 ||    16.332579 || 
    Epoch 10    --      4.553556 ||   0.0197 ||   0.0675 ||  0.517279 ||  0.521983 ||      4.556032 ||      0.0187 ||   0.0602 ||  0.522178 ||  0.516337 ||    16.382828 || 
    Epoch 11    --      4.543220 ||   0.0224 ||   0.0698 ||  0.520928 ||  0.526562 ||      4.540822 ||      0.0198 ||   0.0635 ||  0.525699 ||  0.519703 ||    16.491197 || 
    Epoch 12    --      4.534544 ||   0.0247 ||   0.0720 ||  0.522972 ||  0.528274 ||      4.527659 ||      0.0234 ||   0.0694 ||  0.531131 ||  0.525709 ||    16.615021 || 
    Epoch 13    --      4.523406 ||   0.0268 ||   0.0781 ||  0.529760 ||  0.536123 ||      4.520013 ||      0.0244 ||   0.0749 ||  0.534529 ||  0.529872 ||    16.522565 || 
    Epoch 14    --      4.506695 ||   0.0296 ||   0.0806 ||  0.532624 ||  0.539765 ||      4.511981 ||      0.0260 ||   0.0763 ||  0.536182 ||  0.535632 ||    16.293289 || 
    Epoch 15    --      4.496713 ||   0.0320 ||   0.0837 ||  0.536278 ||  0.543972 ||      4.507821 ||      0.0291 ||   0.0798 ||  0.538649 ||  0.537084 ||    15.988418 || 
    Epoch 16    --      4.488816 ||   0.0337 ||   0.0852 ||  0.539536 ||  0.548309 ||      4.466012 ||      0.0335 ||   0.0897 ||  0.552196 ||  0.552631 ||    16.312936 || 
    Epoch 17    --      4.469250 ||   0.0375 ||   0.0927 ||  0.545569 ||  0.553364 ||      4.488250 ||      0.0313 ||   0.0809 ||  0.544653 ||  0.547776 ||    16.389535 || 
    Epoch 18    --      4.454354 ||   0.0406 ||   0.0962 ||  0.550110 ||  0.558295 ||      4.469755 ||      0.0334 ||   0.0889 ||  0.549678 ||  0.553261 ||    16.509773 || 
    Epoch 19    --      4.442868 ||   0.0430 ||   0.0995 ||  0.553196 ||  0.562842 ||      4.439942 ||      0.0423 ||   0.0987 ||  0.557929 ||  0.561253 ||    16.183984 || 
    Epoch 20    --      4.423099 ||   0.0462 ||   0.1027 ||  0.560814 ||  0.571423 ||      4.441927 ||      0.0400 ||   0.0951 ||  0.558072 ||  0.560366 ||    16.168942 || 
    Epoch 21    --      4.410879 ||   0.0491 ||   0.1077 ||  0.564986 ||  0.575383 ||      4.444313 ||      0.0450 ||   0.0975 ||  0.556400 ||  0.559027 ||    16.169409 || 
    Epoch 22    --      4.391349 ||   0.0529 ||   0.1106 ||  0.567533 ||  0.578144 ||      4.406338 ||      0.0485 ||   0.1060 ||  0.564433 ||  0.569341 ||    16.319385 || 
    Epoch 23    --      4.374489 ||   0.0556 ||   0.1167 ||  0.571259 ||  0.583969 ||      4.360299 ||      0.0560 ||   0.1136 ||  0.581138 ||  0.587231 ||    16.120853 || 
    Epoch 24    --      4.362309 ||   0.0587 ||   0.1189 ||  0.575112 ||  0.586962 ||      4.370646 ||      0.0579 ||   0.1196 ||  0.579506 ||  0.586381 ||    16.287476 || 
    Epoch 25    --      4.337905 ||   0.0631 ||   0.1242 ||  0.580241 ||  0.592509 ||      4.355369 ||      0.0570 ||   0.1206 ||  0.583209 ||  0.589241 ||    16.490779 || 
    Epoch 26    --      4.323133 ||   0.0664 ||   0.1308 ||  0.584872 ||  0.598452 ||      4.303889 ||      0.0669 ||   0.1279 ||  0.595441 ||  0.600206 ||    16.031824 || 
    Epoch 27    --      4.315922 ||   0.0689 ||   0.1333 ||  0.587995 ||  0.601073 ||      4.283587 ||      0.0706 ||   0.1363 ||  0.595522 ||  0.603252 ||    16.480197 || 
    Epoch 28    --      4.288294 ||   0.0731 ||   0.1393 ||  0.594015 ||  0.607319 ||      4.298194 ||      0.0686 ||   0.1373 ||  0.600439 ||  0.608238 ||    16.178589 || 
    Epoch 29    --      4.275809 ||   0.0768 ||   0.1434 ||  0.597268 ||  0.611366 ||      4.277782 ||      0.0717 ||   0.1366 ||  0.596046 ||  0.604255 ||    16.256740 || 
    Epoch 30    --      4.254767 ||   0.0790 ||   0.1473 ||  0.599094 ||  0.614795 ||      4.269889 ||      0.0775 ||   0.1481 ||  0.606028 ||  0.613651 ||    16.199951 || 
    Epoch 31    --      4.248149 ||   0.0819 ||   0.1488 ||  0.602280 ||  0.617696 ||      4.254283 ||      0.0829 ||   0.1461 ||  0.604198 ||  0.611281 ||    16.297906 || 
    Epoch 32    --      4.229629 ||   0.0852 ||   0.1542 ||  0.608973 ||  0.623339 ||      4.236379 ||      0.0832 ||   0.1519 ||  0.605589 ||  0.615738 ||    15.895320 || 
    Epoch 33    --      4.205129 ||   0.0906 ||   0.1581 ||  0.611448 ||  0.627217 ||      4.259295 ||      0.0802 ||   0.1508 ||  0.613708 ||  0.621693 ||    16.520402 || 
    Epoch 34    --      4.193274 ||   0.0913 ||   0.1599 ||  0.615595 ||  0.631321 ||      4.193330 ||      0.0886 ||   0.1597 ||  0.620338 ||  0.630314 ||    16.037473 || 
    Epoch 35    --      4.176579 ||   0.0957 ||   0.1670 ||  0.619301 ||  0.635549 ||      4.180059 ||      0.0947 ||   0.1616 ||  0.615645 ||  0.624784 ||    16.240037 || 
    Epoch 36    --      4.172477 ||   0.0991 ||   0.1706 ||  0.620803 ||  0.638588 ||      4.161344 ||      0.0967 ||   0.1656 ||  0.625460 ||  0.634663 ||    16.466313 || 
    Epoch 37    --      4.139667 ||   0.1034 ||   0.1773 ||  0.625828 ||  0.643219 ||      4.171215 ||      0.0958 ||   0.1647 ||  0.625250 ||  0.639942 ||    16.158172 || 
    Epoch 38    --      4.131630 ||   0.1038 ||   0.1760 ||  0.627058 ||  0.644971 ||      4.118435 ||      0.1052 ||   0.1793 ||  0.632082 ||  0.642855 ||    16.429283 || 
    Epoch 39    --      4.121961 ||   0.1068 ||   0.1801 ||  0.629999 ||  0.647992 ||      4.122560 ||      0.1079 ||   0.1803 ||  0.636586 ||  0.646534 ||    16.260466 || 
    Epoch 40    --      4.110149 ||   0.1105 ||   0.1822 ||  0.633621 ||  0.650981 ||      4.203882 ||      0.1033 ||   0.1825 ||  0.634715 ||  0.650195 ||    16.502725 || 
    Epoch 41    --      4.104010 ||   0.1115 ||   0.1848 ||  0.633979 ||  0.652433 ||      4.082549 ||      0.1122 ||   0.1848 ||  0.644109 ||  0.653275 ||    16.288700 || 
    Epoch 42    --      4.090837 ||   0.1147 ||   0.1885 ||  0.638980 ||  0.657201 ||      4.079182 ||      0.1116 ||   0.1839 ||  0.643276 ||  0.654046 ||    16.104987 || 
    Epoch 43    --      4.079505 ||   0.1150 ||   0.1884 ||  0.636419 ||  0.655043 ||      4.098799 ||      0.1096 ||   0.1839 ||  0.641023 ||  0.653297 ||    16.150722 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
