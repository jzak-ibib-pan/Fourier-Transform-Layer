Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --     12.256708 ||   0.2248 ||   0.4662 ||  0.705129 ||  0.706063 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      3.919793 ||   0.1413 ||   0.3483 ||  0.792465 ||  0.799602 ||      3.591078 ||      0.1924 ||   0.4289 ||  0.844249 ||  0.845499 ||   118.779145 || 
    Epoch 01    --      2.949368 ||   0.3169 ||   0.5890 ||  0.899696 ||  0.904837 ||      3.052709 ||      0.2955 ||   0.5675 ||  0.899789 ||  0.898497 ||   118.685375 || 
    Epoch 02    --      2.208649 ||   0.4762 ||   0.7294 ||  0.945748 ||  0.948551 ||      2.387928 ||      0.4353 ||   0.6915 ||  0.943017 ||  0.940638 ||   117.357340 || 
    Epoch 03    --      1.600689 ||   0.6172 ||   0.8283 ||  0.970659 ||  0.972156 ||      1.776887 ||      0.5768 ||   0.8034 ||  0.964016 ||  0.963728 ||   117.418844 || 
    Epoch 04    --      1.135628 ||   0.7252 ||   0.8904 ||  0.984731 ||  0.985587 ||      1.203082 ||      0.7090 ||   0.8897 ||  0.983451 ||  0.983627 ||   117.515882 || 
    Epoch 05    --      0.806145 ||   0.8040 ||   0.9317 ||  0.991321 ||  0.991850 ||      0.890331 ||      0.7813 ||   0.9237 ||  0.989666 ||  0.989835 ||   117.857352 || 
    Epoch 06    --      0.589588 ||   0.8576 ||   0.9565 ||  0.994778 ||  0.995077 ||      0.725672 ||      0.8247 ||   0.9407 ||  0.992739 ||  0.992730 ||   118.368969 || 
    Epoch 07    --      0.444117 ||   0.8921 ||   0.9706 ||  0.996675 ||  0.996883 ||      0.548974 ||      0.8688 ||   0.9635 ||  0.996033 ||  0.995978 ||   117.630230 || 
    Epoch 08    --      0.321144 ||   0.9222 ||   0.9821 ||  0.998247 ||  0.998380 ||      0.358713 ||      0.9069 ||   0.9809 ||  0.997823 ||  0.997773 ||   117.595001 || 
    Epoch 09    --      0.254828 ||   0.9395 ||   0.9882 ||  0.998493 ||  0.998588 ||      0.353836 ||      0.9107 ||   0.9848 ||  0.997470 ||  0.997429 ||   117.498078 || 
    Epoch 10    --      0.209268 ||   0.9508 ||   0.9920 ||  0.998632 ||  0.998689 ||      0.268411 ||      0.9386 ||   0.9900 ||  0.997896 ||  0.997838 ||   118.623713 || 
    Epoch 11    --      0.172761 ||   0.9602 ||   0.9937 ||  0.998937 ||  0.998989 ||      0.202551 ||      0.9485 ||   0.9954 ||  0.998449 ||  0.998446 ||   117.813010 || 
    Epoch 12    --      0.142928 ||   0.9662 ||   0.9956 ||  0.999129 ||  0.999164 ||      0.130938 ||      0.9718 ||   0.9965 ||  0.999196 ||  0.999240 ||   117.716886 || 
    Epoch 13    --      0.125546 ||   0.9711 ||   0.9963 ||  0.999185 ||  0.999220 ||      0.108930 ||      0.9742 ||   0.9978 ||  0.999231 ||  0.999224 ||   117.830491 || 
    Epoch 14    --      0.112456 ||   0.9746 ||   0.9973 ||  0.999126 ||  0.999146 ||      0.188202 ||      0.9565 ||   0.9957 ||  0.998897 ||  0.998866 ||   118.232520 || 
    Epoch 15    --      0.108192 ||   0.9759 ||   0.9978 ||  0.999336 ||  0.999358 ||      0.102506 ||      0.9771 ||   0.9981 ||  0.999193 ||  0.999232 ||   117.790260 || 
    Epoch 16    --      0.092779 ||   0.9793 ||   0.9981 ||  0.999289 ||  0.999310 ||      0.087154 ||      0.9818 ||   0.9989 ||  0.999148 ||  0.999147 ||   118.564266 || 
    Epoch 17    --      0.091473 ||   0.9794 ||   0.9981 ||  0.999220 ||  0.999239 ||      0.123898 ||      0.9704 ||   0.9981 ||  0.999099 ||  0.999098 ||   117.873175 || 
    Epoch 18    --      0.081785 ||   0.9824 ||   0.9984 ||  0.999467 ||  0.999478 ||      0.078673 ||      0.9818 ||   0.9987 ||  0.999297 ||  0.999300 ||   117.715364 || 
Layers list:
	conv2d                                   -                      (5, 5, 3, 41)|(41,)
	conv2d-filters                           -                                       41
	conv2d-kernel_size                       -                                        5
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                      (32144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 28, 28, 41)        3116      
_________________________________________________________________
flatten_2 (Flatten)          (None, 32144)             0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               3214500   
=================================================================
Total params: 3,217,616
Trainable params: 3,217,616
Non-trainable params: 0
_________________________________________________________________
