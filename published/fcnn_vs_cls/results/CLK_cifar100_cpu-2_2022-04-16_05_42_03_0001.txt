Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.466202 ||   0.0279 ||   0.0927 ||  0.539512 ||  0.553762 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607014 ||   0.0518 ||   0.1316 ||  0.561768 ||  0.563323 ||      4.605806 ||      0.0095 ||   0.0447 ||  0.500765 ||  0.487093 ||    91.937815 || 
    Epoch 01    --      4.603472 ||   0.0099 ||   0.0488 ||  0.495014 ||  0.496739 ||      4.603377 ||      0.0088 ||   0.0454 ||  0.501677 ||  0.492111 ||    90.162293 || 
    Epoch 02    --      4.601811 ||   0.0104 ||   0.0501 ||  0.494865 ||  0.496645 ||      4.603263 ||      0.0100 ||   0.0462 ||  0.501271 ||  0.487541 ||    90.983390 || 
    Epoch 03    --      4.597954 ||   0.0118 ||   0.0513 ||  0.497138 ||  0.499571 ||      4.595294 ||      0.0112 ||   0.0468 ||  0.504975 ||  0.492445 ||    91.139665 || 
    Epoch 04    --      4.594749 ||   0.0121 ||   0.0538 ||  0.498943 ||  0.501502 ||      4.586254 ||      0.0121 ||   0.0540 ||  0.511303 ||  0.501914 ||    90.405282 || 
    Epoch 05    --      4.589394 ||   0.0140 ||   0.0547 ||  0.502544 ||  0.505126 ||      4.583848 ||      0.0115 ||   0.0508 ||  0.509629 ||  0.500320 ||    90.670908 || 
    Epoch 06    --      4.582635 ||   0.0154 ||   0.0582 ||  0.506309 ||  0.509060 ||      4.617378 ||      0.0137 ||   0.0571 ||  0.516681 ||  0.505428 ||    91.436591 || 
    Epoch 07    --      4.575667 ||   0.0161 ||   0.0592 ||  0.507455 ||  0.510863 ||      4.573072 ||      0.0157 ||   0.0581 ||  0.515960 ||  0.502731 ||    90.670974 || 
    Epoch 08    --      4.566158 ||   0.0182 ||   0.0616 ||  0.511303 ||  0.515221 ||      4.564351 ||      0.0163 ||   0.0603 ||  0.520518 ||  0.511987 ||    90.410137 || 
    Epoch 09    --      4.563584 ||   0.0192 ||   0.0655 ||  0.515696 ||  0.519398 ||      4.548564 ||      0.0207 ||   0.0668 ||  0.524513 ||  0.519427 ||    91.453905 || 
    Epoch 10    --      4.548530 ||   0.0217 ||   0.0692 ||  0.518947 ||  0.523481 ||      4.551048 ||      0.0189 ||   0.0621 ||  0.523887 ||  0.515432 ||    90.952214 || 
    Epoch 11    --      4.538210 ||   0.0237 ||   0.0723 ||  0.523497 ||  0.529347 ||      4.535894 ||      0.0202 ||   0.0648 ||  0.529207 ||  0.522524 ||    90.436619 || 
    Epoch 12    --      4.527636 ||   0.0256 ||   0.0748 ||  0.526134 ||  0.532150 ||      4.530836 ||      0.0246 ||   0.0709 ||  0.532064 ||  0.526554 ||    90.367409 || 
    Epoch 13    --      4.519104 ||   0.0285 ||   0.0793 ||  0.531176 ||  0.537558 ||      4.526080 ||      0.0254 ||   0.0733 ||  0.534520 ||  0.529565 ||    91.655330 || 
    Epoch 14    --      4.512032 ||   0.0296 ||   0.0812 ||  0.533951 ||  0.540985 ||      4.503854 ||      0.0309 ||   0.0779 ||  0.536694 ||  0.535363 ||    92.186621 || 
    Epoch 15    --      4.491804 ||   0.0324 ||   0.0839 ||  0.537106 ||  0.545124 ||      4.517553 ||      0.0296 ||   0.0783 ||  0.537005 ||  0.536406 ||    90.920961 || 
    Epoch 16    --      4.480989 ||   0.0352 ||   0.0874 ||  0.540165 ||  0.548930 ||      4.474489 ||      0.0360 ||   0.0890 ||  0.553712 ||  0.554076 ||    90.421040 || 
    Epoch 17    --      4.469773 ||   0.0384 ||   0.0932 ||  0.545701 ||  0.553901 ||      4.481787 ||      0.0329 ||   0.0838 ||  0.545485 ||  0.548784 ||    90.734138 || 
    Epoch 18    --      4.455173 ||   0.0406 ||   0.0960 ||  0.549229 ||  0.557854 ||      4.455599 ||      0.0376 ||   0.0929 ||  0.554189 ||  0.557052 ||    90.811662 || 
    Epoch 19    --      4.441942 ||   0.0428 ||   0.0984 ||  0.552877 ||  0.562933 ||      4.448340 ||      0.0412 ||   0.0962 ||  0.556168 ||  0.559509 ||    91.233539 || 
    Epoch 20    --      4.434892 ||   0.0441 ||   0.0997 ||  0.554989 ||  0.565663 ||      4.439282 ||      0.0411 ||   0.0955 ||  0.557680 ||  0.561801 ||    90.279045 || 
    Epoch 21    --      4.421296 ||   0.0461 ||   0.1036 ||  0.558505 ||  0.569582 ||      4.436267 ||      0.0475 ||   0.1011 ||  0.560612 ||  0.564170 ||    91.153678 || 
    Epoch 22    --      4.404606 ||   0.0499 ||   0.1072 ||  0.562825 ||  0.574328 ||      4.426068 ||      0.0434 ||   0.1056 ||  0.562864 ||  0.568599 ||    90.653719 || 
    Epoch 23    --      4.392386 ||   0.0541 ||   0.1141 ||  0.566372 ||  0.579134 ||      4.431271 ||      0.0484 ||   0.1067 ||  0.568255 ||  0.573347 ||    92.028754 || 
    Epoch 24    --      4.376842 ||   0.0560 ||   0.1154 ||  0.571535 ||  0.583488 ||      4.371206 ||      0.0566 ||   0.1156 ||  0.575622 ||  0.584053 ||    90.341368 || 
    Epoch 25    --      4.360623 ||   0.0586 ||   0.1189 ||  0.575662 ||  0.588463 ||      4.363963 ||      0.0550 ||   0.1147 ||  0.574166 ||  0.579966 ||    90.856979 || 
    Epoch 26    --      4.347483 ||   0.0622 ||   0.1260 ||  0.577743 ||  0.592099 ||      4.331273 ||      0.0639 ||   0.1239 ||  0.583023 ||  0.585903 ||    91.122626 || 
    Epoch 27    --      4.333684 ||   0.0646 ||   0.1285 ||  0.582609 ||  0.595826 ||      4.320875 ||      0.0646 ||   0.1311 ||  0.594587 ||  0.603512 ||    90.919606 || 
    Epoch 28    --      4.310747 ||   0.0695 ||   0.1330 ||  0.587538 ||  0.601003 ||      4.357110 ||      0.0627 ||   0.1277 ||  0.588782 ||  0.596489 ||    90.169577 || 
    Epoch 29    --      4.307271 ||   0.0721 ||   0.1374 ||  0.591405 ||  0.605173 ||      4.276750 ||      0.0732 ||   0.1382 ||  0.601583 ||  0.611283 ||    90.772834 || 
    Epoch 30    --      4.276537 ||   0.0754 ||   0.1416 ||  0.595833 ||  0.611850 ||      4.260947 ||      0.0772 ||   0.1447 ||  0.600546 ||  0.609731 ||    90.716602 || 
    Epoch 31    --      4.262667 ||   0.0786 ||   0.1446 ||  0.599612 ||  0.615394 ||      4.247921 ||      0.0775 ||   0.1464 ||  0.603463 ||  0.614413 ||    90.779107 || 
    Epoch 32    --      4.236184 ||   0.0829 ||   0.1515 ||  0.606254 ||  0.621598 ||      4.251241 ||      0.0799 ||   0.1483 ||  0.606054 ||  0.618608 ||    90.876297 || 
    Epoch 33    --      4.228836 ||   0.0845 ||   0.1523 ||  0.608876 ||  0.624806 ||      4.238364 ||      0.0859 ||   0.1514 ||  0.609885 ||  0.618281 ||    90.482307 || 
    Epoch 34    --      4.211696 ||   0.0888 ||   0.1593 ||  0.614139 ||  0.630414 ||      4.201685 ||      0.0866 ||   0.1578 ||  0.619538 ||  0.628912 ||    90.622931 || 
    Epoch 35    --      4.181563 ||   0.0953 ||   0.1648 ||  0.619427 ||  0.636034 ||      4.200749 ||      0.0881 ||   0.1584 ||  0.620687 ||  0.631113 ||    90.763592 || 
    Epoch 36    --      4.167809 ||   0.0971 ||   0.1687 ||  0.620955 ||  0.639136 ||      4.170195 ||      0.0949 ||   0.1653 ||  0.625126 ||  0.633451 ||    90.169848 || 
    Epoch 37    --      4.151224 ||   0.1012 ||   0.1736 ||  0.624723 ||  0.642222 ||      4.180851 ||      0.0969 ||   0.1685 ||  0.627715 ||  0.640856 ||    90.763693 || 
    Epoch 38    --      4.147529 ||   0.1021 ||   0.1738 ||  0.627365 ||  0.645055 ||      4.108658 ||      0.1058 ||   0.1810 ||  0.638408 ||  0.650912 ||    90.628895 || 
    Epoch 39    --      4.115201 ||   0.1071 ||   0.1813 ||  0.633334 ||  0.651799 ||      4.121449 ||      0.1037 ||   0.1765 ||  0.636561 ||  0.646327 ||    91.279268 || 
    Epoch 40    --      4.115606 ||   0.1069 ||   0.1809 ||  0.632488 ||  0.649090 ||      4.103856 ||      0.1063 ||   0.1798 ||  0.634117 ||  0.646740 ||    90.201267 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
