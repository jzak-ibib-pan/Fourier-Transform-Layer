Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.685238 ||   0.0268 ||   0.0940 ||  0.536006 ||  0.551753 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607639 ||   0.0518 ||   0.1306 ||  0.556394 ||  0.557973 ||      4.607036 ||      0.0090 ||   0.0439 ||  0.500045 ||  0.485811 ||    18.177031 || 
    Epoch 01    --      4.606124 ||   0.0095 ||   0.0483 ||  0.493597 ||  0.495085 ||      4.603985 ||      0.0087 ||   0.0457 ||  0.501842 ||  0.492512 ||    16.235199 || 
    Epoch 02    --      4.602985 ||   0.0103 ||   0.0490 ||  0.493673 ||  0.495273 ||      4.604279 ||      0.0089 ||   0.0462 ||  0.501422 ||  0.487283 ||    16.100298 || 
    Epoch 03    --      4.601770 ||   0.0110 ||   0.0487 ||  0.495233 ||  0.497409 ||      4.600228 ||      0.0098 ||   0.0447 ||  0.503356 ||  0.489329 ||    16.690995 || 
    Epoch 04    --      4.598811 ||   0.0109 ||   0.0507 ||  0.495470 ||  0.497819 ||      4.597069 ||      0.0108 ||   0.0464 ||  0.503911 ||  0.494615 ||    16.151584 || 
    Epoch 05    --      4.596117 ||   0.0119 ||   0.0500 ||  0.497345 ||  0.499545 ||      4.594512 ||      0.0104 ||   0.0480 ||  0.505248 ||  0.494645 ||    16.375125 || 
    Epoch 06    --      4.591400 ||   0.0129 ||   0.0527 ||  0.498506 ||  0.500435 ||      4.593637 ||      0.0099 ||   0.0471 ||  0.505443 ||  0.492511 ||    16.354248 || 
    Epoch 07    --      4.589938 ||   0.0136 ||   0.0532 ||  0.501526 ||  0.503895 ||      4.587338 ||      0.0127 ||   0.0495 ||  0.507745 ||  0.493448 ||    16.317483 || 
    Epoch 08    --      4.583123 ||   0.0148 ||   0.0556 ||  0.502195 ||  0.505229 ||      4.586755 ||      0.0131 ||   0.0526 ||  0.511298 ||  0.500310 ||    16.169647 || 
    Epoch 09    --      4.578547 ||   0.0150 ||   0.0581 ||  0.506363 ||  0.508959 ||      4.569439 ||      0.0172 ||   0.0594 ||  0.516110 ||  0.509516 ||    16.320487 || 
    Epoch 10    --      4.569874 ||   0.0170 ||   0.0612 ||  0.508941 ||  0.512629 ||      4.574616 ||      0.0154 ||   0.0559 ||  0.517979 ||  0.508267 ||    16.271439 || 
    Epoch 11    --      4.565297 ||   0.0182 ||   0.0632 ||  0.511048 ||  0.515001 ||      4.561417 ||      0.0169 ||   0.0590 ||  0.520427 ||  0.512266 ||    16.293925 || 
    Epoch 12    --      4.553720 ||   0.0208 ||   0.0669 ||  0.514508 ||  0.518421 ||      4.556112 ||      0.0185 ||   0.0604 ||  0.520122 ||  0.510632 ||    16.060340 || 
    Epoch 13    --      4.544018 ||   0.0234 ||   0.0711 ||  0.518681 ||  0.522827 ||      4.548172 ||      0.0203 ||   0.0654 ||  0.525137 ||  0.516051 ||    16.322621 || 
    Epoch 14    --      4.531850 ||   0.0250 ||   0.0748 ||  0.521625 ||  0.526166 ||      4.533744 ||      0.0232 ||   0.0702 ||  0.527593 ||  0.521851 ||    16.241188 || 
    Epoch 15    --      4.525753 ||   0.0264 ||   0.0739 ||  0.524902 ||  0.530081 ||      4.523720 ||      0.0259 ||   0.0719 ||  0.532344 ||  0.527265 ||    16.070374 || 
    Epoch 16    --      4.511014 ||   0.0291 ||   0.0786 ||  0.530335 ||  0.536539 ||      4.501354 ||      0.0296 ||   0.0798 ||  0.540403 ||  0.534022 ||    16.084301 || 
    Epoch 17    --      4.500571 ||   0.0322 ||   0.0827 ||  0.535856 ||  0.541325 ||      4.514621 ||      0.0259 ||   0.0734 ||  0.532784 ||  0.529748 ||    16.319600 || 
    Epoch 18    --      4.481090 ||   0.0340 ||   0.0873 ||  0.539171 ||  0.545454 ||      4.494574 ||      0.0311 ||   0.0797 ||  0.537627 ||  0.537121 ||    15.905866 || 
    Epoch 19    --      4.472816 ||   0.0365 ||   0.0889 ||  0.541963 ||  0.549263 ||      4.464006 ||      0.0369 ||   0.0903 ||  0.553313 ||  0.554003 ||    15.959361 || 
    Epoch 20    --      4.461773 ||   0.0388 ||   0.0927 ||  0.548220 ||  0.556923 ||      4.477750 ||      0.0371 ||   0.0903 ||  0.551616 ||  0.553860 ||    16.395271 || 
    Epoch 21    --      4.449041 ||   0.0419 ||   0.0966 ||  0.552280 ||  0.561454 ||      4.437142 ||      0.0417 ||   0.0961 ||  0.559056 ||  0.561162 ||    16.348382 || 
    Epoch 22    --      4.429545 ||   0.0451 ||   0.1010 ||  0.557317 ||  0.567458 ||      4.452880 ||      0.0387 ||   0.0940 ||  0.553226 ||  0.556246 ||    16.703174 || 
    Epoch 23    --      4.416471 ||   0.0473 ||   0.1057 ||  0.559197 ||  0.570186 ||      4.411248 ||      0.0481 ||   0.1005 ||  0.560078 ||  0.563510 ||    16.207438 || 
    Epoch 24    --      4.399465 ||   0.0509 ||   0.1088 ||  0.564676 ||  0.575630 ||      4.393362 ||      0.0504 ||   0.1060 ||  0.569655 ||  0.576111 ||    16.373413 || 
    Epoch 25    --      4.382274 ||   0.0539 ||   0.1125 ||  0.569730 ||  0.581547 ||      4.372294 ||      0.0511 ||   0.1117 ||  0.573542 ||  0.578780 ||    16.166225 || 
    Epoch 26    --      4.368205 ||   0.0573 ||   0.1183 ||  0.572200 ||  0.585485 ||      4.347060 ||      0.0580 ||   0.1157 ||  0.580735 ||  0.583539 ||    16.397338 || 
    Epoch 27    --      4.359846 ||   0.0586 ||   0.1197 ||  0.574042 ||  0.587325 ||      4.377849 ||      0.0564 ||   0.1227 ||  0.579523 ||  0.586326 ||    16.199469 || 
    Epoch 28    --      4.340509 ||   0.0626 ||   0.1241 ||  0.577893 ||  0.591026 ||      4.384012 ||      0.0541 ||   0.1163 ||  0.577284 ||  0.583445 ||    16.485614 || 
    Epoch 29    --      4.329613 ||   0.0656 ||   0.1294 ||  0.581091 ||  0.595123 ||      4.366703 ||      0.0602 ||   0.1198 ||  0.576318 ||  0.582370 ||    16.164889 || 
    Epoch 30    --      4.320886 ||   0.0668 ||   0.1297 ||  0.582819 ||  0.597448 ||      4.302175 ||      0.0702 ||   0.1364 ||  0.593331 ||  0.604059 ||    16.119495 || 
    Epoch 31    --      4.302824 ||   0.0693 ||   0.1318 ||  0.586184 ||  0.601173 ||      4.309078 ||      0.0723 ||   0.1391 ||  0.593848 ||  0.601460 ||    16.487201 || 
    Epoch 32    --      4.298595 ||   0.0722 ||   0.1366 ||  0.588895 ||  0.602890 ||      4.315990 ||      0.0666 ||   0.1319 ||  0.589556 ||  0.601675 ||    16.438107 || 
    Epoch 33    --      4.278946 ||   0.0751 ||   0.1388 ||  0.592845 ||  0.608213 ||      4.303526 ||      0.0724 ||   0.1315 ||  0.590156 ||  0.597254 ||    16.262842 || 
    Epoch 34    --      4.263221 ||   0.0797 ||   0.1426 ||  0.595731 ||  0.612485 ||      4.264246 ||      0.0774 ||   0.1399 ||  0.600027 ||  0.608567 ||    16.287492 || 
    Epoch 35    --      4.245856 ||   0.0841 ||   0.1479 ||  0.601190 ||  0.616985 ||      4.260143 ||      0.0766 ||   0.1384 ||  0.599299 ||  0.607925 ||    16.464042 || 
    Epoch 36    --      4.228965 ||   0.0859 ||   0.1526 ||  0.603049 ||  0.620578 ||      4.237619 ||      0.0846 ||   0.1491 ||  0.609022 ||  0.616566 ||    16.011648 || 
    Epoch 37    --      4.215797 ||   0.0879 ||   0.1556 ||  0.605365 ||  0.622047 ||      4.233572 ||      0.0850 ||   0.1538 ||  0.613572 ||  0.626014 ||    16.351861 || 
    Epoch 38    --      4.208109 ||   0.0883 ||   0.1573 ||  0.606177 ||  0.623692 ||      4.272847 ||      0.0885 ||   0.1586 ||  0.611017 ||  0.621399 ||    15.899853 || 
    Epoch 39    --      4.195760 ||   0.0932 ||   0.1609 ||  0.611533 ||  0.628541 ||      4.286088 ||      0.0799 ||   0.1485 ||  0.599267 ||  0.607435 ||    16.257648 || 
    Epoch 40    --      4.180272 ||   0.0956 ||   0.1629 ||  0.613241 ||  0.630611 ||      4.174816 ||      0.0949 ||   0.1653 ||  0.620434 ||  0.632269 ||    16.268603 || 
    Epoch 41    --      4.170748 ||   0.0983 ||   0.1683 ||  0.616632 ||  0.635080 ||      4.143499 ||      0.1001 ||   0.1644 ||  0.624595 ||  0.632712 ||    16.211437 || 
    Epoch 42    --      4.155135 ||   0.1018 ||   0.1694 ||  0.619352 ||  0.638606 ||      4.168396 ||      0.0996 ||   0.1678 ||  0.624216 ||  0.634945 ||    16.184056 || 
    Epoch 43    --      4.152090 ||   0.1018 ||   0.1683 ||  0.620260 ||  0.638678 ||      4.137889 ||      0.1015 ||   0.1734 ||  0.626812 ||  0.639350 ||    16.219446 || 
    Epoch 44    --      4.139929 ||   0.1039 ||   0.1746 ||  0.622953 ||  0.641958 ||      4.196378 ||      0.0994 ||   0.1713 ||  0.624803 ||  0.638527 ||    16.019988 || 
    Epoch 45    --      4.133551 ||   0.1060 ||   0.1746 ||  0.623237 ||  0.642642 ||      4.204540 ||      0.0909 ||   0.1664 ||  0.617064 ||  0.629844 ||    16.232464 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
