Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.945424 ||   0.0286 ||   0.0961 ||  0.536630 ||  0.552680 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.606977 ||   0.0499 ||   0.1267 ||  0.558009 ||  0.559533 ||      4.606994 ||      0.0090 ||   0.0442 ||  0.500156 ||  0.485912 ||    18.045294 || 
    Epoch 01    --      4.605008 ||   0.0096 ||   0.0487 ||  0.494595 ||  0.496295 ||      4.603364 ||      0.0084 ||   0.0456 ||  0.502723 ||  0.493411 ||    16.200863 || 
    Epoch 02    --      4.603266 ||   0.0103 ||   0.0497 ||  0.494130 ||  0.495946 ||      4.603679 ||      0.0090 ||   0.0465 ||  0.501446 ||  0.487973 ||    16.463476 || 
    Epoch 03    --      4.599435 ||   0.0112 ||   0.0492 ||  0.496079 ||  0.498339 ||      4.601065 ||      0.0103 ||   0.0472 ||  0.506131 ||  0.493110 ||    16.342002 || 
    Epoch 04    --      4.598559 ||   0.0110 ||   0.0519 ||  0.495823 ||  0.498152 ||      4.595955 ||      0.0102 ||   0.0481 ||  0.506417 ||  0.496485 ||    15.912341 || 
    Epoch 05    --      4.594594 ||   0.0122 ||   0.0508 ||  0.498402 ||  0.500824 ||      4.591285 ||      0.0108 ||   0.0494 ||  0.506710 ||  0.497667 ||    16.186558 || 
    Epoch 06    --      4.588614 ||   0.0136 ||   0.0547 ||  0.500137 ||  0.502229 ||      4.589117 ||      0.0116 ||   0.0497 ||  0.508445 ||  0.496156 ||    16.386025 || 
    Epoch 07    --      4.584934 ||   0.0147 ||   0.0557 ||  0.503638 ||  0.506447 ||      4.577564 ||      0.0142 ||   0.0521 ||  0.511599 ||  0.497315 ||    16.131815 || 
    Epoch 08    --      4.577218 ||   0.0157 ||   0.0584 ||  0.506069 ||  0.509148 ||      4.575294 ||      0.0143 ||   0.0527 ||  0.511963 ||  0.501421 ||    16.374458 || 
    Epoch 09    --      4.571122 ||   0.0167 ||   0.0609 ||  0.509871 ||  0.513042 ||      4.574688 ||      0.0184 ||   0.0616 ||  0.516758 ||  0.511269 ||    16.527495 || 
    Epoch 10    --      4.562571 ||   0.0190 ||   0.0648 ||  0.512754 ||  0.517033 ||      4.560159 ||      0.0188 ||   0.0580 ||  0.517940 ||  0.508814 ||    16.294849 || 
    Epoch 11    --      4.555229 ||   0.0202 ||   0.0665 ||  0.515226 ||  0.520040 ||      4.551147 ||      0.0186 ||   0.0607 ||  0.521828 ||  0.513482 ||    16.422895 || 
    Epoch 12    --      4.542796 ||   0.0240 ||   0.0705 ||  0.519213 ||  0.524387 ||      4.537823 ||      0.0215 ||   0.0649 ||  0.527434 ||  0.520683 ||    16.353510 || 
    Epoch 13    --      4.533731 ||   0.0256 ||   0.0734 ||  0.523307 ||  0.528966 ||      4.536404 ||      0.0231 ||   0.0702 ||  0.524862 ||  0.517913 ||    16.381165 || 
    Epoch 14    --      4.517725 ||   0.0278 ||   0.0755 ||  0.526565 ||  0.533095 ||      4.517712 ||      0.0274 ||   0.0761 ||  0.535611 ||  0.532513 ||    16.137151 || 
    Epoch 15    --      4.506331 ||   0.0301 ||   0.0786 ||  0.531002 ||  0.537786 ||      4.518529 ||      0.0296 ||   0.0788 ||  0.538870 ||  0.535520 ||    16.176693 || 
    Epoch 16    --      4.495117 ||   0.0322 ||   0.0828 ||  0.536057 ||  0.543838 ||      4.477584 ||      0.0353 ||   0.0831 ||  0.544185 ||  0.541849 ||    16.613229 || 
    Epoch 17    --      4.476568 ||   0.0362 ||   0.0892 ||  0.542216 ||  0.549550 ||      4.495855 ||      0.0290 ||   0.0773 ||  0.540717 ||  0.539883 ||    16.306782 || 
    Epoch 18    --      4.462364 ||   0.0389 ||   0.0918 ||  0.546466 ||  0.554022 ||      4.471024 ||      0.0355 ||   0.0889 ||  0.549613 ||  0.551854 ||    16.402152 || 
    Epoch 19    --      4.453895 ||   0.0398 ||   0.0956 ||  0.549501 ||  0.558492 ||      4.431866 ||      0.0424 ||   0.0995 ||  0.562464 ||  0.564444 ||    16.408606 || 
    Epoch 20    --      4.436920 ||   0.0439 ||   0.0983 ||  0.555573 ||  0.564804 ||      4.452336 ||      0.0430 ||   0.0970 ||  0.555332 ||  0.557109 ||    16.251342 || 
    Epoch 21    --      4.423404 ||   0.0470 ||   0.1048 ||  0.560144 ||  0.569658 ||      4.412906 ||      0.0476 ||   0.1034 ||  0.565427 ||  0.567125 ||    16.193903 || 
    Epoch 22    --      4.403610 ||   0.0503 ||   0.1085 ||  0.564456 ||  0.574859 ||      4.445815 ||      0.0421 ||   0.1004 ||  0.563541 ||  0.567404 ||    16.300094 || 
    Epoch 23    --      4.391492 ||   0.0522 ||   0.1129 ||  0.566060 ||  0.577852 ||      4.388366 ||      0.0512 ||   0.1083 ||  0.573243 ||  0.577323 ||    16.082553 || 
    Epoch 24    --      4.369070 ||   0.0564 ||   0.1166 ||  0.573928 ||  0.584895 ||      4.400111 ||      0.0553 ||   0.1128 ||  0.572721 ||  0.579946 ||    16.322114 || 
    Epoch 25    --      4.353682 ||   0.0597 ||   0.1222 ||  0.578161 ||  0.589747 ||      4.362797 ||      0.0570 ||   0.1175 ||  0.578437 ||  0.582396 ||    16.025592 || 
    Epoch 26    --      4.344302 ||   0.0617 ||   0.1251 ||  0.578630 ||  0.591281 ||      4.322716 ||      0.0669 ||   0.1295 ||  0.594011 ||  0.598464 ||    16.091686 || 
    Epoch 27    --      4.323101 ||   0.0668 ||   0.1314 ||  0.585926 ||  0.598410 ||      4.294567 ||      0.0691 ||   0.1355 ||  0.595931 ||  0.604858 ||    16.365566 || 
    Epoch 28    --      4.302640 ||   0.0703 ||   0.1351 ||  0.591481 ||  0.604117 ||      4.302098 ||      0.0694 ||   0.1329 ||  0.595699 ||  0.601941 ||    16.486230 || 
    Epoch 29    --      4.279688 ||   0.0741 ||   0.1412 ||  0.596259 ||  0.609872 ||      4.319901 ||      0.0706 ||   0.1349 ||  0.593251 ||  0.601146 ||    16.482883 || 
    Epoch 30    --      4.265740 ||   0.0764 ||   0.1449 ||  0.599878 ||  0.615415 ||      4.264364 ||      0.0776 ||   0.1470 ||  0.606817 ||  0.616047 ||    16.309507 || 
    Epoch 31    --      4.248312 ||   0.0799 ||   0.1486 ||  0.604062 ||  0.619496 ||      4.327515 ||      0.0785 ||   0.1479 ||  0.600662 ||  0.610092 ||    16.363494 || 
    Epoch 32    --      4.221613 ||   0.0848 ||   0.1533 ||  0.609635 ||  0.624485 ||      4.255818 ||      0.0786 ||   0.1506 ||  0.608170 ||  0.621237 ||    16.184637 || 
    Epoch 33    --      4.211916 ||   0.0891 ||   0.1574 ||  0.611796 ||  0.627676 ||      4.206173 ||      0.0872 ||   0.1628 ||  0.621322 ||  0.629165 ||    16.611812 || 
    Epoch 34    --      4.195323 ||   0.0910 ||   0.1614 ||  0.615179 ||  0.631429 ||      4.209973 ||      0.0875 ||   0.1552 ||  0.612463 ||  0.620683 ||    16.155939 || 
    Epoch 35    --      4.171870 ||   0.0961 ||   0.1676 ||  0.620798 ||  0.637205 ||      4.194006 ||      0.0898 ||   0.1567 ||  0.618601 ||  0.627084 ||    16.570868 || 
    Epoch 36    --      4.163343 ||   0.0980 ||   0.1685 ||  0.620820 ||  0.639421 ||      4.148872 ||      0.0984 ||   0.1685 ||  0.631056 ||  0.639471 ||    16.234750 || 
    Epoch 37    --      4.139803 ||   0.1029 ||   0.1767 ||  0.626121 ||  0.644137 ||      4.166678 ||      0.0960 ||   0.1647 ||  0.623771 ||  0.635957 ||    16.176762 || 
    Epoch 38    --      4.129416 ||   0.1040 ||   0.1788 ||  0.630310 ||  0.648405 ||      4.138214 ||      0.1016 ||   0.1769 ||  0.632822 ||  0.644796 ||    16.448954 || 
    Epoch 39    --      4.112205 ||   0.1071 ||   0.1830 ||  0.633515 ||  0.651994 ||      4.149692 ||      0.1097 ||   0.1854 ||  0.641821 ||  0.654687 ||    16.366867 || 
    Epoch 40    --      4.100670 ||   0.1096 ||   0.1851 ||  0.635837 ||  0.653336 ||      4.066310 ||      0.1150 ||   0.1911 ||  0.648393 ||  0.665407 ||    16.559238 || 
    Epoch 41    --      4.074969 ||   0.1163 ||   0.1908 ||  0.640409 ||  0.659985 ||      4.079746 ||      0.1116 ||   0.1867 ||  0.644642 ||  0.657009 ||    16.020376 || 
    Epoch 42    --      4.077005 ||   0.1151 ||   0.1898 ||  0.641951 ||  0.661441 ||      4.064065 ||      0.1158 ||   0.1923 ||  0.646415 ||  0.658649 ||    16.319805 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
