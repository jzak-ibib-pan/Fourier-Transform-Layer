Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                       10
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.3
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      2.138445 ||   0.2709 ||   0.8319 ||  0.757502 ||  0.758251 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      2.124631 ||   0.2721 ||   0.7823 ||  0.725015 ||  0.731341 ||      2.081952 ||      0.2020 ||   0.7507 ||  0.713527 ||  0.706828 ||    17.428857 || 
    Epoch 01    --      2.121407 ||   0.2051 ||   0.7317 ||  0.675344 ||  0.688411 ||      2.049812 ||      0.2518 ||   0.8126 ||  0.743275 ||  0.739734 ||    15.711664 || 
    Epoch 02    --      2.022473 ||   0.2412 ||   0.8019 ||  0.728761 ||  0.737695 ||      1.960421 ||      0.2674 ||   0.8232 ||  0.752103 ||  0.758052 ||    15.344175 || 
    Epoch 03    --      1.989377 ||   0.2493 ||   0.8140 ||  0.739382 ||  0.747322 ||      1.952703 ||      0.2724 ||   0.8365 ||  0.756317 ||  0.762000 ||    15.721239 || 
    Epoch 04    --      1.982044 ||   0.2512 ||   0.8179 ||  0.742319 ||  0.749543 ||      1.964280 ||      0.2436 ||   0.8090 ||  0.750242 ||  0.750135 ||    15.277362 || 
    Epoch 05    --      1.974361 ||   0.2567 ||   0.8158 ||  0.744813 ||  0.751856 ||      1.967779 ||      0.2483 ||   0.8173 ||  0.746624 ||  0.750541 ||    15.491964 || 
    Epoch 06    --      1.966120 ||   0.2566 ||   0.8240 ||  0.747501 ||  0.754145 ||      1.941401 ||      0.2597 ||   0.8238 ||  0.753191 ||  0.758745 ||    15.327471 || 
    Epoch 07    --      1.967817 ||   0.2569 ||   0.8192 ||  0.747143 ||  0.753418 ||      2.028982 ||      0.2227 ||   0.7692 ||  0.736564 ||  0.721171 ||    15.892458 || 
    Epoch 08    --      1.969536 ||   0.2575 ||   0.8191 ||  0.746049 ||  0.753347 ||      1.915571 ||      0.2711 ||   0.8380 ||  0.762980 ||  0.768142 ||    15.810850 || 
    Epoch 09    --      1.964192 ||   0.2589 ||   0.8217 ||  0.748595 ||  0.755191 ||      1.976649 ||      0.2762 ||   0.8369 ||  0.763627 ||  0.762931 ||    15.268252 || 
    Epoch 10    --      1.947485 ||   0.2633 ||   0.8290 ||  0.752732 ||  0.759716 ||      2.014600 ||      0.2759 ||   0.8241 ||  0.759828 ||  0.756444 ||    15.371337 || 
    Epoch 11    --      1.960433 ||   0.2607 ||   0.8199 ||  0.749112 ||  0.755885 ||      1.922473 ||      0.2663 ||   0.8462 ||  0.762511 ||  0.767869 ||    15.793081 || 
    Epoch 12    --      1.950477 ||   0.2630 ||   0.8257 ||  0.752156 ||  0.759291 ||      1.949084 ||      0.2552 ||   0.8083 ||  0.755057 ||  0.752833 ||    15.729050 || 
    Epoch 13    --      1.950614 ||   0.2626 ||   0.8263 ||  0.752259 ||  0.759443 ||      1.918193 ||      0.2650 ||   0.8383 ||  0.762993 ||  0.767775 ||    15.514708 || 
    Epoch 14    --      1.946354 ||   0.2610 ||   0.8273 ||  0.753169 ||  0.760323 ||      1.933329 ||      0.2508 ||   0.8268 ||  0.758962 ||  0.760255 ||    15.815614 || 
    Epoch 15    --      1.940378 ||   0.2668 ||   0.8263 ||  0.755551 ||  0.761414 ||      1.933579 ||      0.2551 ||   0.8261 ||  0.757561 ||  0.760702 ||    15.941141 || 
    Epoch 16    --      1.938337 ||   0.2667 ||   0.8310 ||  0.756447 ||  0.762915 ||      1.942122 ||      0.2595 ||   0.8233 ||  0.754011 ||  0.756234 ||    15.483034 || 
    Epoch 17    --      1.936764 ||   0.2697 ||   0.8310 ||  0.756651 ||  0.763432 ||      1.993079 ||      0.2351 ||   0.7908 ||  0.746478 ||  0.737654 ||    15.922611 || 
    Epoch 18    --      1.936327 ||   0.2679 ||   0.8300 ||  0.757100 ||  0.763330 ||      2.016799 ||      0.2259 ||   0.7853 ||  0.740698 ||  0.728146 ||    15.452634 || 
    Epoch 19    --      1.932984 ||   0.2684 ||   0.8323 ||  0.757993 ||  0.764749 ||      1.910972 ||      0.2653 ||   0.8398 ||  0.763988 ||  0.767986 ||    15.517583 || 
    Epoch 20    --      1.929841 ||   0.2708 ||   0.8323 ||  0.759518 ||  0.766064 ||      1.887169 ||      0.2869 ||   0.8510 ||  0.772499 ||  0.778766 ||    15.999347 || 
    Epoch 21    --      1.934996 ||   0.2673 ||   0.8292 ||  0.757945 ||  0.764075 ||      1.985224 ||      0.2320 ||   0.7968 ||  0.747382 ||  0.740261 ||    15.927993 || 
    Epoch 22    --      1.924706 ||   0.2694 ||   0.8339 ||  0.760292 ||  0.766636 ||      1.933452 ||      0.2548 ||   0.8280 ||  0.756725 ||  0.758875 ||    15.923968 || 
    Epoch 23    --      1.926324 ||   0.2742 ||   0.8328 ||  0.760946 ||  0.766872 ||      1.919582 ||      0.2617 ||   0.8307 ||  0.761065 ||  0.764225 ||    15.855313 || 
    Epoch 24    --      1.920869 ||   0.2742 ||   0.8352 ||  0.761953 ||  0.768133 ||      1.929488 ||      0.2559 ||   0.8315 ||  0.761198 ||  0.761859 ||    15.796418 || 
    Epoch 25    --      1.917825 ||   0.2726 ||   0.8365 ||  0.762490 ||  0.768582 ||      1.924522 ||      0.2899 ||   0.8488 ||  0.773339 ||  0.777456 ||    15.471400 || 
    Epoch 26    --      1.918897 ||   0.2760 ||   0.8351 ||  0.762687 ||  0.768601 ||      1.919644 ||      0.2589 ||   0.8296 ||  0.760965 ||  0.764229 ||    15.773707 || 
    Epoch 27    --      1.922037 ||   0.2716 ||   0.8347 ||  0.761337 ||  0.767712 ||      1.892421 ||      0.2693 ||   0.8358 ||  0.767789 ||  0.771492 ||    16.142583 || 
    Epoch 28    --      1.915924 ||   0.2746 ||   0.8360 ||  0.763174 ||  0.769627 ||      1.872648 ||      0.2885 ||   0.8546 ||  0.775895 ||  0.782856 ||    15.788115 || 
    Epoch 29    --      1.919611 ||   0.2744 ||   0.8321 ||  0.762084 ||  0.768250 ||      1.944161 ||      0.2907 ||   0.8480 ||  0.772973 ||  0.773155 ||    15.895545 || 
    Epoch 30    --      1.911327 ||   0.2754 ||   0.8358 ||  0.764007 ||  0.770541 ||      1.876980 ||      0.2868 ||   0.8499 ||  0.773026 ||  0.779214 ||    15.786539 || 
    Epoch 31    --      1.912210 ||   0.2740 ||   0.8372 ||  0.763533 ||  0.770162 ||      1.937522 ||      0.2561 ||   0.8123 ||  0.758966 ||  0.756002 ||    15.628850 || 
    Epoch 32    --      1.911988 ||   0.2750 ||   0.8365 ||  0.764145 ||  0.770228 ||      1.892540 ||      0.2769 ||   0.8452 ||  0.769465 ||  0.776053 ||    15.645911 || 
    Epoch 33    --      1.906708 ||   0.2774 ||   0.8365 ||  0.764418 ||  0.771020 ||      1.889194 ||      0.2876 ||   0.8535 ||  0.776541 ||  0.780157 ||    15.582799 || 
    Epoch 34    --      1.906315 ||   0.2773 ||   0.8386 ||  0.766119 ||  0.772100 ||      1.939938 ||      0.2908 ||   0.8464 ||  0.772403 ||  0.773418 ||    15.922240 || 
    Epoch 35    --      1.902039 ||   0.2779 ||   0.8387 ||  0.765761 ||  0.772315 ||      1.904665 ||      0.2863 ||   0.8527 ||  0.782000 ||  0.782654 ||    15.922917 || 
    Epoch 36    --      1.903248 ||   0.2785 ||   0.8379 ||  0.766033 ||  0.772598 ||      1.888640 ||      0.2688 ||   0.8390 ||  0.773339 ||  0.774407 ||    15.594571 || 
    Epoch 37    --      1.902462 ||   0.2783 ||   0.8386 ||  0.767253 ||  0.773108 ||      1.937223 ||      0.2513 ||   0.8120 ||  0.761439 ||  0.753898 ||    15.664685 || 
    Epoch 38    --      1.901718 ||   0.2779 ||   0.8389 ||  0.766832 ||  0.773250 ||      1.911567 ||      0.3029 ||   0.8514 ||  0.780474 ||  0.781207 ||    15.614779 || 
    Epoch 39    --      1.899459 ||   0.2776 ||   0.8394 ||  0.767543 ||  0.773831 ||      1.874412 ||      0.2839 ||   0.8392 ||  0.772650 ||  0.775356 ||    16.027643 || 
    Epoch 40    --      1.895666 ||   0.2835 ||   0.8408 ||  0.769622 ||  0.775548 ||      1.870512 ||      0.2811 ||   0.8455 ||  0.774741 ||  0.780172 ||    15.511281 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 20)|(20,)
	conv2d-filters                           -                                       20
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                         (5120, 10)|(10,)
	dense_2-units                            -                                       10
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 20)        17360     
_________________________________________________________________
flatten_2 (Flatten)          (None, 5120)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                51210     
=================================================================
Total params: 68,570
Trainable params: 68,570
Non-trainable params: 0
_________________________________________________________________
