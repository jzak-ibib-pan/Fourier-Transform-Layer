Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.692131 ||   0.0251 ||   0.0900 ||  0.534493 ||  0.549091 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607258 ||   0.0527 ||   0.1327 ||  0.560857 ||  0.562391 ||      4.607010 ||      0.0090 ||   0.0438 ||  0.500002 ||  0.485735 ||    17.481271 || 
    Epoch 01    --      4.605628 ||   0.0094 ||   0.0482 ||  0.493804 ||  0.495256 ||      4.604259 ||      0.0084 ||   0.0447 ||  0.500881 ||  0.491570 ||    16.153048 || 
    Epoch 02    --      4.603805 ||   0.0099 ||   0.0494 ||  0.493671 ||  0.495397 ||      4.604207 ||      0.0094 ||   0.0465 ||  0.501489 ||  0.487003 ||    16.026848 || 
    Epoch 03    --      4.600678 ||   0.0111 ||   0.0493 ||  0.495395 ||  0.497722 ||      4.598089 ||      0.0098 ||   0.0462 ||  0.504370 ||  0.490432 ||    16.075312 || 
    Epoch 04    --      4.598516 ||   0.0109 ||   0.0514 ||  0.495721 ||  0.498125 ||      4.595036 ||      0.0106 ||   0.0474 ||  0.505195 ||  0.494826 ||    16.332427 || 
    Epoch 05    --      4.595951 ||   0.0124 ||   0.0508 ||  0.498465 ||  0.500653 ||      4.596417 ||      0.0098 ||   0.0475 ||  0.504908 ||  0.494993 ||    16.459157 || 
    Epoch 06    --      4.591059 ||   0.0130 ||   0.0542 ||  0.500165 ||  0.502282 ||      4.592175 ||      0.0112 ||   0.0498 ||  0.509890 ||  0.497577 ||    16.238934 || 
    Epoch 07    --      4.587403 ||   0.0143 ||   0.0548 ||  0.502307 ||  0.504806 ||      4.580237 ||      0.0135 ||   0.0533 ||  0.513304 ||  0.499595 ||    16.210762 || 
    Epoch 08    --      4.577069 ||   0.0155 ||   0.0575 ||  0.506502 ||  0.509557 ||      4.581859 ||      0.0128 ||   0.0531 ||  0.512804 ||  0.501541 ||    16.431126 || 
    Epoch 09    --      4.573316 ||   0.0166 ||   0.0600 ||  0.509637 ||  0.512531 ||      4.564538 ||      0.0182 ||   0.0602 ||  0.518517 ||  0.511974 ||    16.364671 || 
    Epoch 10    --      4.562232 ||   0.0194 ||   0.0663 ||  0.516744 ||  0.521004 ||      4.562711 ||      0.0175 ||   0.0586 ||  0.522023 ||  0.513694 ||    16.468173 || 
    Epoch 11    --      4.548759 ||   0.0208 ||   0.0677 ||  0.519123 ||  0.523870 ||      4.547972 ||      0.0194 ||   0.0621 ||  0.523777 ||  0.514149 ||    16.084337 || 
    Epoch 12    --      4.534975 ||   0.0247 ||   0.0728 ||  0.523807 ||  0.528778 ||      4.534032 ||      0.0213 ||   0.0668 ||  0.531421 ||  0.525222 ||    16.407681 || 
    Epoch 13    --      4.521039 ||   0.0281 ||   0.0779 ||  0.529546 ||  0.536008 ||      4.516170 ||      0.0244 ||   0.0771 ||  0.537545 ||  0.531954 ||    16.305772 || 
    Epoch 14    --      4.512247 ||   0.0288 ||   0.0789 ||  0.533084 ||  0.539839 ||      4.495376 ||      0.0311 ||   0.0796 ||  0.542151 ||  0.540832 ||    16.251400 || 
    Epoch 15    --      4.494544 ||   0.0307 ||   0.0837 ||  0.539063 ||  0.546285 ||      4.502942 ||      0.0296 ||   0.0809 ||  0.542685 ||  0.542662 ||    16.028468 || 
    Epoch 16    --      4.481859 ||   0.0341 ||   0.0888 ||  0.542353 ||  0.550867 ||      4.488023 ||      0.0319 ||   0.0808 ||  0.545335 ||  0.544403 ||    16.438768 || 
    Epoch 17    --      4.463040 ||   0.0370 ||   0.0931 ||  0.548060 ||  0.556184 ||      4.473773 ||      0.0325 ||   0.0844 ||  0.547952 ||  0.547266 ||    16.060745 || 
    Epoch 18    --      4.444987 ||   0.0415 ||   0.0971 ||  0.553227 ||  0.561914 ||      4.473714 ||      0.0368 ||   0.0925 ||  0.554490 ||  0.557293 ||    16.254716 || 
    Epoch 19    --      4.438052 ||   0.0427 ||   0.1012 ||  0.556669 ||  0.566527 ||      4.439454 ||      0.0416 ||   0.1017 ||  0.567060 ||  0.572329 ||    16.252685 || 
    Epoch 20    --      4.421159 ||   0.0455 ||   0.1044 ||  0.561338 ||  0.571925 ||      4.422530 ||      0.0434 ||   0.1047 ||  0.567243 ||  0.571716 ||    16.695856 || 
    Epoch 21    --      4.405221 ||   0.0485 ||   0.1086 ||  0.565856 ||  0.576416 ||      4.421400 ||      0.0457 ||   0.1027 ||  0.565726 ||  0.570498 ||    16.103930 || 
    Epoch 22    --      4.381466 ||   0.0526 ||   0.1120 ||  0.570828 ||  0.581736 ||      4.404747 ||      0.0481 ||   0.1111 ||  0.571930 ||  0.576859 ||    16.253181 || 
    Epoch 23    --      4.374016 ||   0.0558 ||   0.1172 ||  0.572273 ||  0.585185 ||      4.378673 ||      0.0517 ||   0.1123 ||  0.577471 ||  0.580581 ||    16.482428 || 
    Epoch 24    --      4.351784 ||   0.0588 ||   0.1209 ||  0.578086 ||  0.590612 ||      4.380046 ||      0.0566 ||   0.1241 ||  0.584939 ||  0.592648 ||    16.290073 || 
    Epoch 25    --      4.339426 ||   0.0619 ||   0.1266 ||  0.584107 ||  0.596910 ||      4.343235 ||      0.0594 ||   0.1200 ||  0.581950 ||  0.588135 ||    16.287657 || 
    Epoch 26    --      4.328546 ||   0.0646 ||   0.1288 ||  0.585643 ||  0.599223 ||      4.293754 ||      0.0674 ||   0.1288 ||  0.596911 ||  0.601269 ||    16.366253 || 
    Epoch 27    --      4.308727 ||   0.0676 ||   0.1345 ||  0.589828 ||  0.602765 ||      4.299559 ||      0.0673 ||   0.1330 ||  0.598436 ||  0.608937 ||    16.440436 || 
    Epoch 28    --      4.284044 ||   0.0728 ||   0.1410 ||  0.596795 ||  0.610380 ||      4.324655 ||      0.0632 ||   0.1334 ||  0.598745 ||  0.605533 ||    16.107769 || 
    Epoch 29    --      4.273829 ||   0.0760 ||   0.1435 ||  0.598982 ||  0.613372 ||      4.266103 ||      0.0738 ||   0.1396 ||  0.604067 ||  0.613239 ||    15.967657 || 
    Epoch 30    --      4.258496 ||   0.0787 ||   0.1469 ||  0.602416 ||  0.618286 ||      4.248537 ||      0.0821 ||   0.1481 ||  0.607412 ||  0.615728 ||    16.396178 || 
    Epoch 31    --      4.247417 ||   0.0817 ||   0.1489 ||  0.605022 ||  0.621080 ||      4.233232 ||      0.0839 ||   0.1566 ||  0.614158 ||  0.626582 ||    16.439887 || 
    Epoch 32    --      4.230158 ||   0.0853 ||   0.1538 ||  0.608706 ||  0.624083 ||      4.227863 ||      0.0811 ||   0.1495 ||  0.608821 ||  0.621183 ||    16.210579 || 
    Epoch 33    --      4.198565 ||   0.0890 ||   0.1593 ||  0.616252 ||  0.632402 ||      4.247605 ||      0.0877 ||   0.1587 ||  0.614941 ||  0.623643 ||    16.230504 || 
    Epoch 34    --      4.195504 ||   0.0912 ||   0.1617 ||  0.615992 ||  0.632885 ||      4.260480 ||      0.0765 ||   0.1484 ||  0.606066 ||  0.613568 ||    16.029145 || 
    Epoch 35    --      4.180339 ||   0.0958 ||   0.1651 ||  0.617941 ||  0.634643 ||      4.188451 ||      0.0904 ||   0.1607 ||  0.620501 ||  0.630948 ||    16.254692 || 
    Epoch 36    --      4.163723 ||   0.0984 ||   0.1693 ||  0.621854 ||  0.640043 ||      4.127688 ||      0.0993 ||   0.1711 ||  0.633561 ||  0.644379 ||    16.082810 || 
    Epoch 37    --      4.143169 ||   0.1019 ||   0.1734 ||  0.625578 ||  0.643334 ||      4.174713 ||      0.0920 ||   0.1637 ||  0.621836 ||  0.633847 ||    16.185102 || 
    Epoch 38    --      4.130111 ||   0.1037 ||   0.1751 ||  0.625806 ||  0.643824 ||      4.122394 ||      0.1058 ||   0.1766 ||  0.633481 ||  0.645555 ||    16.407038 || 
    Epoch 39    --      4.119683 ||   0.1062 ||   0.1804 ||  0.630352 ||  0.648929 ||      4.163316 ||      0.0993 ||   0.1700 ||  0.626701 ||  0.636705 ||    16.062372 || 
    Epoch 40    --      4.118357 ||   0.1069 ||   0.1789 ||  0.630496 ||  0.647632 ||      4.138601 ||      0.1031 ||   0.1732 ||  0.627165 ||  0.641761 ||    16.124288 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
