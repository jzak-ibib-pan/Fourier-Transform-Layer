Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.926540 ||   0.0271 ||   0.0941 ||  0.539188 ||  0.555776 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607456 ||   0.0543 ||   0.1336 ||  0.563510 ||  0.564877 ||      4.606555 ||      0.0094 ||   0.0446 ||  0.500588 ||  0.486454 ||    91.596653 || 
    Epoch 01    --      4.603465 ||   0.0100 ||   0.0491 ||  0.495337 ||  0.497046 ||      4.603109 ||      0.0087 ||   0.0450 ||  0.501825 ||  0.492285 ||    90.093135 || 
    Epoch 02    --      4.600114 ||   0.0110 ||   0.0501 ||  0.495815 ||  0.497577 ||      4.617428 ||      0.0112 ||   0.0521 ||  0.509264 ||  0.497218 ||    90.702466 || 
    Epoch 03    --      4.597157 ||   0.0124 ||   0.0516 ||  0.498587 ||  0.501243 ||      4.599422 ||      0.0104 ||   0.0475 ||  0.505528 ||  0.492218 ||    91.514998 || 
    Epoch 04    --      4.595083 ||   0.0118 ||   0.0529 ||  0.498194 ||  0.500697 ||      4.591099 ||      0.0118 ||   0.0511 ||  0.508174 ||  0.497930 ||    91.780621 || 
    Epoch 05    --      4.592021 ||   0.0132 ||   0.0525 ||  0.500164 ||  0.502561 ||      4.586613 ||      0.0121 ||   0.0498 ||  0.507789 ||  0.497940 ||    91.303986 || 
    Epoch 06    --      4.585194 ||   0.0145 ||   0.0567 ||  0.502813 ||  0.505295 ||      4.585623 ||      0.0121 ||   0.0520 ||  0.509771 ||  0.498096 ||    91.843126 || 
    Epoch 07    --      4.581474 ||   0.0152 ||   0.0567 ||  0.504006 ||  0.507391 ||      4.575030 ||      0.0145 ||   0.0538 ||  0.512093 ||  0.498440 ||    91.778551 || 
    Epoch 08    --      4.575679 ||   0.0160 ||   0.0600 ||  0.506271 ||  0.510185 ||      4.578840 ||      0.0139 ||   0.0542 ||  0.513712 ||  0.502622 ||    91.874375 || 
    Epoch 09    --      4.571375 ||   0.0165 ||   0.0600 ||  0.510103 ||  0.513266 ||      4.618914 ||      0.0204 ||   0.0653 ||  0.524197 ||  0.518491 ||    92.124369 || 
    Epoch 10    --      4.565088 ||   0.0183 ||   0.0634 ||  0.512533 ||  0.516148 ||      4.571205 ||      0.0165 ||   0.0547 ||  0.516542 ||  0.507909 ||    91.452497 || 
    Epoch 11    --      4.558650 ||   0.0195 ||   0.0642 ||  0.513487 ||  0.518133 ||      4.559799 ||      0.0189 ||   0.0613 ||  0.520421 ||  0.512677 ||    91.827494 || 
    Epoch 12    --      4.547263 ||   0.0220 ||   0.0679 ||  0.516452 ||  0.521024 ||      4.559194 ||      0.0203 ||   0.0650 ||  0.524663 ||  0.515184 ||    91.980354 || 
    Epoch 13    --      4.543754 ||   0.0234 ||   0.0704 ||  0.519578 ||  0.524386 ||      4.541192 ||      0.0198 ||   0.0658 ||  0.524147 ||  0.514377 ||    91.636568 || 
    Epoch 14    --      4.533384 ||   0.0241 ||   0.0737 ||  0.522258 ||  0.527548 ||      4.549904 ||      0.0219 ||   0.0691 ||  0.525381 ||  0.520670 ||    91.699072 || 
    Epoch 15    --      4.520555 ||   0.0267 ||   0.0765 ||  0.526009 ||  0.531910 ||      4.530407 ||      0.0245 ||   0.0739 ||  0.530513 ||  0.528117 ||    91.746118 || 
    Epoch 16    --      4.512839 ||   0.0291 ||   0.0783 ||  0.529872 ||  0.537889 ||      4.514704 ||      0.0297 ||   0.0769 ||  0.533276 ||  0.529971 ||    92.513145 || 
    Epoch 17    --      4.500909 ||   0.0322 ||   0.0833 ||  0.535974 ||  0.542755 ||      4.507979 ||      0.0284 ||   0.0787 ||  0.539803 ||  0.539305 ||    91.902416 || 
    Epoch 18    --      4.484854 ||   0.0356 ||   0.0877 ||  0.540198 ||  0.547562 ||      4.496565 ||      0.0308 ||   0.0838 ||  0.543477 ||  0.544616 ||    91.308819 || 
    Epoch 19    --      4.470969 ||   0.0374 ||   0.0919 ||  0.544741 ||  0.553101 ||      4.546889 ||      0.0329 ||   0.0856 ||  0.543703 ||  0.546910 ||    91.433943 || 
    Epoch 20    --      4.461909 ||   0.0396 ||   0.0933 ||  0.548134 ||  0.558289 ||      4.455514 ||      0.0370 ||   0.0903 ||  0.552175 ||  0.555609 ||    91.793302 || 
    Epoch 21    --      4.449349 ||   0.0422 ||   0.0989 ||  0.552764 ||  0.563302 ||      4.441678 ||      0.0423 ||   0.0985 ||  0.558427 ||  0.562254 ||    91.871428 || 
    Epoch 22    --      4.432555 ||   0.0437 ||   0.1002 ||  0.556914 ||  0.567877 ||      4.449258 ||      0.0389 ||   0.0935 ||  0.552467 ||  0.555399 ||    92.121627 || 
    Epoch 23    --      4.421495 ||   0.0470 ||   0.1075 ||  0.558591 ||  0.570625 ||      4.414014 ||      0.0473 ||   0.0996 ||  0.561802 ||  0.568786 ||    91.434147 || 
    Epoch 24    --      4.403382 ||   0.0494 ||   0.1089 ||  0.562623 ||  0.574293 ||      4.408066 ||      0.0480 ||   0.1090 ||  0.569618 ||  0.579768 ||    91.699762 || 
    Epoch 25    --      4.393891 ||   0.0516 ||   0.1117 ||  0.567978 ||  0.579959 ||      4.386580 ||      0.0520 ||   0.1139 ||  0.574916 ||  0.581880 ||    91.867966 || 
    Epoch 26    --      4.384882 ||   0.0548 ||   0.1151 ||  0.570013 ||  0.582716 ||      4.368983 ||      0.0567 ||   0.1190 ||  0.578930 ||  0.583545 ||    91.231203 || 
    Epoch 27    --      4.371830 ||   0.0562 ||   0.1172 ||  0.573439 ||  0.586193 ||      4.344931 ||      0.0581 ||   0.1239 ||  0.584885 ||  0.594258 ||    92.574914 || 
    Epoch 28    --      4.352765 ||   0.0606 ||   0.1239 ||  0.577621 ||  0.590692 ||      4.348958 ||      0.0574 ||   0.1227 ||  0.583528 ||  0.590098 ||    91.731344 || 
    Epoch 29    --      4.336833 ||   0.0640 ||   0.1270 ||  0.580636 ||  0.594230 ||      4.343539 ||      0.0623 ||   0.1269 ||  0.588707 ||  0.596318 ||    92.450130 || 
    Epoch 30    --      4.334731 ||   0.0635 ||   0.1278 ||  0.579851 ||  0.594249 ||      4.333205 ||      0.0652 ||   0.1304 ||  0.584065 ||  0.590334 ||    91.278292 || 
    Epoch 31    --      4.314217 ||   0.0678 ||   0.1320 ||  0.585844 ||  0.600879 ||      4.309472 ||      0.0681 ||   0.1348 ||  0.592760 ||  0.602030 ||    91.622102 || 
    Epoch 32    --      4.296785 ||   0.0714 ||   0.1366 ||  0.589887 ||  0.604419 ||      4.305228 ||      0.0687 ||   0.1376 ||  0.595446 ||  0.605901 ||    91.762827 || 
    Epoch 33    --      4.292421 ||   0.0719 ||   0.1370 ||  0.592264 ||  0.606949 ||      4.284804 ||      0.0715 ||   0.1336 ||  0.594426 ||  0.601516 ||    91.856569 || 
    Epoch 34    --      4.271466 ||   0.0764 ||   0.1417 ||  0.596511 ||  0.612386 ||      4.267192 ||      0.0752 ||   0.1424 ||  0.600964 ||  0.609464 ||    91.715940 || 
    Epoch 35    --      4.264969 ||   0.0801 ||   0.1449 ||  0.598141 ||  0.613632 ||      4.247459 ||      0.0772 ||   0.1469 ||  0.607823 ||  0.619081 ||    91.903602 || 
    Epoch 36    --      4.247519 ||   0.0810 ||   0.1496 ||  0.600636 ||  0.618248 ||      4.274839 ||      0.0734 ||   0.1380 ||  0.599274 ||  0.604538 ||    91.497364 || 
    Epoch 37    --      4.236887 ||   0.0841 ||   0.1521 ||  0.603337 ||  0.619165 ||      4.270375 ||      0.0812 ||   0.1470 ||  0.605742 ||  0.618314 ||    92.072268 || 
    Epoch 38    --      4.228320 ||   0.0849 ||   0.1525 ||  0.605198 ||  0.621909 ||      4.205696 ||      0.0896 ||   0.1581 ||  0.614233 ||  0.626268 ||    91.669362 || 
    Epoch 39    --      4.209764 ||   0.0880 ||   0.1586 ||  0.610845 ||  0.627863 ||      4.209359 ||      0.0899 ||   0.1561 ||  0.612774 ||  0.622386 ||    91.228209 || 
    Epoch 40    --      4.207132 ||   0.0911 ||   0.1578 ||  0.611735 ||  0.628289 ||      4.164785 ||      0.0958 ||   0.1678 ||  0.623466 ||  0.636768 ||    91.231887 || 
    Epoch 41    --      4.189699 ||   0.0938 ||   0.1625 ||  0.614582 ||  0.632342 ||      4.195587 ||      0.0902 ||   0.1579 ||  0.617312 ||  0.624946 ||    91.731964 || 
    Epoch 42    --      4.162060 ||   0.0971 ||   0.1678 ||  0.619872 ||  0.638675 ||      4.155886 ||      0.0955 ||   0.1635 ||  0.624756 ||  0.634149 ||    91.934097 || 
    Epoch 43    --      4.146415 ||   0.1008 ||   0.1710 ||  0.622890 ||  0.641291 ||      4.145643 ||      0.0995 ||   0.1736 ||  0.627914 ||  0.640221 ||    91.247628 || 
    Epoch 44    --      4.146379 ||   0.1014 ||   0.1736 ||  0.623680 ||  0.642157 ||      4.138927 ||      0.1000 ||   0.1737 ||  0.632870 ||  0.647277 ||    92.122672 || 
    Epoch 45    --      4.125322 ||   0.1052 ||   0.1778 ||  0.625169 ||  0.645059 ||      4.171353 ||      0.0940 ||   0.1675 ||  0.624604 ||  0.635235 ||    91.489852 || 
    Epoch 46    --      4.126451 ||   0.1056 ||   0.1755 ||  0.628748 ||  0.647106 ||      4.114254 ||      0.1084 ||   0.1843 ||  0.638060 ||  0.651244 ||    91.732147 || 
    Epoch 47    --      4.115262 ||   0.1072 ||   0.1792 ||  0.631543 ||  0.650721 ||      4.121228 ||      0.1065 ||   0.1811 ||  0.635290 ||  0.647297 ||    91.200916 || 
    Epoch 48    --      4.119503 ||   0.1067 ||   0.1785 ||  0.629856 ||  0.649644 ||      4.156660 ||      0.0968 ||   0.1694 ||  0.627566 ||  0.636158 ||    92.513481 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
