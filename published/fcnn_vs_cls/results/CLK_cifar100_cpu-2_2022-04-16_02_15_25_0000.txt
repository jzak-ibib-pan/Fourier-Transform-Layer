Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.716834 ||   0.0252 ||   0.0900 ||  0.533185 ||  0.550442 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.606851 ||   0.0509 ||   0.1311 ||  0.558168 ||  0.559681 ||      4.605618 ||      0.0099 ||   0.0449 ||  0.501235 ||  0.487102 ||    91.373205 || 
    Epoch 01    --      4.607313 ||   0.0101 ||   0.0492 ||  0.495111 ||  0.496811 ||      4.605363 ||      0.0090 ||   0.0454 ||  0.502378 ||  0.493568 ||    89.947481 || 
    Epoch 02    --      4.603010 ||   0.0102 ||   0.0499 ||  0.494558 ||  0.496373 ||      4.603607 ||      0.0093 ||   0.0466 ||  0.501538 ||  0.486614 ||    89.850255 || 
    Epoch 03    --      4.602039 ||   0.0110 ||   0.0501 ||  0.495523 ||  0.497764 ||      4.601699 ||      0.0102 ||   0.0472 ||  0.503736 ||  0.489742 ||    89.576543 || 
    Epoch 04    --      4.599856 ||   0.0108 ||   0.0514 ||  0.495609 ||  0.498178 ||      4.597668 ||      0.0104 ||   0.0473 ||  0.505273 ||  0.495357 ||    90.514058 || 
    Epoch 05    --      4.597347 ||   0.0121 ||   0.0518 ||  0.498170 ||  0.500350 ||      4.591191 ||      0.0105 ||   0.0489 ||  0.507474 ||  0.498376 ||    90.005974 || 
    Epoch 06    --      4.592593 ||   0.0130 ||   0.0551 ||  0.500158 ||  0.502571 ||      4.592464 ||      0.0106 ||   0.0484 ||  0.506135 ||  0.493646 ||    89.811062 || 
    Epoch 07    --      4.588931 ||   0.0143 ||   0.0554 ||  0.501437 ||  0.504314 ||      4.590093 ||      0.0121 ||   0.0518 ||  0.510990 ||  0.496943 ||    89.561417 || 
    Epoch 08    --      4.582642 ||   0.0150 ||   0.0572 ||  0.504276 ||  0.507320 ||      4.582691 ||      0.0127 ||   0.0510 ||  0.510342 ||  0.499625 ||    89.920452 || 
    Epoch 09    --      4.576905 ||   0.0157 ||   0.0603 ||  0.508475 ||  0.511412 ||      4.570826 ||      0.0173 ||   0.0589 ||  0.515409 ||  0.509197 ||    90.014271 || 
    Epoch 10    --      4.571068 ||   0.0171 ||   0.0625 ||  0.510924 ||  0.514727 ||      4.570361 ||      0.0167 ||   0.0532 ||  0.514838 ||  0.505916 ||    89.795568 || 
    Epoch 11    --      4.559673 ||   0.0204 ||   0.0657 ||  0.514961 ||  0.519517 ||      4.557319 ||      0.0186 ||   0.0643 ||  0.524006 ||  0.516632 ||    90.183616 || 
    Epoch 12    --      4.548519 ||   0.0222 ||   0.0689 ||  0.516177 ||  0.521159 ||      4.538089 ||      0.0217 ||   0.0658 ||  0.527954 ||  0.519804 ||    89.842468 || 
    Epoch 13    --      4.539751 ||   0.0253 ||   0.0742 ||  0.522965 ||  0.528666 ||      4.536823 ||      0.0217 ||   0.0679 ||  0.526554 ||  0.519803 ||    89.982504 || 
    Epoch 14    --      4.533130 ||   0.0258 ||   0.0754 ||  0.525002 ||  0.530595 ||      4.520755 ||      0.0244 ||   0.0734 ||  0.532963 ||  0.528117 ||    89.889426 || 
    Epoch 15    --      4.519323 ||   0.0281 ||   0.0782 ||  0.529053 ||  0.534852 ||      4.520921 ||      0.0278 ||   0.0778 ||  0.534761 ||  0.531293 ||    89.576931 || 
    Epoch 16    --      4.506500 ||   0.0304 ||   0.0811 ||  0.534245 ||  0.541608 ||      4.499386 ||      0.0289 ||   0.0847 ||  0.545464 ||  0.544573 ||    89.826992 || 
    Epoch 17    --      4.486338 ||   0.0333 ||   0.0862 ||  0.541148 ||  0.548328 ||      4.509625 ||      0.0277 ||   0.0749 ||  0.536504 ||  0.535574 ||    90.420726 || 
    Epoch 18    --      4.473865 ||   0.0370 ||   0.0916 ||  0.545437 ||  0.553411 ||      4.480189 ||      0.0335 ||   0.0848 ||  0.543728 ||  0.543519 ||    89.733235 || 
    Epoch 19    --      4.460252 ||   0.0389 ||   0.0950 ||  0.548594 ||  0.557761 ||      4.455892 ||      0.0385 ||   0.0936 ||  0.553336 ||  0.556373 ||    89.608305 || 
    Epoch 20    --      4.448249 ||   0.0411 ||   0.0964 ||  0.551319 ||  0.561039 ||      4.461685 ||      0.0375 ||   0.0902 ||  0.546750 ||  0.546823 ||    91.203520 || 
    Epoch 21    --      4.431904 ||   0.0438 ||   0.1013 ||  0.555665 ||  0.565608 ||      4.465409 ||      0.0454 ||   0.1057 ||  0.563926 ||  0.569620 ||    90.639549 || 
    Epoch 22    --      4.409392 ||   0.0485 ||   0.1058 ||  0.563431 ||  0.574679 ||      4.421371 ||      0.0445 ||   0.1029 ||  0.565143 ||  0.569922 ||    89.905196 || 
    Epoch 23    --      4.410928 ||   0.0499 ||   0.1093 ||  0.561733 ||  0.573749 ||      4.397445 ||      0.0515 ||   0.1064 ||  0.573974 ||  0.578797 ||    89.561500 || 
    Epoch 24    --      4.389681 ||   0.0526 ||   0.1113 ||  0.569485 ||  0.581418 ||      4.397947 ||      0.0500 ||   0.1079 ||  0.570995 ||  0.577498 ||    91.608373 || 
    Epoch 25    --      4.378222 ||   0.0547 ||   0.1138 ||  0.571768 ||  0.583992 ||      4.374604 ||      0.0542 ||   0.1080 ||  0.570651 ||  0.575580 ||    89.592774 || 
    Epoch 26    --      4.361891 ||   0.0580 ||   0.1190 ||  0.573797 ||  0.586657 ||      4.369559 ||      0.0533 ||   0.1123 ||  0.573034 ||  0.575134 ||    90.670933 || 
    Epoch 27    --      4.344609 ||   0.0601 ||   0.1230 ||  0.578208 ||  0.590769 ||      4.305954 ||      0.0649 ||   0.1295 ||  0.592961 ||  0.603528 ||    89.561756 || 
    Epoch 28    --      4.331203 ||   0.0646 ||   0.1262 ||  0.580876 ||  0.593119 ||      4.356449 ||      0.0553 ||   0.1175 ||  0.579848 ||  0.587224 ||    89.922455 || 
    Epoch 29    --      4.325795 ||   0.0663 ||   0.1291 ||  0.581841 ||  0.595247 ||      4.307452 ||      0.0664 ||   0.1303 ||  0.593979 ||  0.601145 ||    89.532953 || 
    Epoch 30    --      4.313007 ||   0.0681 ||   0.1305 ||  0.585220 ||  0.599282 ||      4.292092 ||      0.0716 ||   0.1386 ||  0.599344 ||  0.606264 ||    92.202201 || 
    Epoch 31    --      4.294958 ||   0.0718 ||   0.1352 ||  0.589827 ||  0.605223 ||      4.286564 ||      0.0748 ||   0.1425 ||  0.598557 ||  0.608646 ||    91.249075 || 
    Epoch 32    --      4.283332 ||   0.0741 ||   0.1368 ||  0.592128 ||  0.606263 ||      4.289452 ||      0.0716 ||   0.1329 ||  0.595235 ||  0.605118 ||    91.342870 || 
    Epoch 33    --      4.274009 ||   0.0763 ||   0.1380 ||  0.594295 ||  0.608942 ||      4.270124 ||      0.0799 ||   0.1465 ||  0.604352 ||  0.612393 ||    91.452271 || 
    Epoch 34    --      4.258138 ||   0.0810 ||   0.1450 ||  0.598365 ||  0.614056 ||      4.275062 ||      0.0731 ||   0.1412 ||  0.602889 ||  0.611282 ||    91.452272 || 
    Epoch 35    --      4.247964 ||   0.0816 ||   0.1473 ||  0.601434 ||  0.616860 ||      4.291932 ||      0.0760 ||   0.1354 ||  0.594690 ||  0.603341 ||    92.514764 || 
    Epoch 36    --      4.237401 ||   0.0841 ||   0.1501 ||  0.602171 ||  0.618739 ||      4.209962 ||      0.0863 ||   0.1477 ||  0.610652 ||  0.618259 ||    92.030432 || 
    Epoch 37    --      4.223721 ||   0.0860 ||   0.1532 ||  0.603672 ||  0.619820 ||      4.254581 ||      0.0841 ||   0.1533 ||  0.611512 ||  0.625614 ||    91.882696 || 
    Epoch 38    --      4.210709 ||   0.0877 ||   0.1552 ||  0.607370 ||  0.624439 ||      4.199433 ||      0.0888 ||   0.1579 ||  0.615984 ||  0.628935 ||    91.639805 || 
    Epoch 39    --      4.192811 ||   0.0921 ||   0.1595 ||  0.611753 ||  0.629443 ||      4.217666 ||      0.0858 ||   0.1508 ||  0.610763 ||  0.619239 ||    91.999201 || 
    Epoch 40    --      4.192625 ||   0.0926 ||   0.1611 ||  0.611984 ||  0.628807 ||      4.203821 ||      0.0912 ||   0.1607 ||  0.616087 ||  0.627500 ||    91.324634 || 
    Epoch 41    --      4.185354 ||   0.0949 ||   0.1620 ||  0.613337 ||  0.631123 ||      4.172527 ||      0.0992 ||   0.1694 ||  0.623017 ||  0.632595 ||    91.717958 || 
    Epoch 42    --      4.162161 ||   0.0979 ||   0.1655 ||  0.616921 ||  0.635646 ||      4.191286 ||      0.0919 ||   0.1596 ||  0.617555 ||  0.627660 ||    91.688887 || 
    Epoch 43    --      4.155387 ||   0.1008 ||   0.1698 ||  0.617146 ||  0.636194 ||      4.146901 ||      0.1010 ||   0.1787 ||  0.632332 ||  0.645455 ||    91.389858 || 
    Epoch 44    --      4.146890 ||   0.1034 ||   0.1728 ||  0.619856 ||  0.639171 ||      4.125642 ||      0.1038 ||   0.1734 ||  0.626679 ||  0.639070 ||    91.905474 || 
    Epoch 45    --      4.131519 ||   0.1057 ||   0.1760 ||  0.623727 ||  0.642629 ||      4.201656 ||      0.0942 ||   0.1643 ||  0.616667 ||  0.626986 ||    91.374235 || 
    Epoch 46    --      4.139892 ||   0.1039 ||   0.1688 ||  0.621331 ||  0.639404 ||      4.133987 ||      0.1021 ||   0.1736 ||  0.629769 ||  0.642962 ||    91.444519 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
