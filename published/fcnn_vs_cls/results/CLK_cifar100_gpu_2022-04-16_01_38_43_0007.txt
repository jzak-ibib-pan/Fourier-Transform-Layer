Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.621498 ||   0.0279 ||   0.0910 ||  0.535074 ||  0.549827 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.606963 ||   0.0512 ||   0.1288 ||  0.556045 ||  0.557554 ||      4.606421 ||      0.0094 ||   0.0449 ||  0.501114 ||  0.487213 ||    14.596155 || 
    Epoch 01    --      4.604571 ||   0.0099 ||   0.0494 ||  0.495280 ||  0.497056 ||      4.602736 ||      0.0089 ||   0.0455 ||  0.502114 ||  0.492461 ||    13.031993 || 
    Epoch 02    --      4.601559 ||   0.0106 ||   0.0501 ||  0.494804 ||  0.496468 ||      4.602167 ||      0.0097 ||   0.0467 ||  0.502923 ||  0.489836 ||    12.988058 || 
    Epoch 03    --      4.598467 ||   0.0114 ||   0.0501 ||  0.496941 ||  0.499289 ||      4.598896 ||      0.0103 ||   0.0465 ||  0.504523 ||  0.491476 ||    13.225266 || 
    Epoch 04    --      4.597373 ||   0.0110 ||   0.0516 ||  0.496363 ||  0.498654 ||      4.592409 ||      0.0108 ||   0.0496 ||  0.507611 ||  0.498571 ||    13.697228 || 
    Epoch 05    --      4.593621 ||   0.0119 ||   0.0516 ||  0.498678 ||  0.501147 ||      4.590057 ||      0.0112 ||   0.0490 ||  0.506072 ||  0.496771 ||    13.616685 || 
    Epoch 06    --      4.587418 ||   0.0130 ||   0.0543 ||  0.501837 ||  0.504056 ||      4.587086 ||      0.0111 ||   0.0512 ||  0.508624 ||  0.496322 ||    12.608457 || 
    Epoch 07    --      4.586199 ||   0.0139 ||   0.0558 ||  0.503006 ||  0.505608 ||      4.584979 ||      0.0147 ||   0.0523 ||  0.510111 ||  0.495822 ||    13.068656 || 
    Epoch 08    --      4.579335 ||   0.0154 ||   0.0575 ||  0.506019 ||  0.508962 ||      4.576479 ||      0.0130 ||   0.0541 ||  0.513686 ||  0.503084 ||    13.471663 || 
    Epoch 09    --      4.575738 ||   0.0163 ||   0.0600 ||  0.508737 ||  0.511627 ||      4.569206 ||      0.0181 ||   0.0597 ||  0.517255 ||  0.510280 ||    12.968674 || 
    Epoch 10    --      4.566040 ||   0.0180 ||   0.0632 ||  0.511833 ||  0.515541 ||      4.568000 ||      0.0159 ||   0.0550 ||  0.516097 ||  0.506274 ||    12.768136 || 
    Epoch 11    --      4.553755 ||   0.0206 ||   0.0668 ||  0.514023 ||  0.518987 ||      4.554078 ||      0.0186 ||   0.0611 ||  0.521295 ||  0.512338 ||    12.567093 || 
    Epoch 12    --      4.550581 ||   0.0218 ||   0.0681 ||  0.515826 ||  0.520336 ||      4.554342 ||      0.0197 ||   0.0624 ||  0.523115 ||  0.514342 ||    12.828278 || 
    Epoch 13    --      4.542947 ||   0.0243 ||   0.0731 ||  0.520539 ||  0.525773 ||      4.566203 ||      0.0224 ||   0.0701 ||  0.527400 ||  0.519756 ||    12.552215 || 
    Epoch 14    --      4.530645 ||   0.0258 ||   0.0751 ||  0.523379 ||  0.528583 ||      4.526221 ||      0.0274 ||   0.0743 ||  0.532521 ||  0.527544 ||    12.511389 || 
    Epoch 15    --      4.518249 ||   0.0283 ||   0.0771 ||  0.528092 ||  0.534148 ||      4.522678 ||      0.0272 ||   0.0757 ||  0.533889 ||  0.530788 ||    12.693606 || 
    Epoch 16    --      4.509097 ||   0.0306 ||   0.0804 ||  0.530372 ||  0.537649 ||      4.494442 ||      0.0319 ||   0.0806 ||  0.539796 ||  0.537700 ||    12.657043 || 
    Epoch 17    --      4.491647 ||   0.0335 ||   0.0856 ||  0.537212 ||  0.543867 ||      4.513437 ||      0.0275 ||   0.0757 ||  0.534438 ||  0.532721 ||    12.628013 || 
    Epoch 18    --      4.477500 ||   0.0364 ||   0.0897 ||  0.541605 ||  0.548691 ||      4.486874 ||      0.0342 ||   0.0859 ||  0.544086 ||  0.545070 ||    12.849852 || 
    Epoch 19    --      4.468323 ||   0.0381 ||   0.0927 ||  0.543841 ||  0.552456 ||      4.477616 ||      0.0375 ||   0.0917 ||  0.553590 ||  0.555776 ||    13.707344 || 
    Epoch 20    --      4.461476 ||   0.0399 ||   0.0936 ||  0.546910 ||  0.555754 ||      4.448256 ||      0.0393 ||   0.0961 ||  0.557000 ||  0.559777 ||    13.016526 || 
    Epoch 21    --      4.444390 ||   0.0436 ||   0.0994 ||  0.553043 ||  0.561888 ||      4.475121 ||      0.0402 ||   0.0992 ||  0.558020 ||  0.560652 ||    13.251449 || 
    Epoch 22    --      4.424031 ||   0.0467 ||   0.1033 ||  0.558647 ||  0.568421 ||      4.424714 ||      0.0433 ||   0.1033 ||  0.560279 ||  0.564019 ||    12.940943 || 
    Epoch 23    --      4.416540 ||   0.0479 ||   0.1068 ||  0.559185 ||  0.569751 ||      4.402880 ||      0.0484 ||   0.1032 ||  0.570556 ||  0.574922 ||    12.859672 || 
    Epoch 24    --      4.404784 ||   0.0509 ||   0.1092 ||  0.563037 ||  0.574002 ||      4.448782 ||      0.0477 ||   0.1045 ||  0.563694 ||  0.568266 ||    12.607879 || 
    Epoch 25    --      4.391383 ||   0.0532 ||   0.1124 ||  0.568215 ||  0.579104 ||      4.392943 ||      0.0547 ||   0.1107 ||  0.566594 ||  0.569598 ||    13.212682 || 
    Epoch 26    --      4.375657 ||   0.0571 ||   0.1175 ||  0.570640 ||  0.582252 ||      4.363583 ||      0.0562 ||   0.1124 ||  0.575576 ||  0.576689 ||    13.427314 || 
    Epoch 27    --      4.361558 ||   0.0588 ||   0.1186 ||  0.573059 ||  0.584433 ||      4.339380 ||      0.0611 ||   0.1223 ||  0.580317 ||  0.583984 ||    12.861105 || 
    Epoch 28    --      4.337387 ||   0.0632 ||   0.1256 ||  0.579777 ||  0.590980 ||      4.348397 ||      0.0603 ||   0.1173 ||  0.582362 ||  0.587076 ||    13.102803 || 
    Epoch 29    --      4.333717 ||   0.0659 ||   0.1290 ||  0.581977 ||  0.593731 ||      4.332663 ||      0.0639 ||   0.1215 ||  0.585269 ||  0.592332 ||    13.333179 || 
    Epoch 30    --      4.311797 ||   0.0686 ||   0.1302 ||  0.584467 ||  0.597857 ||      4.321515 ||      0.0681 ||   0.1301 ||  0.591044 ||  0.595987 ||    13.314923 || 
    Epoch 31    --      4.296149 ||   0.0722 ||   0.1359 ||  0.589124 ||  0.602910 ||      4.314506 ||      0.0697 ||   0.1346 ||  0.596812 ||  0.605138 ||    12.817771 || 
    Epoch 32    --      4.279600 ||   0.0757 ||   0.1390 ||  0.593277 ||  0.606332 ||      4.323840 ||      0.0739 ||   0.1394 ||  0.600911 ||  0.611512 ||    12.728462 || 
    Epoch 33    --      4.272604 ||   0.0769 ||   0.1392 ||  0.595888 ||  0.609780 ||      4.261372 ||      0.0793 ||   0.1398 ||  0.602473 ||  0.609072 ||    13.015732 || 
    Epoch 34    --      4.248753 ||   0.0822 ||   0.1467 ||  0.600447 ||  0.615449 ||      4.293383 ||      0.0724 ||   0.1333 ||  0.593370 ||  0.600233 ||    12.799114 || 
    Epoch 35    --      4.239741 ||   0.0852 ||   0.1514 ||  0.603306 ||  0.617651 ||      4.218381 ||      0.0854 ||   0.1474 ||  0.608670 ||  0.618476 ||    13.483378 || 
    Epoch 36    --      4.214908 ||   0.0888 ||   0.1551 ||  0.606169 ||  0.622523 ||      4.227475 ||      0.0880 ||   0.1537 ||  0.614522 ||  0.622091 ||    12.884541 || 
    Epoch 37    --      4.203805 ||   0.0914 ||   0.1592 ||  0.609275 ||  0.624953 ||      4.206635 ||      0.0888 ||   0.1550 ||  0.612726 ||  0.622413 ||    13.014013 || 
    Epoch 38    --      4.186712 ||   0.0944 ||   0.1613 ||  0.613740 ||  0.629593 ||      4.187306 ||      0.0956 ||   0.1667 ||  0.621773 ||  0.633310 ||    11.843824 || 
    Epoch 39    --      4.173407 ||   0.0980 ||   0.1689 ||  0.618955 ||  0.635543 ||      4.179232 ||      0.0982 ||   0.1650 ||  0.623682 ||  0.633448 ||    12.548152 || 
    Epoch 40    --      4.159197 ||   0.0998 ||   0.1709 ||  0.621480 ||  0.638348 ||      4.152971 ||      0.1034 ||   0.1742 ||  0.628361 ||  0.642852 ||    13.282446 || 
    Epoch 41    --      4.147601 ||   0.1019 ||   0.1725 ||  0.623614 ||  0.641613 ||      4.155162 ||      0.1033 ||   0.1734 ||  0.630081 ||  0.637970 ||    13.583726 || 
    Epoch 42    --      4.133641 ||   0.1051 ||   0.1768 ||  0.626275 ||  0.644697 ||      4.179806 ||      0.0978 ||   0.1656 ||  0.623887 ||  0.634346 ||    12.645737 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
