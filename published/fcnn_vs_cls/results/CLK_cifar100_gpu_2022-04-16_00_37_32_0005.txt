Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.519263 ||   0.0260 ||   0.0984 ||  0.541560 ||  0.559518 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607283 ||   0.0524 ||   0.1325 ||  0.563520 ||  0.565009 ||      4.607025 ||      0.0090 ||   0.0442 ||  0.500044 ||  0.485804 ||    14.604507 || 
    Epoch 01    --      4.606456 ||   0.0095 ||   0.0482 ||  0.494239 ||  0.495813 ||      4.604863 ||      0.0087 ||   0.0455 ||  0.501575 ||  0.492512 ||    13.034340 || 
    Epoch 02    --      4.602622 ||   0.0102 ||   0.0496 ||  0.494585 ||  0.496268 ||      4.603066 ||      0.0090 ||   0.0464 ||  0.501996 ||  0.487734 ||    12.840123 || 
    Epoch 03    --      4.599592 ||   0.0110 ||   0.0498 ||  0.497110 ||  0.499353 ||      4.602942 ||      0.0101 ||   0.0469 ||  0.506282 ||  0.492956 ||    13.112284 || 
    Epoch 04    --      4.596835 ||   0.0113 ||   0.0520 ||  0.497243 ||  0.499643 ||      4.593775 ||      0.0108 ||   0.0481 ||  0.507055 ||  0.497647 ||    13.084918 || 
    Epoch 05    --      4.594160 ||   0.0125 ||   0.0516 ||  0.499811 ||  0.502296 ||      4.591748 ||      0.0109 ||   0.0495 ||  0.508107 ||  0.498987 ||    13.082355 || 
    Epoch 06    --      4.588586 ||   0.0136 ||   0.0556 ||  0.501546 ||  0.503877 ||      4.588110 ||      0.0110 ||   0.0494 ||  0.507502 ||  0.495516 ||    13.258447 || 
    Epoch 07    --      4.581755 ||   0.0146 ||   0.0573 ||  0.505016 ||  0.507939 ||      4.577936 ||      0.0149 ||   0.0531 ||  0.512272 ||  0.497982 ||    13.377056 || 
    Epoch 08    --      4.574158 ||   0.0165 ||   0.0592 ||  0.508037 ||  0.511369 ||      4.584975 ||      0.0136 ||   0.0557 ||  0.515853 ||  0.504053 ||    12.881684 || 
    Epoch 09    --      4.568697 ||   0.0171 ||   0.0631 ||  0.512135 ||  0.515292 ||      4.559902 ||      0.0195 ||   0.0612 ||  0.520319 ||  0.514310 ||    13.226893 || 
    Epoch 10    --      4.556061 ||   0.0194 ||   0.0664 ||  0.517061 ||  0.521353 ||      4.553749 ||      0.0192 ||   0.0594 ||  0.522168 ||  0.514951 ||    12.296865 || 
    Epoch 11    --      4.544199 ||   0.0219 ||   0.0698 ||  0.522219 ||  0.527275 ||      4.562553 ||      0.0198 ||   0.0656 ||  0.527593 ||  0.522629 ||    12.356685 || 
    Epoch 12    --      4.533153 ||   0.0244 ||   0.0732 ||  0.524619 ||  0.530024 ||      4.548685 ||      0.0202 ||   0.0640 ||  0.523509 ||  0.517427 ||    13.115735 || 
    Epoch 13    --      4.525748 ||   0.0270 ||   0.0753 ||  0.526935 ||  0.532913 ||      4.521279 ||      0.0235 ||   0.0741 ||  0.532786 ||  0.526353 ||    13.078684 || 
    Epoch 14    --      4.514274 ||   0.0280 ||   0.0786 ||  0.530358 ||  0.536655 ||      4.536153 ||      0.0279 ||   0.0785 ||  0.537396 ||  0.535439 ||    12.550765 || 
    Epoch 15    --      4.501156 ||   0.0305 ||   0.0808 ||  0.534431 ||  0.541200 ||      4.500601 ||      0.0312 ||   0.0799 ||  0.535983 ||  0.532625 ||    13.059577 || 
    Epoch 16    --      4.489550 ||   0.0328 ||   0.0839 ||  0.537503 ||  0.545544 ||      4.496393 ||      0.0345 ||   0.0843 ||  0.545711 ||  0.544786 ||    13.209973 || 
    Epoch 17    --      4.474548 ||   0.0363 ||   0.0899 ||  0.542332 ||  0.549194 ||      4.481299 ||      0.0325 ||   0.0882 ||  0.553179 ||  0.556965 ||    13.361698 || 
    Epoch 18    --      4.457839 ||   0.0392 ||   0.0934 ||  0.549013 ||  0.557134 ||      4.479471 ||      0.0370 ||   0.0897 ||  0.549059 ||  0.551470 ||    13.479479 || 
    Epoch 19    --      4.447269 ||   0.0420 ||   0.0966 ||  0.551991 ||  0.561149 ||      4.433197 ||      0.0412 ||   0.0968 ||  0.557138 ||  0.562011 ||    12.783595 || 
    Epoch 20    --      4.434007 ||   0.0441 ||   0.1000 ||  0.556501 ||  0.566408 ||      4.441685 ||      0.0404 ||   0.0980 ||  0.563369 ||  0.567262 ||    12.697412 || 
    Epoch 21    --      4.416269 ||   0.0465 ||   0.1048 ||  0.561380 ||  0.572073 ||      4.408186 ||      0.0469 ||   0.1034 ||  0.563287 ||  0.564995 ||    12.796913 || 
    Epoch 22    --      4.395467 ||   0.0499 ||   0.1081 ||  0.565927 ||  0.576932 ||      4.399506 ||      0.0483 ||   0.1077 ||  0.566038 ||  0.572079 ||    12.826499 || 
    Epoch 23    --      4.387485 ||   0.0526 ||   0.1133 ||  0.567188 ||  0.579076 ||      4.378236 ||      0.0532 ||   0.1110 ||  0.573218 ||  0.578736 ||    13.862427 || 
    Epoch 24    --      4.372284 ||   0.0561 ||   0.1153 ||  0.571490 ||  0.583774 ||      4.345855 ||      0.0590 ||   0.1204 ||  0.583478 ||  0.590456 ||    13.261697 || 
    Epoch 25    --      4.354828 ||   0.0598 ||   0.1193 ||  0.577121 ||  0.589350 ||      4.355791 ||      0.0576 ||   0.1148 ||  0.577330 ||  0.581781 ||    12.484110 || 
    Epoch 26    --      4.342662 ||   0.0621 ||   0.1248 ||  0.580328 ||  0.593510 ||      4.325311 ||      0.0614 ||   0.1235 ||  0.589429 ||  0.595436 ||    12.543783 || 
    Epoch 27    --      4.330562 ||   0.0644 ||   0.1284 ||  0.581509 ||  0.595046 ||      4.296815 ||      0.0683 ||   0.1317 ||  0.594418 ||  0.604509 ||    13.492626 || 
    Epoch 28    --      4.304436 ||   0.0692 ||   0.1340 ||  0.589762 ||  0.603371 ||      4.321338 ||      0.0626 ||   0.1277 ||  0.586236 ||  0.592255 ||    13.235071 || 
    Epoch 29    --      4.298492 ||   0.0725 ||   0.1364 ||  0.590833 ||  0.605131 ||      4.300430 ||      0.0670 ||   0.1265 ||  0.591024 ||  0.598017 ||    12.484733 || 
    Epoch 30    --      4.291009 ||   0.0730 ||   0.1395 ||  0.591947 ||  0.607612 ||      4.291874 ||      0.0720 ||   0.1419 ||  0.597526 ||  0.607031 ||    13.295154 || 
    Epoch 31    --      4.270283 ||   0.0764 ||   0.1419 ||  0.596316 ||  0.612135 ||      4.371120 ||      0.0749 ||   0.1474 ||  0.599102 ||  0.610080 ||    12.875239 || 
    Epoch 32    --      4.251060 ||   0.0798 ||   0.1456 ||  0.600664 ||  0.615409 ||      4.283788 ||      0.0753 ||   0.1448 ||  0.602335 ||  0.615619 ||    12.619038 || 
    Epoch 33    --      4.238460 ||   0.0822 ||   0.1499 ||  0.605013 ||  0.621335 ||      4.251685 ||      0.0821 ||   0.1521 ||  0.610100 ||  0.619944 ||    13.186862 || 
    Epoch 34    --      4.221614 ||   0.0875 ||   0.1558 ||  0.607873 ||  0.624735 ||      4.244297 ||      0.0828 ||   0.1509 ||  0.608296 ||  0.617990 ||    13.374599 || 
    Epoch 35    --      4.212319 ||   0.0896 ||   0.1565 ||  0.609782 ||  0.626685 ||      4.228631 ||      0.0839 ||   0.1502 ||  0.606400 ||  0.616493 ||    12.795785 || 
    Epoch 36    --      4.208973 ||   0.0917 ||   0.1588 ||  0.610993 ||  0.629263 ||      4.188375 ||      0.0883 ||   0.1542 ||  0.615524 ||  0.624511 ||    12.814656 || 
    Epoch 37    --      4.184040 ||   0.0944 ||   0.1645 ||  0.614244 ||  0.631478 ||      4.187229 ||      0.0929 ||   0.1606 ||  0.618237 ||  0.631934 ||    13.504395 || 
    Epoch 38    --      4.177279 ||   0.0953 ||   0.1641 ||  0.616110 ||  0.634449 ||      4.187365 ||      0.0937 ||   0.1679 ||  0.620119 ||  0.634316 ||    13.072902 || 
    Epoch 39    --      4.161373 ||   0.0984 ||   0.1694 ||  0.621093 ||  0.639633 ||      4.181364 ||      0.0970 ||   0.1660 ||  0.625649 ||  0.636244 ||    12.945035 || 
    Epoch 40    --      4.146945 ||   0.1007 ||   0.1711 ||  0.623449 ||  0.641747 ||      4.166144 ||      0.1022 ||   0.1764 ||  0.628702 ||  0.644236 ||    12.888223 || 
    Epoch 41    --      4.140298 ||   0.1030 ||   0.1738 ||  0.625090 ||  0.643795 ||      4.134024 ||      0.1033 ||   0.1718 ||  0.632451 ||  0.643808 ||    12.748244 || 
    Epoch 42    --      4.139982 ||   0.1047 ||   0.1757 ||  0.628531 ||  0.647390 ||      4.123693 ||      0.1081 ||   0.1828 ||  0.640473 ||  0.655419 ||    12.660399 || 
    Epoch 43    --      4.106899 ||   0.1094 ||   0.1813 ||  0.631837 ||  0.651710 ||      4.097268 ||      0.1081 ||   0.1811 ||  0.636924 ||  0.650933 ||    13.006420 || 
    Epoch 44    --      4.112257 ||   0.1086 ||   0.1814 ||  0.629318 ||  0.649466 ||      4.142825 ||      0.1046 ||   0.1796 ||  0.632002 ||  0.646685 ||    13.310339 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
