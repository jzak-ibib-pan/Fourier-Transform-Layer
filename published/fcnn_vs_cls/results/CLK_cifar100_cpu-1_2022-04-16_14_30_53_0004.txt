Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.429571 ||   0.0311 ||   0.0973 ||  0.538758 ||  0.557303 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.608130 ||   0.0525 ||   0.1326 ||  0.563771 ||  0.565194 ||      4.606400 ||      0.0097 ||   0.0449 ||  0.500591 ||  0.486669 ||    17.890637 || 
    Epoch 01    --      4.604096 ||   0.0102 ||   0.0487 ||  0.495673 ||  0.497441 ||      4.604310 ||      0.0084 ||   0.0444 ||  0.501458 ||  0.491869 ||    16.226546 || 
    Epoch 02    --      4.602043 ||   0.0108 ||   0.0503 ||  0.495535 ||  0.497350 ||      4.603156 ||      0.0092 ||   0.0463 ||  0.501903 ||  0.487363 ||    16.229557 || 
    Epoch 03    --      4.598484 ||   0.0113 ||   0.0501 ||  0.497208 ||  0.499744 ||      4.598310 ||      0.0102 ||   0.0464 ||  0.503941 ||  0.489741 ||    16.364088 || 
    Epoch 04    --      4.595838 ||   0.0114 ||   0.0518 ||  0.496146 ||  0.498644 ||      4.594870 ||      0.0104 ||   0.0481 ||  0.506640 ||  0.496648 ||    16.307436 || 
    Epoch 05    --      4.593071 ||   0.0127 ||   0.0520 ||  0.499780 ||  0.502222 ||      4.586512 ||      0.0112 ||   0.0499 ||  0.507890 ||  0.499285 ||    16.155660 || 
    Epoch 06    --      4.586522 ||   0.0139 ||   0.0558 ||  0.503092 ||  0.505515 ||      4.589317 ||      0.0122 ||   0.0506 ||  0.511344 ||  0.500034 ||    16.216474 || 
    Epoch 07    --      4.577296 ||   0.0157 ||   0.0584 ||  0.507787 ||  0.510738 ||      4.594754 ||      0.0142 ||   0.0548 ||  0.514581 ||  0.501140 ||    16.273841 || 
    Epoch 08    --      4.572872 ||   0.0170 ||   0.0621 ||  0.509697 ||  0.513183 ||      4.572015 ||      0.0152 ||   0.0560 ||  0.516148 ||  0.505794 ||    16.436657 || 
    Epoch 09    --      4.563904 ||   0.0179 ||   0.0643 ||  0.514592 ||  0.517837 ||      4.554020 ||      0.0201 ||   0.0642 ||  0.522487 ||  0.517428 ||    16.296083 || 
    Epoch 10    --      4.549757 ||   0.0207 ||   0.0691 ||  0.518778 ||  0.523612 ||      4.554151 ||      0.0196 ||   0.0622 ||  0.522824 ||  0.514738 ||    16.283408 || 
    Epoch 11    --      4.538496 ||   0.0235 ||   0.0725 ||  0.523128 ||  0.528531 ||      4.543396 ||      0.0211 ||   0.0666 ||  0.529059 ||  0.523936 ||    16.378804 || 
    Epoch 12    --      4.526192 ||   0.0269 ||   0.0752 ||  0.527802 ||  0.533801 ||      4.522791 ||      0.0255 ||   0.0718 ||  0.533610 ||  0.528406 ||    16.129170 || 
    Epoch 13    --      4.513013 ||   0.0298 ||   0.0803 ||  0.534428 ||  0.541363 ||      4.508151 ||      0.0271 ||   0.0780 ||  0.537837 ||  0.532646 ||    16.610029 || 
    Epoch 14    --      4.497313 ||   0.0318 ||   0.0833 ||  0.538458 ||  0.545835 ||      4.511447 ||      0.0292 ||   0.0769 ||  0.536452 ||  0.533982 ||    16.404501 || 
    Epoch 15    --      4.477296 ||   0.0342 ||   0.0891 ||  0.543439 ||  0.551392 ||      4.494887 ||      0.0327 ||   0.0868 ||  0.548616 ||  0.548982 ||    16.224210 || 
    Epoch 16    --      4.471662 ||   0.0366 ||   0.0915 ||  0.546905 ||  0.555775 ||      4.456610 ||      0.0387 ||   0.0928 ||  0.555807 ||  0.555533 ||    16.030975 || 
    Epoch 17    --      4.446597 ||   0.0415 ||   0.0984 ||  0.553965 ||  0.562788 ||      4.454745 ||      0.0360 ||   0.0891 ||  0.556689 ||  0.560723 ||    16.338376 || 
    Epoch 18    --      4.433183 ||   0.0446 ||   0.1020 ||  0.557481 ||  0.566262 ||      4.491130 ||      0.0401 ||   0.0938 ||  0.555611 ||  0.562200 ||    15.943163 || 
    Epoch 19    --      4.413096 ||   0.0484 ||   0.1075 ||  0.563764 ||  0.574323 ||      4.416100 ||      0.0430 ||   0.1041 ||  0.568684 ||  0.571989 ||    16.071118 || 
    Epoch 20    --      4.398806 ||   0.0505 ||   0.1095 ||  0.568826 ||  0.579818 ||      4.376635 ||      0.0492 ||   0.1126 ||  0.574430 ||  0.579666 ||    16.433043 || 
    Epoch 21    --      4.383432 ||   0.0543 ||   0.1153 ||  0.573148 ||  0.583993 ||      4.380023 ||      0.0558 ||   0.1181 ||  0.581332 ||  0.584422 ||    16.270685 || 
    Epoch 22    --      4.359965 ||   0.0578 ||   0.1195 ||  0.577497 ||  0.589751 ||      4.378382 ||      0.0519 ||   0.1161 ||  0.576692 ||  0.582412 ||    16.065002 || 
    Epoch 23    --      4.344845 ||   0.0620 ||   0.1259 ||  0.581794 ||  0.595103 ||      4.344842 ||      0.0639 ||   0.1279 ||  0.592682 ||  0.600117 ||    16.148375 || 
    Epoch 24    --      4.324065 ||   0.0664 ||   0.1299 ||  0.587469 ||  0.600524 ||      4.319607 ||      0.0655 ||   0.1298 ||  0.589841 ||  0.597477 ||    16.234344 || 
    Epoch 25    --      4.302598 ||   0.0706 ||   0.1353 ||  0.592832 ||  0.606684 ||      4.338797 ||      0.0651 ||   0.1311 ||  0.594578 ||  0.601579 ||    16.361261 || 
    Epoch 26    --      4.296355 ||   0.0724 ||   0.1381 ||  0.593018 ||  0.607446 ||      4.267516 ||      0.0771 ||   0.1470 ||  0.607721 ||  0.614137 ||    16.417905 || 
    Epoch 27    --      4.277682 ||   0.0759 ||   0.1441 ||  0.598977 ||  0.613707 ||      4.282975 ||      0.0766 ||   0.1472 ||  0.606820 ||  0.617191 ||    16.293097 || 
    Epoch 28    --      4.248281 ||   0.0817 ||   0.1507 ||  0.605612 ||  0.619914 ||      4.239192 ||      0.0808 ||   0.1497 ||  0.612426 ||  0.620524 ||    16.424962 || 
    Epoch 29    --      4.230364 ||   0.0856 ||   0.1547 ||  0.608830 ||  0.623607 ||      4.230209 ||      0.0825 ||   0.1513 ||  0.613190 ||  0.623641 ||    16.230359 || 
    Epoch 30    --      4.213267 ||   0.0879 ||   0.1572 ||  0.612798 ||  0.629680 ||      4.215166 ||      0.0866 ||   0.1604 ||  0.620043 ||  0.629326 ||    16.192393 || 
    Epoch 31    --      4.196986 ||   0.0922 ||   0.1619 ||  0.616569 ||  0.633199 ||      4.194136 ||      0.0916 ||   0.1628 ||  0.617898 ||  0.628408 ||    16.600169 || 
    Epoch 32    --      4.173965 ||   0.0948 ||   0.1669 ||  0.621272 ||  0.636966 ||      4.185777 ||      0.0938 ||   0.1675 ||  0.626074 ||  0.638214 ||    16.474665 || 
    Epoch 33    --      4.161994 ||   0.0982 ||   0.1691 ||  0.623329 ||  0.640098 ||      4.194057 ||      0.0960 ||   0.1682 ||  0.625379 ||  0.634584 ||    16.261816 || 
    Epoch 34    --      4.144691 ||   0.1017 ||   0.1746 ||  0.627728 ||  0.645373 ||      4.154555 ||      0.0979 ||   0.1728 ||  0.630533 ||  0.640175 ||    16.082965 || 
    Epoch 35    --      4.118937 ||   0.1081 ||   0.1803 ||  0.631182 ||  0.649037 ||      4.193228 ||      0.0929 ||   0.1576 ||  0.615196 ||  0.627231 ||    16.387540 || 
    Epoch 36    --      4.110570 ||   0.1097 ||   0.1822 ||  0.633760 ||  0.653702 ||      4.115023 ||      0.1044 ||   0.1764 ||  0.635419 ||  0.645631 ||    16.120592 || 
    Epoch 37    --      4.082710 ||   0.1147 ||   0.1888 ||  0.639162 ||  0.657626 ||      4.135617 ||      0.1086 ||   0.1801 ||  0.639343 ||  0.651885 ||    16.145137 || 
    Epoch 38    --      4.075512 ||   0.1170 ||   0.1911 ||  0.641662 ||  0.660716 ||      4.070588 ||      0.1152 ||   0.1953 ||  0.649925 ||  0.663985 ||    16.213316 || 
    Epoch 39    --      4.063918 ||   0.1195 ||   0.1952 ||  0.642809 ||  0.662868 ||      4.028775 ||      0.1214 ||   0.1977 ||  0.654077 ||  0.667411 ||    16.301046 || 
    Epoch 40    --      4.039626 ||   0.1224 ||   0.1968 ||  0.648249 ||  0.666740 ||      4.023710 ||      0.1253 ||   0.2032 ||  0.654581 ||  0.672577 ||    16.219939 || 
    Epoch 41    --      4.030709 ||   0.1261 ||   0.2015 ||  0.649781 ||  0.670484 ||      4.062336 ||      0.1147 ||   0.1889 ||  0.645792 ||  0.658243 ||    16.052729 || 
    Epoch 42    --      4.018140 ||   0.1261 ||   0.2032 ||  0.651439 ||  0.672137 ||      4.011456 ||      0.1300 ||   0.1993 ||  0.653749 ||  0.666739 ||    16.312762 || 
    Epoch 43    --      4.015457 ||   0.1293 ||   0.2055 ||  0.651873 ||  0.672083 ||      3.990084 ||      0.1293 ||   0.2112 ||  0.661396 ||  0.677902 ||    16.574864 || 
    Epoch 44    --      4.007419 ||   0.1285 ||   0.2074 ||  0.653253 ||  0.673817 ||      4.015373 ||      0.1265 ||   0.2008 ||  0.653185 ||  0.670117 ||    16.076217 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
