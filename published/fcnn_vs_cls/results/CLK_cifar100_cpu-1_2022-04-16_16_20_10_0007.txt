Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      7.176287 ||   0.0242 ||   0.0871 ||  0.532424 ||  0.547726 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607414 ||   0.0530 ||   0.1295 ||  0.556467 ||  0.558010 ||      4.607001 ||      0.0090 ||   0.0443 ||  0.500144 ||  0.485874 ||    17.681445 || 
    Epoch 01    --      4.605481 ||   0.0097 ||   0.0481 ||  0.494558 ||  0.496161 ||      4.603668 ||      0.0087 ||   0.0461 ||  0.502668 ||  0.493203 ||    16.513535 || 
    Epoch 02    --      4.601448 ||   0.0106 ||   0.0509 ||  0.494921 ||  0.496721 ||      4.603026 ||      0.0097 ||   0.0472 ||  0.501885 ||  0.487589 ||    16.112034 || 
    Epoch 03    --      4.599340 ||   0.0116 ||   0.0498 ||  0.496980 ||  0.499287 ||      4.597228 ||      0.0106 ||   0.0484 ||  0.504942 ||  0.491329 ||    15.948173 || 
    Epoch 04    --      4.596651 ||   0.0116 ||   0.0525 ||  0.497189 ||  0.499580 ||      4.591059 ||      0.0123 ||   0.0493 ||  0.509106 ||  0.499270 ||    16.124613 || 
    Epoch 05    --      4.591671 ||   0.0134 ||   0.0531 ||  0.500769 ||  0.503176 ||      4.590455 ||      0.0109 ||   0.0497 ||  0.508906 ||  0.498493 ||    16.348246 || 
    Epoch 06    --      4.585025 ||   0.0144 ||   0.0566 ||  0.503177 ||  0.505601 ||      4.586957 ||      0.0123 ||   0.0502 ||  0.511874 ||  0.499753 ||    16.275377 || 
    Epoch 07    --      4.580669 ||   0.0159 ||   0.0586 ||  0.506558 ||  0.509661 ||      4.582294 ||      0.0140 ||   0.0555 ||  0.513602 ||  0.499970 ||    16.065234 || 
    Epoch 08    --      4.571690 ||   0.0175 ||   0.0608 ||  0.508379 ||  0.512017 ||      4.571181 ||      0.0155 ||   0.0558 ||  0.515626 ||  0.504158 ||    16.527791 || 
    Epoch 09    --      4.562977 ||   0.0188 ||   0.0652 ||  0.516731 ||  0.520335 ||      4.556469 ||      0.0189 ||   0.0651 ||  0.524399 ||  0.518000 ||    16.149161 || 
    Epoch 10    --      4.549564 ||   0.0214 ||   0.0712 ||  0.521475 ||  0.526018 ||      4.557688 ||      0.0184 ||   0.0613 ||  0.523645 ||  0.517453 ||    16.107635 || 
    Epoch 11    --      4.532958 ||   0.0245 ||   0.0756 ||  0.527145 ||  0.533246 ||      4.538398 ||      0.0199 ||   0.0673 ||  0.529452 ||  0.522932 ||    15.999185 || 
    Epoch 12    --      4.523304 ||   0.0271 ||   0.0782 ||  0.532321 ||  0.538490 ||      4.515090 ||      0.0264 ||   0.0733 ||  0.536120 ||  0.531898 ||    16.685431 || 
    Epoch 13    --      4.507852 ||   0.0298 ||   0.0831 ||  0.536486 ||  0.543579 ||      4.498209 ||      0.0264 ||   0.0792 ||  0.542007 ||  0.535804 ||    16.073723 || 
    Epoch 14    --      4.489606 ||   0.0325 ||   0.0871 ||  0.542336 ||  0.550451 ||      4.501541 ||      0.0368 ||   0.0932 ||  0.555488 ||  0.557258 ||    15.989873 || 
    Epoch 15    --      4.477138 ||   0.0345 ||   0.0896 ||  0.547655 ||  0.556533 ||      4.477256 ||      0.0345 ||   0.0927 ||  0.556988 ||  0.559044 ||    16.224750 || 
    Epoch 16    --      4.462811 ||   0.0376 ||   0.0932 ||  0.549954 ||  0.560022 ||      4.463293 ||      0.0358 ||   0.0911 ||  0.553373 ||  0.552019 ||    16.313541 || 
    Epoch 17    --      4.440513 ||   0.0413 ||   0.0995 ||  0.556837 ||  0.566327 ||      4.443401 ||      0.0369 ||   0.0933 ||  0.559581 ||  0.563605 ||    15.813766 || 
    Epoch 18    --      4.425890 ||   0.0445 ||   0.1028 ||  0.561948 ||  0.571553 ||      4.436282 ||      0.0397 ||   0.0993 ||  0.564552 ||  0.568859 ||    16.228787 || 
    Epoch 19    --      4.410764 ||   0.0474 ||   0.1085 ||  0.566699 ||  0.577949 ||      4.411169 ||      0.0459 ||   0.1073 ||  0.573040 ||  0.577798 ||    16.505394 || 
    Epoch 20    --      4.400256 ||   0.0500 ||   0.1108 ||  0.568605 ||  0.579831 ||      4.385110 ||      0.0511 ||   0.1134 ||  0.580420 ||  0.586305 ||    16.378984 || 
    Epoch 21    --      4.377789 ||   0.0531 ||   0.1154 ||  0.574679 ||  0.587118 ||      4.385205 ||      0.0517 ||   0.1151 ||  0.575193 ||  0.581020 ||    16.015026 || 
    Epoch 22    --      4.361554 ||   0.0564 ||   0.1192 ||  0.578297 ||  0.590890 ||      4.369519 ||      0.0552 ||   0.1190 ||  0.580429 ||  0.586654 ||    16.359923 || 
    Epoch 23    --      4.347034 ||   0.0579 ||   0.1221 ||  0.582339 ||  0.596301 ||      4.335482 ||      0.0604 ||   0.1258 ||  0.586797 ||  0.591180 ||    16.631861 || 
    Epoch 24    --      4.333328 ||   0.0625 ||   0.1259 ||  0.584961 ||  0.598240 ||      4.322632 ||      0.0598 ||   0.1274 ||  0.596836 ||  0.605527 ||    16.240692 || 
    Epoch 25    --      4.319519 ||   0.0634 ||   0.1296 ||  0.587973 ||  0.602077 ||      4.326315 ||      0.0631 ||   0.1265 ||  0.587101 ||  0.593222 ||    16.034595 || 
    Epoch 26    --      4.302143 ||   0.0672 ||   0.1333 ||  0.592519 ||  0.607533 ||      4.289485 ||      0.0662 ||   0.1351 ||  0.598336 ||  0.605074 ||    16.209399 || 
    Epoch 27    --      4.286315 ||   0.0708 ||   0.1398 ||  0.596744 ||  0.611384 ||      4.263001 ||      0.0749 ||   0.1392 ||  0.603116 ||  0.613455 ||    16.568097 || 
    Epoch 28    --      4.272561 ||   0.0749 ||   0.1422 ||  0.598517 ||  0.613951 ||      4.316358 ||      0.0646 ||   0.1327 ||  0.593258 ||  0.602094 ||    16.136325 || 
    Epoch 29    --      4.255043 ||   0.0776 ||   0.1466 ||  0.602984 ||  0.618047 ||      4.255080 ||      0.0750 ||   0.1429 ||  0.607974 ||  0.617182 ||    16.125261 || 
    Epoch 30    --      4.250619 ||   0.0774 ||   0.1481 ||  0.603532 ||  0.619945 ||      4.225116 ||      0.0842 ||   0.1547 ||  0.611957 ||  0.623287 ||    16.262357 || 
    Epoch 31    --      4.235085 ||   0.0805 ||   0.1505 ||  0.606657 ||  0.623630 ||      4.225410 ||      0.0787 ||   0.1548 ||  0.616476 ||  0.626242 ||    15.911949 || 
    Epoch 32    --      4.216938 ||   0.0850 ||   0.1542 ||  0.610114 ||  0.626561 ||      4.246812 ||      0.0791 ||   0.1475 ||  0.605953 ||  0.617540 ||    16.350072 || 
    Epoch 33    --      4.206566 ||   0.0870 ||   0.1575 ||  0.611804 ||  0.628957 ||      4.197405 ||      0.0835 ||   0.1574 ||  0.622047 ||  0.631999 ||    16.270768 || 
    Epoch 34    --      4.190492 ||   0.0897 ||   0.1609 ||  0.616136 ||  0.633218 ||      4.195670 ||      0.0868 ||   0.1554 ||  0.617187 ||  0.627073 ||    16.474528 || 
    Epoch 35    --      4.177062 ||   0.0928 ||   0.1645 ||  0.618076 ||  0.635339 ||      4.200449 ||      0.0869 ||   0.1567 ||  0.617494 ||  0.628329 ||    15.873680 || 
    Epoch 36    --      4.179312 ||   0.0942 ||   0.1646 ||  0.618896 ||  0.636776 ||      4.185544 ||      0.0887 ||   0.1619 ||  0.620059 ||  0.629371 ||    15.923767 || 
    Epoch 37    --      4.155400 ||   0.0978 ||   0.1705 ||  0.621889 ||  0.639930 ||      4.152831 ||      0.0950 ||   0.1660 ||  0.628526 ||  0.642822 ||    16.179444 || 
    Epoch 38    --      4.150182 ||   0.0986 ||   0.1695 ||  0.623536 ||  0.641496 ||      4.123686 ||      0.0998 ||   0.1750 ||  0.634702 ||  0.648383 ||    16.609194 || 
    Epoch 39    --      4.132636 ||   0.1024 ||   0.1749 ||  0.627756 ||  0.646128 ||      4.137450 ||      0.1007 ||   0.1718 ||  0.630841 ||  0.643122 ||    16.036036 || 
    Epoch 40    --      4.121782 ||   0.1049 ||   0.1778 ||  0.629238 ||  0.647537 ||      4.109240 ||      0.1058 ||   0.1809 ||  0.633732 ||  0.648496 ||    16.382258 || 
    Epoch 41    --      4.113158 ||   0.1059 ||   0.1803 ||  0.630801 ||  0.650492 ||      4.106859 ||      0.1091 ||   0.1794 ||  0.638863 ||  0.649346 ||    16.405910 || 
    Epoch 42    --      4.108000 ||   0.1081 ||   0.1821 ||  0.633092 ||  0.652889 ||      4.106487 ||      0.1083 ||   0.1843 ||  0.642247 ||  0.655936 ||    16.263051 || 
    Epoch 43    --      4.094468 ||   0.1103 ||   0.1845 ||  0.633914 ||  0.652768 ||      4.131332 ||      0.1037 ||   0.1763 ||  0.633494 ||  0.646508 ||    16.282738 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
