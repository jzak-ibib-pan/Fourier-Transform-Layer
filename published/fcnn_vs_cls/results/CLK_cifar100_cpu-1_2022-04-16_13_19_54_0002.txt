Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.992417 ||   0.0279 ||   0.0941 ||  0.537508 ||  0.554753 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.607978 ||   0.0515 ||   0.1311 ||  0.561589 ||  0.562976 ||      4.607008 ||      0.0090 ||   0.0439 ||  0.500099 ||  0.485803 ||    17.052143 || 
    Epoch 01    --      4.604917 ||   0.0100 ||   0.0487 ||  0.494497 ||  0.496215 ||      4.603804 ||      0.0086 ||   0.0456 ||  0.501806 ||  0.492388 ||    16.199095 || 
    Epoch 02    --      4.603009 ||   0.0103 ||   0.0498 ||  0.493834 ||  0.495656 ||      4.603539 ||      0.0097 ||   0.0468 ||  0.501601 ||  0.487030 ||    16.713711 || 
    Epoch 03    --      4.600183 ||   0.0110 ||   0.0494 ||  0.495954 ||  0.498422 ||      4.601124 ||      0.0101 ||   0.0459 ||  0.504101 ||  0.490648 ||    16.293202 || 
    Epoch 04    --      4.596857 ||   0.0113 ||   0.0521 ||  0.496566 ||  0.499169 ||      4.598825 ||      0.0111 ||   0.0485 ||  0.507654 ||  0.497010 ||    16.226816 || 
    Epoch 05    --      4.596017 ||   0.0127 ||   0.0512 ||  0.498105 ||  0.500543 ||      4.591042 ||      0.0106 ||   0.0488 ||  0.506619 ||  0.497270 ||    16.141345 || 
    Epoch 06    --      4.590006 ||   0.0139 ||   0.0554 ||  0.501381 ||  0.503975 ||      4.588965 ||      0.0113 ||   0.0499 ||  0.508876 ||  0.496671 ||    16.517710 || 
    Epoch 07    --      4.583679 ||   0.0153 ||   0.0556 ||  0.504177 ||  0.507393 ||      4.585386 ||      0.0123 ||   0.0502 ||  0.508356 ||  0.494640 ||    16.439280 || 
    Epoch 08    --      4.579610 ||   0.0164 ||   0.0586 ||  0.506245 ||  0.509877 ||      4.583838 ||      0.0143 ||   0.0560 ||  0.516332 ||  0.504899 ||    16.207680 || 
    Epoch 09    --      4.569894 ||   0.0167 ||   0.0606 ||  0.511223 ||  0.514367 ||      4.589888 ||      0.0196 ||   0.0633 ||  0.522270 ||  0.516703 ||    16.644119 || 
    Epoch 10    --      4.563539 ||   0.0191 ||   0.0658 ||  0.514636 ||  0.518647 ||      4.567689 ||      0.0165 ||   0.0581 ||  0.520689 ||  0.512953 ||    16.133990 || 
    Epoch 11    --      4.553380 ||   0.0203 ||   0.0672 ||  0.516575 ||  0.522070 ||      4.552229 ||      0.0194 ||   0.0624 ||  0.523265 ||  0.515903 ||    16.104440 || 
    Epoch 12    --      4.543655 ||   0.0234 ||   0.0703 ||  0.520616 ||  0.525905 ||      4.546293 ||      0.0215 ||   0.0681 ||  0.530686 ||  0.523506 ||    15.865385 || 
    Epoch 13    --      4.530891 ||   0.0258 ||   0.0747 ||  0.527529 ||  0.533771 ||      4.529717 ||      0.0224 ||   0.0746 ||  0.531717 ||  0.523690 ||    16.224575 || 
    Epoch 14    --      4.518592 ||   0.0275 ||   0.0785 ||  0.530052 ||  0.536880 ||      4.526686 ||      0.0251 ||   0.0753 ||  0.532517 ||  0.528655 ||    16.266341 || 
    Epoch 15    --      4.501215 ||   0.0302 ||   0.0822 ||  0.535547 ||  0.542875 ||      4.515524 ||      0.0265 ||   0.0786 ||  0.539322 ||  0.538069 ||    16.094914 || 
    Epoch 16    --      4.492530 ||   0.0332 ||   0.0858 ||  0.540031 ||  0.549001 ||      4.491272 ||      0.0333 ||   0.0842 ||  0.549302 ||  0.550696 ||    16.269916 || 
    Epoch 17    --      4.468792 ||   0.0368 ||   0.0910 ||  0.545738 ||  0.554447 ||      4.488917 ||      0.0322 ||   0.0877 ||  0.550904 ||  0.554487 ||    16.574063 || 
    Epoch 18    --      4.456036 ||   0.0393 ||   0.0957 ||  0.550932 ||  0.559536 ||      4.463020 ||      0.0349 ||   0.0904 ||  0.555652 ||  0.557531 ||    16.036013 || 
    Epoch 19    --      4.441487 ||   0.0432 ||   0.1016 ||  0.557012 ||  0.567368 ||      4.448588 ||      0.0424 ||   0.1024 ||  0.565506 ||  0.571349 ||    16.216036 || 
    Epoch 20    --      4.424066 ||   0.0447 ||   0.1036 ||  0.562063 ||  0.573781 ||      4.421869 ||      0.0431 ||   0.1039 ||  0.569281 ||  0.574813 ||    16.318875 || 
    Epoch 21    --      4.410840 ||   0.0490 ||   0.1089 ||  0.566835 ||  0.578459 ||      4.386928 ||      0.0518 ||   0.1112 ||  0.574110 ||  0.578585 ||    16.117090 || 
    Epoch 22    --      4.385462 ||   0.0531 ||   0.1143 ||  0.573976 ||  0.586490 ||      4.384246 ||      0.0492 ||   0.1171 ||  0.579459 ||  0.586212 ||    15.939570 || 
    Epoch 23    --      4.368660 ||   0.0560 ||   0.1181 ||  0.574301 ||  0.587939 ||      4.366742 ||      0.0558 ||   0.1124 ||  0.578537 ||  0.583495 ||    16.550241 || 
    Epoch 24    --      4.350703 ||   0.0607 ||   0.1234 ||  0.580911 ||  0.594267 ||      4.336798 ||      0.0587 ||   0.1222 ||  0.589506 ||  0.600114 ||    16.390490 || 
    Epoch 25    --      4.337806 ||   0.0613 ||   0.1251 ||  0.586131 ||  0.599896 ||      4.343110 ||      0.0593 ||   0.1206 ||  0.584605 ||  0.590772 ||    15.877825 || 
    Epoch 26    --      4.324453 ||   0.0648 ||   0.1309 ||  0.586824 ||  0.602063 ||      4.313130 ||      0.0678 ||   0.1263 ||  0.588829 ||  0.593634 ||    16.128447 || 
    Epoch 27    --      4.301543 ||   0.0684 ||   0.1356 ||  0.592227 ||  0.607574 ||      4.318926 ||      0.0696 ||   0.1395 ||  0.599645 ||  0.613186 ||    16.284338 || 
    Epoch 28    --      4.283301 ||   0.0737 ||   0.1399 ||  0.596517 ||  0.611986 ||      4.301871 ||      0.0678 ||   0.1336 ||  0.597502 ||  0.605352 ||    16.375416 || 
    Epoch 29    --      4.267069 ||   0.0769 ||   0.1450 ||  0.601457 ||  0.617358 ||      4.257421 ||      0.0748 ||   0.1398 ||  0.605697 ||  0.615057 ||    16.477350 || 
    Epoch 30    --      4.255791 ||   0.0771 ||   0.1471 ||  0.603043 ||  0.619413 ||      4.250098 ||      0.0799 ||   0.1460 ||  0.600362 ||  0.611454 ||    16.277609 || 
    Epoch 31    --      4.236479 ||   0.0820 ||   0.1503 ||  0.605204 ||  0.623316 ||      4.234748 ||      0.0816 ||   0.1536 ||  0.613001 ||  0.623713 ||    16.799412 || 
    Epoch 32    --      4.213547 ||   0.0861 ||   0.1552 ||  0.612109 ||  0.628416 ||      4.275578 ||      0.0740 ||   0.1420 ||  0.596292 ||  0.607941 ||    15.891339 || 
    Epoch 33    --      4.203169 ||   0.0885 ||   0.1581 ||  0.614295 ||  0.631565 ||      4.199412 ||      0.0869 ||   0.1615 ||  0.620582 ||  0.632205 ||    16.018478 || 
    Epoch 34    --      4.191613 ||   0.0918 ||   0.1626 ||  0.616774 ||  0.633933 ||      4.177109 ||      0.0928 ||   0.1603 ||  0.625849 ||  0.638585 ||    16.117302 || 
    Epoch 35    --      4.171375 ||   0.0966 ||   0.1659 ||  0.620254 ||  0.638620 ||      4.203510 ||      0.0873 ||   0.1553 ||  0.615860 ||  0.627170 ||    16.348184 || 
    Epoch 36    --      4.161315 ||   0.0984 ||   0.1682 ||  0.622587 ||  0.641554 ||      4.136811 ||      0.0991 ||   0.1715 ||  0.633296 ||  0.643904 ||    15.707626 || 
    Epoch 37    --      4.138985 ||   0.1016 ||   0.1758 ||  0.625475 ||  0.644203 ||      4.152324 ||      0.0961 ||   0.1689 ||  0.629515 ||  0.644152 ||    16.319528 || 
    Epoch 38    --      4.140563 ||   0.1016 ||   0.1736 ||  0.625614 ||  0.644626 ||      4.180818 ||      0.0958 ||   0.1735 ||  0.624434 ||  0.638875 ||    16.144921 || 
    Epoch 39    --      4.119275 ||   0.1060 ||   0.1790 ||  0.631080 ||  0.650400 ||      4.194057 ||      0.0960 ||   0.1789 ||  0.635257 ||  0.647549 ||    16.433213 || 
    Epoch 40    --      4.112709 ||   0.1076 ||   0.1793 ||  0.630403 ||  0.648853 ||      4.086917 ||      0.1116 ||   0.1885 ||  0.643098 ||  0.657901 ||    16.098219 || 
    Epoch 41    --      4.109518 ||   0.1104 ||   0.1822 ||  0.633807 ||  0.653156 ||      4.127225 ||      0.1036 ||   0.1718 ||  0.629912 ||  0.637818 ||    16.366115 || 
    Epoch 42    --      4.087844 ||   0.1119 ||   0.1840 ||  0.634494 ||  0.654610 ||      4.080344 ||      0.1094 ||   0.1840 ||  0.644154 ||  0.656364 ||    16.587989 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "model_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
