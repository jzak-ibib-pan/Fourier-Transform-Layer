Build arguments
	model_type                               -                                   custom
	input_shape                              -                              (32, 32, 3)
	noof_classes                             -                                      100
	weights                                  -                                     None
	freeze                                   -                                        0
	layers                                   -           ['conv2d', 'flatten', 'dense']
Compile arguments
	optimizer                                -                                     adam
	loss                                     -                 categorical_crossentropy
	run_eagerly                              -                                    False
	metrics_000                              -                     categorical_accuracy
	metrics_001                              -                                    top-5
	metrics_002                              -                                     mAUC
	metrics_003                              -                                     uAUC
Train arguments
	epochs                                   -                                      100
	batch                                    -                                        8
	call_time                                -                                     True
	call_stop                                -                                     True
	call_stop_kwargs-baseline                -                                      0.1
	call_stop_kwargs-monitor                 -                 val_categorical_accuracy
	call_stop_kwargs-patience                -                                        2
	call_stop_kwargs-min_delta               -                                    0.001
	call_stop_kwargs-restore_best            -                                     True
	call_checkpoint                          -                                    False
	call_checkpoint_kwargs-monitor           -                 val_categorical_accuracy
	call_checkpoint_kwargs-mode              -                                     auto
	call_checkpoint_kwargs-save_freq         -                                    epoch
	call_checkpoint_kwargs-save_weights_only -                                     True
	call_checkpoint_kwargs-save_best_only    -                                     True
	save_memory                              -                                     True
	save_final                               -                                     True
	validation_split                         -                                      0.2
	verbose                                  -                                        1
	dataset_size                             -                                    50000
CPU - local PC (IP: 180)
Evaluation: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    || 
    Epoch 0     --      6.568326 ||   0.0260 ||   0.0973 ||  0.542232 ||  0.559732 || 
Training history: 
     epochs     --      loss     || cat_acc  ||   top5   ||    mAU    ||    uAU    ||    val_loss   || val_cat_acc || val_top5 ||  val_mAU  ||  val_uAU  ||     time     || 
    Epoch 00    --      4.608062 ||   0.0518 ||   0.1297 ||  0.556696 ||  0.558106 ||      4.605515 ||      0.0094 ||   0.0446 ||  0.500405 ||  0.486400 ||    94.233060 || 
    Epoch 01    --      4.604116 ||   0.0100 ||   0.0489 ||  0.495229 ||  0.496915 ||      4.603640 ||      0.0086 ||   0.0451 ||  0.501655 ||  0.492307 ||    94.233087 || 
    Epoch 02    --      4.602363 ||   0.0102 ||   0.0496 ||  0.493937 ||  0.495611 ||      4.602321 ||      0.0098 ||   0.0472 ||  0.502948 ||  0.488865 ||    95.467471 || 
    Epoch 03    --      4.598644 ||   0.0114 ||   0.0504 ||  0.496986 ||  0.499418 ||      4.599056 ||      0.0105 ||   0.0461 ||  0.504517 ||  0.490660 ||    93.856735 || 
    Epoch 04    --      4.596311 ||   0.0112 ||   0.0519 ||  0.496895 ||  0.499335 ||      4.593755 ||      0.0108 ||   0.0482 ||  0.506209 ||  0.496419 ||    94.436255 || 
    Epoch 05    --      4.592440 ||   0.0130 ||   0.0525 ||  0.499766 ||  0.502233 ||      4.591495 ||      0.0104 ||   0.0500 ||  0.507530 ||  0.498202 ||    94.854430 || 
    Epoch 06    --      4.585059 ||   0.0141 ||   0.0569 ||  0.503460 ||  0.505827 ||      4.581363 ||      0.0129 ||   0.0533 ||  0.512409 ||  0.501494 ||    94.608152 || 
    Epoch 07    --      4.577163 ||   0.0162 ||   0.0585 ||  0.508181 ||  0.511215 ||      4.572401 ||      0.0160 ||   0.0551 ||  0.515042 ||  0.501377 ||    94.621394 || 
    Epoch 08    --      4.568161 ||   0.0182 ||   0.0627 ||  0.511820 ||  0.515505 ||      4.567693 ||      0.0170 ||   0.0582 ||  0.519327 ||  0.510611 ||    93.860951 || 
    Epoch 09    --      4.554807 ||   0.0210 ||   0.0690 ||  0.520332 ||  0.524547 ||      4.558568 ||      0.0223 ||   0.0687 ||  0.531119 ||  0.527471 ||    96.905032 || 
    Epoch 10    --      4.540246 ||   0.0249 ||   0.0749 ||  0.526526 ||  0.532118 ||      4.541069 ||      0.0216 ||   0.0636 ||  0.527851 ||  0.522339 ||    94.045672 || 
    Epoch 11    --      4.524064 ||   0.0270 ||   0.0780 ||  0.531197 ||  0.538058 ||      4.523977 ||      0.0238 ||   0.0732 ||  0.538141 ||  0.534567 ||    94.217578 || 
    Epoch 12    --      4.514503 ||   0.0294 ||   0.0817 ||  0.535115 ||  0.542637 ||      4.524848 ||      0.0239 ||   0.0717 ||  0.534175 ||  0.529701 ||    94.561351 || 
    Epoch 13    --      4.497890 ||   0.0321 ||   0.0865 ||  0.540319 ||  0.548661 ||      4.504134 ||      0.0290 ||   0.0819 ||  0.541977 ||  0.538064 ||    94.858914 || 
    Epoch 14    --      4.484268 ||   0.0347 ||   0.0894 ||  0.543444 ||  0.552388 ||      4.499346 ||      0.0279 ||   0.0797 ||  0.545365 ||  0.545131 ||    94.561337 || 
    Epoch 15    --      4.469697 ||   0.0384 ||   0.0935 ||  0.548307 ||  0.558155 ||      4.466145 ||      0.0348 ||   0.0940 ||  0.556902 ||  0.560150 ||    94.389518 || 
    Epoch 16    --      4.451194 ||   0.0410 ||   0.0971 ||  0.552475 ||  0.563371 ||      4.458480 ||      0.0372 ||   0.0925 ||  0.557344 ||  0.561257 ||    94.436391 || 
    Epoch 17    --      4.432845 ||   0.0445 ||   0.1025 ||  0.559766 ||  0.570763 ||      4.452803 ||      0.0384 ||   0.0908 ||  0.555504 ||  0.560216 ||    94.155171 || 
    Epoch 18    --      4.418994 ||   0.0470 ||   0.1066 ||  0.562749 ||  0.573588 ||      4.416997 ||      0.0452 ||   0.1064 ||  0.568697 ||  0.574991 ||    94.764552 || 
    Epoch 19    --      4.402007 ||   0.0503 ||   0.1110 ||  0.567734 ||  0.579870 ||      4.397822 ||      0.0500 ||   0.1131 ||  0.573760 ||  0.580603 ||    94.233304 || 
    Epoch 20    --      4.385318 ||   0.0534 ||   0.1161 ||  0.573454 ||  0.586734 ||      4.406734 ||      0.0502 ||   0.1161 ||  0.578252 ||  0.585149 ||    94.436410 || 
    Epoch 21    --      4.371801 ||   0.0556 ||   0.1193 ||  0.576852 ||  0.589906 ||      4.383946 ||      0.0539 ||   0.1159 ||  0.572352 ||  0.577500 ||    94.561459 || 
    Epoch 22    --      4.344360 ||   0.0611 ||   0.1253 ||  0.582086 ||  0.596140 ||      4.367764 ||      0.0543 ||   0.1248 ||  0.585819 ||  0.595507 ||    93.952092 || 
    Epoch 23    --      4.331743 ||   0.0631 ||   0.1298 ||  0.584946 ||  0.599909 ||      4.315508 ||      0.0640 ||   0.1260 ||  0.592820 ||  0.601364 ||    94.467697 || 
    Epoch 24    --      4.315172 ||   0.0664 ||   0.1334 ||  0.590871 ||  0.605971 ||      4.301313 ||      0.0680 ||   0.1338 ||  0.600782 ||  0.613109 ||    94.608359 || 
    Epoch 25    --      4.291088 ||   0.0712 ||   0.1395 ||  0.595546 ||  0.611392 ||      4.320113 ||      0.0664 ||   0.1360 ||  0.600900 ||  0.610692 ||    94.567498 || 
    Epoch 26    --      4.277722 ||   0.0728 ||   0.1439 ||  0.598987 ||  0.615871 ||      4.265475 ||      0.0779 ||   0.1427 ||  0.606948 ||  0.616043 ||    94.118492 || 
    Epoch 27    --      4.270121 ||   0.0753 ||   0.1450 ||  0.601263 ||  0.617041 ||      4.254529 ||      0.0776 ||   0.1443 ||  0.610458 ||  0.623987 ||    94.419473 || 
    Epoch 28    --      4.245912 ||   0.0812 ||   0.1504 ||  0.607183 ||  0.623747 ||      4.277576 ||      0.0750 ||   0.1434 ||  0.608574 ||  0.621588 ||    94.530222 || 
    Epoch 29    --      4.247916 ||   0.0811 ||   0.1531 ||  0.609324 ||  0.626193 ||      4.221353 ||      0.0823 ||   0.1537 ||  0.616474 ||  0.630262 ||    95.389632 || 
    Epoch 30    --      4.227040 ||   0.0842 ||   0.1535 ||  0.610015 ||  0.628697 ||      4.233233 ||      0.0828 ||   0.1644 ||  0.622168 ||  0.634803 ||    95.342784 || 
    Epoch 31    --      4.216022 ||   0.0874 ||   0.1581 ||  0.612675 ||  0.630018 ||      4.225564 ||      0.0846 ||   0.1642 ||  0.617403 ||  0.629928 ||    95.905278 || 
    Epoch 32    --      4.196019 ||   0.0909 ||   0.1636 ||  0.617916 ||  0.635544 ||      4.182549 ||      0.0884 ||   0.1632 ||  0.623728 ||  0.638766 ||    94.914098 || 
    Epoch 33    --      4.169714 ||   0.0936 ||   0.1653 ||  0.622224 ||  0.640905 ||      4.179509 ||      0.0922 ||   0.1634 ||  0.619942 ||  0.631123 ||    95.436514 || 
    Epoch 34    --      4.158490 ||   0.0981 ||   0.1734 ||  0.624644 ||  0.644319 ||      4.160667 ||      0.0937 ||   0.1651 ||  0.627724 ||  0.639611 ||    95.827181 || 
    Epoch 35    --      4.144485 ||   0.1007 ||   0.1750 ||  0.626921 ||  0.645741 ||      4.164784 ||      0.0929 ||   0.1659 ||  0.621051 ||  0.634783 ||    95.139689 || 
    Epoch 36    --      4.138664 ||   0.1021 ||   0.1766 ||  0.628456 ||  0.648422 ||      4.171234 ||      0.0937 ||   0.1644 ||  0.621433 ||  0.632820 ||    95.311583 || 
    Epoch 37    --      4.125690 ||   0.1049 ||   0.1809 ||  0.630427 ||  0.649493 ||      4.164423 ||      0.1033 ||   0.1793 ||  0.635472 ||  0.651649 ||    95.170961 || 
    Epoch 38    --      4.109512 ||   0.1067 ||   0.1822 ||  0.633500 ||  0.653478 ||      4.107477 ||      0.1039 ||   0.1844 ||  0.637786 ||  0.653347 ||    95.092805 || 
    Epoch 39    --      4.117200 ||   0.1080 ||   0.1828 ||  0.634374 ||  0.653960 ||      4.145653 ||      0.0951 ||   0.1686 ||  0.629467 ||  0.642431 ||    95.389683 || 
Layers list:
	conv2d                                   -                    (17, 17, 3, 24)|(24,)
	conv2d-filters                           -                                       24
	conv2d-kernel_size                       -                                       17
	conv2d-strides                           -                                   (1, 1)
	conv2d-padding                           -                                    valid
	conv2d-data_format                       -                                     None
	conv2d-dilation_rate                     -                                   (1, 1)
	conv2d-groups                            -                                        1
	conv2d-activation                        -                                     relu
	conv2d-use_bias                          -                                     True
	conv2d-kernel_initializer                -                                he_normal
	conv2d-bias_initializer                  -                                    zeros
	conv2d-kernel_regularizer                -                                     None
	conv2d-bias_regularizer                  -                                     None
	conv2d-activity_regularizer              -                                     None
	conv2d-kernel_constraint                 -                                     None
	conv2d-bias_constraint                   -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	flatten_2                                -                                         
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
	dense_2                                  -                       (6144, 100)|(100,)
	dense_2-units                            -                                      100
	dense_2-activation                       -                                  softmax
	dense_2-use_bias                         -                                     True
	dense_2-kernel_initializer               -                           glorot_uniform
	dense_2-bias_initializer                 -                                    zeros
	dense_2-kernel_regularizer               -                                     None
	dense_2-bias_regularizer                 -                                     None
	dense_2-activity_regularizer             -                                     None
	dense_2-kernel_constraint                -                                     None
	dense_2-bias_constraint                  -                                     None
	######################################## - XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Model: "functional_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 24)        20832     
_________________________________________________________________
flatten_2 (Flatten)          (None, 6144)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 100)               614500    
=================================================================
Total params: 635,332
Trainable params: 635,332
Non-trainable params: 0
_________________________________________________________________
